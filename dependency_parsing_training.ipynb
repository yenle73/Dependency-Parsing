{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b2ab8fae53834fc1bb5d0f61bb011e92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_317a56cc788c4ecaac6b37c8a3f30769",
              "IPY_MODEL_bf4a4caab1dc495c889731726a34ce6d",
              "IPY_MODEL_5d17ce7fa3514f4d8df144033983a978"
            ],
            "layout": "IPY_MODEL_3ffb78d8c5a54b32a8c033f7c6cc40ba"
          }
        },
        "317a56cc788c4ecaac6b37c8a3f30769": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_05e872ea2a46447d9f2b2b9215b73ca7",
            "placeholder": "​",
            "style": "IPY_MODEL_c1c65f53c934435d8c60f398e875931a",
            "value": "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.7.0.json: "
          }
        },
        "bf4a4caab1dc495c889731726a34ce6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_791cbc0bf8854cf4ab6040b569c5eaf6",
            "max": 46172,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bfb7421febf8418c8901bf05b244908e",
            "value": 46172
          }
        },
        "5d17ce7fa3514f4d8df144033983a978": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_75bec608a3d24251a72f7bd904c3d488",
            "placeholder": "​",
            "style": "IPY_MODEL_b6fac222e8574c87b2394d54037e5d38",
            "value": " 370k/? [00:00&lt;00:00, 8.30MB/s]"
          }
        },
        "3ffb78d8c5a54b32a8c033f7c6cc40ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05e872ea2a46447d9f2b2b9215b73ca7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1c65f53c934435d8c60f398e875931a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "791cbc0bf8854cf4ab6040b569c5eaf6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bfb7421febf8418c8901bf05b244908e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "75bec608a3d24251a72f7bd904c3d488": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b6fac222e8574c87b2394d54037e5d38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6aac134b60b942c2b7aebb44e7a5fd20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_36c23c8fcdaf4a1f91ce7541ba59f129",
              "IPY_MODEL_65f4b1c251de47fcbac45c8002bc681c",
              "IPY_MODEL_33d358f425174bafae6c574f02906110"
            ],
            "layout": "IPY_MODEL_942610994e0b40dd996fc0fdf458ecbb"
          }
        },
        "36c23c8fcdaf4a1f91ce7541ba59f129": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_94d2044760594ad6b763ad87ee34b90a",
            "placeholder": "​",
            "style": "IPY_MODEL_91f0ad68c8824544a4539e92d4bb3cbe",
            "value": "Downloading https://huggingface.co/stanfordnlp/stanza-vi/resolve/v1.7.0/models/tokenize/vtb.pt: 100%"
          }
        },
        "65f4b1c251de47fcbac45c8002bc681c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2dbd8e120c6945c78e68e6535c1ad15a",
            "max": 640448,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_292902829e2f49279ba805e4491b5991",
            "value": 640448
          }
        },
        "33d358f425174bafae6c574f02906110": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_81705314278b42ceba5530d1f4878231",
            "placeholder": "​",
            "style": "IPY_MODEL_433b548928bb41f9830aaf60d37b6445",
            "value": " 640k/640k [00:00&lt;00:00, 8.26MB/s]"
          }
        },
        "942610994e0b40dd996fc0fdf458ecbb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94d2044760594ad6b763ad87ee34b90a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91f0ad68c8824544a4539e92d4bb3cbe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2dbd8e120c6945c78e68e6535c1ad15a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "292902829e2f49279ba805e4491b5991": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "81705314278b42ceba5530d1f4878231": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "433b548928bb41f9830aaf60d37b6445": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a515f1f7b2044d83a1c3aea2af6a9706": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_525147f8eb0b41e8a657e9cf51ea1c29",
              "IPY_MODEL_4f08a50425694d4eba498e73f3329ca8",
              "IPY_MODEL_56c99f9c0d3441c6b90a550f9a31e61c"
            ],
            "layout": "IPY_MODEL_41117cf619c649d28c5e81a839debf6d"
          }
        },
        "525147f8eb0b41e8a657e9cf51ea1c29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f5d7bc235714a888cf259c5db3396d9",
            "placeholder": "​",
            "style": "IPY_MODEL_8a73985e88f84e8e8f51c3738c56cb89",
            "value": "Downloading https://huggingface.co/stanfordnlp/stanza-vi/resolve/v1.7.0/models/pos/vtb_charlm.pt: 100%"
          }
        },
        "4f08a50425694d4eba498e73f3329ca8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f8853ab53bb74c8288d36211107fa980",
            "max": 33100422,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_735c59f7caf5434d8ad8a2ddb1017336",
            "value": 33100422
          }
        },
        "56c99f9c0d3441c6b90a550f9a31e61c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9241ac74c6c94094abe32460c848ffa9",
            "placeholder": "​",
            "style": "IPY_MODEL_ba6cd5285de0407c9d2a789a2c8e5c86",
            "value": " 33.1M/33.1M [00:00&lt;00:00, 155MB/s]"
          }
        },
        "41117cf619c649d28c5e81a839debf6d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f5d7bc235714a888cf259c5db3396d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a73985e88f84e8e8f51c3738c56cb89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f8853ab53bb74c8288d36211107fa980": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "735c59f7caf5434d8ad8a2ddb1017336": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9241ac74c6c94094abe32460c848ffa9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba6cd5285de0407c9d2a789a2c8e5c86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "acefd5d6f72e490d8398dab8178bfa50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e4083120606f48c69894d596a96717d5",
              "IPY_MODEL_e42dfb9c36234149a66df587200d6cbc",
              "IPY_MODEL_7d24d4ff172b45cca5c935c398fb876e"
            ],
            "layout": "IPY_MODEL_e212a78f10634650a08bc78fa75582ff"
          }
        },
        "e4083120606f48c69894d596a96717d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b94d88c0aeb046009db12454ba85a10e",
            "placeholder": "​",
            "style": "IPY_MODEL_14a10165e97d41fa88d4949540856ab5",
            "value": "Downloading https://huggingface.co/stanfordnlp/stanza-vi/resolve/v1.7.0/models/constituency/vlsp22_charlm.pt: 100%"
          }
        },
        "e42dfb9c36234149a66df587200d6cbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b25439c16cc34f7fb359a7f235768b91",
            "max": 105253100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d7fdb4f5436245dea13f47f576c2addf",
            "value": 105253100
          }
        },
        "7d24d4ff172b45cca5c935c398fb876e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_67f5698090224aa68ed707478eb9e348",
            "placeholder": "​",
            "style": "IPY_MODEL_e1061dbcb80440d89294fcdb063fc49a",
            "value": " 105M/105M [00:00&lt;00:00, 212MB/s]"
          }
        },
        "e212a78f10634650a08bc78fa75582ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b94d88c0aeb046009db12454ba85a10e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "14a10165e97d41fa88d4949540856ab5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b25439c16cc34f7fb359a7f235768b91": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7fdb4f5436245dea13f47f576c2addf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "67f5698090224aa68ed707478eb9e348": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1061dbcb80440d89294fcdb063fc49a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d30be805e87146269ee04182756b043e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_64b20422df3e48c3ae9f0b00531b9c67",
              "IPY_MODEL_6c94e813653248638d085641c270cb3a",
              "IPY_MODEL_7740f72c792e433c8d4a017ba0e0ffe0"
            ],
            "layout": "IPY_MODEL_4293e3590c9943ab917e0cd94d141e84"
          }
        },
        "64b20422df3e48c3ae9f0b00531b9c67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc5d57e96461468ea5cdb4bd9a08b2e9",
            "placeholder": "​",
            "style": "IPY_MODEL_0ad85e3557cf4d56b556efefda73a77c",
            "value": "Downloading https://huggingface.co/stanfordnlp/stanza-vi/resolve/v1.7.0/models/depparse/vtb_charlm.pt: 100%"
          }
        },
        "6c94e813653248638d085641c270cb3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d2c977a2c0054e9590f4bb20c2e8952e",
            "max": 158721548,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_09bf8702c66b46f893c99977696f48ec",
            "value": 158721548
          }
        },
        "7740f72c792e433c8d4a017ba0e0ffe0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c688e2ac5eb4895990e8c0a4f886d15",
            "placeholder": "​",
            "style": "IPY_MODEL_70b39ab459bc4fe6ae4de50565ca1770",
            "value": " 159M/159M [00:00&lt;00:00, 184MB/s]"
          }
        },
        "4293e3590c9943ab917e0cd94d141e84": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc5d57e96461468ea5cdb4bd9a08b2e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ad85e3557cf4d56b556efefda73a77c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d2c977a2c0054e9590f4bb20c2e8952e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09bf8702c66b46f893c99977696f48ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7c688e2ac5eb4895990e8c0a4f886d15": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70b39ab459bc4fe6ae4de50565ca1770": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "658e5e55a52c4ef099f38c3ad9972f56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1194852bae0d42bf836104c296f37552",
              "IPY_MODEL_72182c58b3874634834208d297eefe61",
              "IPY_MODEL_f835684546134f1eadee7041bd9db892"
            ],
            "layout": "IPY_MODEL_5df1145016b74e3fa160dc846392d4f4"
          }
        },
        "1194852bae0d42bf836104c296f37552": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_55b41830bab94484813723f31d77a6c1",
            "placeholder": "​",
            "style": "IPY_MODEL_6dbdb52497ca4d19b5661c11d1634a19",
            "value": "Downloading https://huggingface.co/stanfordnlp/stanza-vi/resolve/v1.7.0/models/sentiment/vsfc.pt: 100%"
          }
        },
        "72182c58b3874634834208d297eefe61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8cbf48680357418c9d1ee9f7a5a35508",
            "max": 69428835,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c313b22eb6584cc090638a712209e683",
            "value": 69428835
          }
        },
        "f835684546134f1eadee7041bd9db892": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2bffd8975f6e44a58761988eb206c4bc",
            "placeholder": "​",
            "style": "IPY_MODEL_2245bad616c448a59daf5e6a855c1e66",
            "value": " 69.4M/69.4M [00:00&lt;00:00, 215MB/s]"
          }
        },
        "5df1145016b74e3fa160dc846392d4f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55b41830bab94484813723f31d77a6c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6dbdb52497ca4d19b5661c11d1634a19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8cbf48680357418c9d1ee9f7a5a35508": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c313b22eb6584cc090638a712209e683": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2bffd8975f6e44a58761988eb206c4bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2245bad616c448a59daf5e6a855c1e66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2d740012e319419f91a6ec99e45e36b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0637a34545224428b4d1b003a702606d",
              "IPY_MODEL_09881afeedf74b89a52fd126e5a47c44",
              "IPY_MODEL_66e4c8f8d6c042c9acce639fcabdebca"
            ],
            "layout": "IPY_MODEL_a202e39b079043cd8903299e35db353d"
          }
        },
        "0637a34545224428b4d1b003a702606d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c48a8451eb294042a981e9ece01a88d2",
            "placeholder": "​",
            "style": "IPY_MODEL_3229f3137762487cb93b4136be96c623",
            "value": "Downloading https://huggingface.co/stanfordnlp/stanza-vi/resolve/v1.7.0/models/ner/vlsp.pt: 100%"
          }
        },
        "09881afeedf74b89a52fd126e5a47c44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6b95d647daf24802924b9e37bee23caf",
            "max": 51168286,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e430846b8b5f4f2bb27f1a17957c160c",
            "value": 51168286
          }
        },
        "66e4c8f8d6c042c9acce639fcabdebca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a1d5eefc7384871837dbbf94e053856",
            "placeholder": "​",
            "style": "IPY_MODEL_a6da5a1950c44f29806fe2b8412c17ca",
            "value": " 51.2M/51.2M [00:00&lt;00:00, 174MB/s]"
          }
        },
        "a202e39b079043cd8903299e35db353d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c48a8451eb294042a981e9ece01a88d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3229f3137762487cb93b4136be96c623": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6b95d647daf24802924b9e37bee23caf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e430846b8b5f4f2bb27f1a17957c160c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5a1d5eefc7384871837dbbf94e053856": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6da5a1950c44f29806fe2b8412c17ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "beb320a915ed4860af4323e755d0221e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ccec99d6d4284c269d9342fbc5bf8d7e",
              "IPY_MODEL_a8cc90ba9dbc4109827527e36aade708",
              "IPY_MODEL_c5ee975818774b8f90d996ef3d887ae4"
            ],
            "layout": "IPY_MODEL_654a49e954cf4504aa9ee555024b61d8"
          }
        },
        "ccec99d6d4284c269d9342fbc5bf8d7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0534ec6a084a441b8284af5b879c3324",
            "placeholder": "​",
            "style": "IPY_MODEL_41899a89787b4631ac4b1f43d3c2b097",
            "value": "Downloading https://huggingface.co/stanfordnlp/stanza-vi/resolve/v1.7.0/models/backward_charlm/conll17.pt: 100%"
          }
        },
        "a8cc90ba9dbc4109827527e36aade708": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1429402e5b6847c9af70ce02b03c9276",
            "max": 24398079,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cb0360c250964e61838ee3c18e0985f4",
            "value": 24398079
          }
        },
        "c5ee975818774b8f90d996ef3d887ae4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d70f9be6a5974c26a25f23993d38deb8",
            "placeholder": "​",
            "style": "IPY_MODEL_d957beb0d7aa411f89f048feaa388849",
            "value": " 24.4M/24.4M [00:00&lt;00:00, 40.4MB/s]"
          }
        },
        "654a49e954cf4504aa9ee555024b61d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0534ec6a084a441b8284af5b879c3324": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41899a89787b4631ac4b1f43d3c2b097": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1429402e5b6847c9af70ce02b03c9276": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb0360c250964e61838ee3c18e0985f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d70f9be6a5974c26a25f23993d38deb8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d957beb0d7aa411f89f048feaa388849": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "72f6d1e4c137420ca6fc0b440c8a7eb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e19f58467e014d209ea34a08ea6a66d5",
              "IPY_MODEL_47b23ad6513241f9a882f569ee4e3674",
              "IPY_MODEL_8577ffddffed44c1a861fc15d3dc5a66"
            ],
            "layout": "IPY_MODEL_2b37e6276a3845e4af04a9de2a63d389"
          }
        },
        "e19f58467e014d209ea34a08ea6a66d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dfa9464766b44a15bde43e30eaa78dc1",
            "placeholder": "​",
            "style": "IPY_MODEL_97f21f5c80d54c9499d83220b753a2af",
            "value": "Downloading https://huggingface.co/stanfordnlp/stanza-vi/resolve/v1.7.0/models/pretrain/conll17.pt: 100%"
          }
        },
        "47b23ad6513241f9a882f569ee4e3674": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c1d45ef090e14534ac2cfe6397841ed1",
            "max": 107342520,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_27aeaefe868447fea2bec468f11a04c6",
            "value": 107342520
          }
        },
        "8577ffddffed44c1a861fc15d3dc5a66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_014e26ee7cd9456a9e23afa50ca7443f",
            "placeholder": "​",
            "style": "IPY_MODEL_ebbc489da11842bdbd2cc69cafe24ce5",
            "value": " 107M/107M [00:01&lt;00:00, 38.8MB/s]"
          }
        },
        "2b37e6276a3845e4af04a9de2a63d389": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dfa9464766b44a15bde43e30eaa78dc1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97f21f5c80d54c9499d83220b753a2af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c1d45ef090e14534ac2cfe6397841ed1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "27aeaefe868447fea2bec468f11a04c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "014e26ee7cd9456a9e23afa50ca7443f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ebbc489da11842bdbd2cc69cafe24ce5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "56fe7e2f028e4902a4b9a4182490e0f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_73779ee5f44142c09b1467b6bc3bf73d",
              "IPY_MODEL_b2efe33f37ce402ebc276161a0ab28ec",
              "IPY_MODEL_09e4fc7dca274bbb94ece0c2818e55a5"
            ],
            "layout": "IPY_MODEL_83ec1126eb034e40b82baab1ed667634"
          }
        },
        "73779ee5f44142c09b1467b6bc3bf73d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fe2f058a2fb24c488d5c86897b80ee08",
            "placeholder": "​",
            "style": "IPY_MODEL_60b1855f8de240d8976dcb39a44b35d3",
            "value": "Downloading https://huggingface.co/stanfordnlp/stanza-vi/resolve/v1.7.0/models/forward_charlm/conll17.pt: 100%"
          }
        },
        "b2efe33f37ce402ebc276161a0ab28ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_675432f003654b478caa4ac7a8af2681",
            "max": 24398077,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5471c82fa1e34215a99abfe7642a2b66",
            "value": 24398077
          }
        },
        "09e4fc7dca274bbb94ece0c2818e55a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fc1b6ecd3d284224a756b7dcc5028eca",
            "placeholder": "​",
            "style": "IPY_MODEL_5d31ac500abb4dc1a178140d558ca625",
            "value": " 24.4M/24.4M [00:00&lt;00:00, 35.3MB/s]"
          }
        },
        "83ec1126eb034e40b82baab1ed667634": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe2f058a2fb24c488d5c86897b80ee08": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60b1855f8de240d8976dcb39a44b35d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "675432f003654b478caa4ac7a8af2681": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5471c82fa1e34215a99abfe7642a2b66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fc1b6ecd3d284224a756b7dcc5028eca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d31ac500abb4dc1a178140d558ca625": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HY8jQQwJq12f",
        "outputId": "1a34f0f4-6f44-4b58-f983-7c595511fbc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zDqfeuLNEt0j",
        "outputId": "9718ba1a-3be8-4a04-85ed-9da12c11b806"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install stanza"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TgwylS8o6MPa",
        "outputId": "b73c2350-f04a-4163-ca92-98f88f340c39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting stanza\n",
            "  Downloading stanza-1.7.0-py3-none-any.whl (933 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m933.2/933.2 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting emoji (from stanza)\n",
            "  Downloading emoji-2.9.0-py2.py3-none-any.whl (397 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m397.5/397.5 kB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from stanza) (1.23.5)\n",
            "Requirement already satisfied: protobuf>=3.15.0 in /usr/local/lib/python3.10/dist-packages (from stanza) (3.20.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from stanza) (2.31.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from stanza) (3.2.1)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from stanza) (0.10.2)\n",
            "Requirement already satisfied: torch>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from stanza) (2.1.0+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from stanza) (4.66.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza) (1.12)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza) (2.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->stanza) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->stanza) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->stanza) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->stanza) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.3.0->stanza) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.3.0->stanza) (1.3.0)\n",
            "Installing collected packages: emoji, stanza\n",
            "Successfully installed emoji-2.9.0 stanza-1.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/stanfordnlp/stanza.git\n",
        "%cd stanza\n",
        "!pip install -e ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SwmZ1Sfx641N",
        "outputId": "ed95beb4-f6aa-4dd5-e518-a7b935e256e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'stanza'...\n",
            "remote: Enumerating objects: 38708, done.\u001b[K\n",
            "remote: Counting objects: 100% (718/718), done.\u001b[K\n",
            "remote: Compressing objects: 100% (333/333), done.\u001b[K\n",
            "remote: Total 38708 (delta 535), reused 568 (delta 385), pack-reused 37990\u001b[K\n",
            "Receiving objects: 100% (38708/38708), 82.74 MiB | 8.34 MiB/s, done.\n",
            "Resolving deltas: 100% (29676/29676), done.\n",
            "Updating files: 100% (509/509), done.\n",
            "/content/drive/MyDrive/stanza\n",
            "Obtaining file:///content/drive/MyDrive/stanza\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: emoji in /usr/local/lib/python3.10/dist-packages (from stanza==1.7.0) (2.9.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from stanza==1.7.0) (1.23.5)\n",
            "Requirement already satisfied: protobuf>=3.15.0 in /usr/local/lib/python3.10/dist-packages (from stanza==1.7.0) (3.20.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from stanza==1.7.0) (2.31.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from stanza==1.7.0) (3.2.1)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from stanza==1.7.0) (0.10.2)\n",
            "Requirement already satisfied: torch>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from stanza==1.7.0) (2.1.0+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from stanza==1.7.0) (4.66.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza==1.7.0) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza==1.7.0) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza==1.7.0) (1.12)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza==1.7.0) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza==1.7.0) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza==1.7.0) (2.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->stanza==1.7.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->stanza==1.7.0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->stanza==1.7.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->stanza==1.7.0) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.3.0->stanza==1.7.0) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.3.0->stanza==1.7.0) (1.3.0)\n",
            "Installing collected packages: stanza\n",
            "  Attempting uninstall: stanza\n",
            "    Found existing installation: stanza 1.7.0\n",
            "    Uninstalling stanza-1.7.0:\n",
            "      Successfully uninstalled stanza-1.7.0\n",
            "  Running setup.py develop for stanza\n",
            "Successfully installed stanza-1.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/UniversalDependencies/UD_Vietnamese-VTB.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7tPUDHU06XY3",
        "outputId": "7fa957de-98f8-459a-df2d-c5807e366a59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'UD_Vietnamese-VTB'...\n",
            "remote: Enumerating objects: 782, done.\u001b[K\n",
            "remote: Counting objects: 100% (100/100), done.\u001b[K\n",
            "remote: Compressing objects: 100% (67/67), done.\u001b[K\n",
            "remote: Total 782 (delta 57), reused 59 (delta 33), pack-reused 682\u001b[K\n",
            "Receiving objects: 100% (782/782), 20.74 MiB | 11.24 MiB/s, done.\n",
            "Resolving deltas: 100% (425/425), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import stanza"
      ],
      "metadata": {
        "id": "swbM-HVj6rGC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up environment variables for Stanza in Colab\n",
        "import os\n",
        "\n",
        "# Set PYTHONPATH to the home directory of Stanza (replace 'path/to/stanza' with your actual path)\n",
        "os.environ['PYTHONPATH'] = '/content/drive/MyDrive/stanza/stanza'\n",
        "\n",
        "# Set UDBASE to the Universal Dependencies download path (replace 'path/to/ud' with your actual path)\n",
        "os.environ['UDBASE'] = '/content/drive/MyDrive/stanza'\n",
        "\n",
        "# Set TOKENIZE_DATA_DIR to the desired directory for preprocessed datasets\n",
        "os.environ['DEPPARSE_DATA_DIR'] = '/content/drive/MyDrive/DEPPARSE'  # You can change this path as needed\n",
        "\n",
        "# Set STANZA_RESOURCES_DIR to the desired directory for supplemental models\n",
        "os.environ['STANZA_RESOURCES_DIR'] = '/content/drive/MyDrive/stanza_resources'  # You can change this path as needed\n"
      ],
      "metadata": {
        "id": "h5ioUDxE_HBl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m stanza.utils.datasets.prepare_depparse_treebank UD_Vietnamese-VTB --gold"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kbBUxd0T6QbO",
        "outputId": "e75e876a-9129-4f80-9db3-a710b7a3bc53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-12-21 09:28:15 INFO: Datasets program called with:\n",
            "/usr/local/lib/python3.10/dist-packages/stanza/utils/datasets/prepare_depparse_treebank.py UD_Vietnamese-VTB --gold\n",
            "Preparing data for UD_Vietnamese-VTB: vi_vtb, vi\n",
            "Reading from /content/drive/MyDrive/stanza/UD_Vietnamese-VTB/vi_vtb-ud-train.conllu and writing to /tmp/tmp9t56bola/vi_vtb.train.gold.conllu\n",
            "Augmented 20 quotes: Counter({'″″': 4, '„”': 4, '《》': 3, '\"\"': 2, '““': 2, '„“': 1, '「」': 1, '””': 1, '»«': 1, '«»': 1})\n",
            "Swapped 'w1, w2' for 'w1 ,w2' 0 times\n",
            "Added 0 new sentences with asdf, zzzz -> asdf,zzzz\n",
            "Changed 15 sentences to use fancy unicode ellipses\n",
            "Added 4 sentences with parens replaced with square brackets\n",
            "Reading from /content/drive/MyDrive/stanza/UD_Vietnamese-VTB/vi_vtb-ud-dev.conllu and writing to /tmp/tmp9t56bola/vi_vtb.dev.gold.conllu\n",
            "Reading from /content/drive/MyDrive/stanza/UD_Vietnamese-VTB/vi_vtb-ud-test.conllu and writing to /tmp/tmp9t56bola/vi_vtb.test.gold.conllu\n",
            "Copying from /tmp/tmp9t56bola/vi_vtb.train.gold.conllu to /content/drive/MyDrive/DEPPARSE/vi_vtb.train.in.conllu\n",
            "Copying from /tmp/tmp9t56bola/vi_vtb.dev.gold.conllu to /content/drive/MyDrive/DEPPARSE/vi_vtb.dev.in.conllu\n",
            "Copying from /tmp/tmp9t56bola/vi_vtb.test.gold.conllu to /content/drive/MyDrive/DEPPARSE/vi_vtb.test.in.conllu\n",
            "Copying from /content/drive/MyDrive/DEPPARSE/vi_vtb.dev.in.conllu to /content/drive/MyDrive/DEPPARSE/vi_vtb.dev.gold.conllu\n",
            "Copying from /content/drive/MyDrive/DEPPARSE/vi_vtb.test.in.conllu to /content/drive/MyDrive/DEPPARSE/vi_vtb.test.gold.conllu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 -m stanza.utils.training.run_depparse UD_Vietnamese-VTB --force --batch_size 200"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZWd3zXFsBTTi",
        "outputId": "354fecdf-0ec1-4092-f94c-494e3cebf156"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-12-21 09:28:28 INFO: Training program called with:\n",
            "/usr/local/lib/python3.10/dist-packages/stanza/utils/training/run_depparse.py UD_Vietnamese-VTB --force --batch_size 200\n",
            "2023-12-21 09:28:28 DEBUG: UD_Vietnamese-VTB: vi_vtb\n",
            "2023-12-21 09:28:28 INFO: Using model /content/drive/MyDrive/stanza_resources/vi/forward_charlm/conll17.pt for forward charlm\n",
            "2023-12-21 09:28:28 INFO: Using model /content/drive/MyDrive/stanza_resources/vi/backward_charlm/conll17.pt for backward charlm\n",
            "2023-12-21 09:28:28 INFO: Using default pretrain for language, found in /content/drive/MyDrive/stanza_resources/vi/pretrain/conll17.pt  To use a different pretrain, specify --wordvec_pretrain_file\n",
            "2023-12-21 09:28:28 INFO: Running train depparse for UD_Vietnamese-VTB with args ['--wordvec_dir', 'extern_data/wordvec', '--train_file', '/content/drive/MyDrive/DEPPARSE/vi_vtb.train.in.conllu', '--eval_file', '/content/drive/MyDrive/DEPPARSE/vi_vtb.dev.in.conllu', '--output_file', '/tmp/tmp84th40bl', '--gold_file', '/content/drive/MyDrive/DEPPARSE/vi_vtb.dev.gold.conllu', '--batch_size', '5000', '--lang', 'vi', '--shorthand', 'vi_vtb', '--mode', 'train', '--wordvec_pretrain_file', '/content/drive/MyDrive/stanza_resources/vi/pretrain/conll17.pt', '--charlm', '--charlm_shorthand', 'vi_conll17', '--charlm_forward_file', '/content/drive/MyDrive/stanza_resources/vi/forward_charlm/conll17.pt', '--charlm_backward_file', '/content/drive/MyDrive/stanza_resources/vi/backward_charlm/conll17.pt', '--batch_size', '200']\n",
            "2023-12-21 09:28:28 INFO: Running parser in train mode\n",
            "2023-12-21 09:28:28 INFO: Directory saved_models/depparse does not exist; creating...\n",
            "2023-12-21 09:28:28 INFO: Using pretrained contextualized char embedding\n",
            "2023-12-21 09:28:28 INFO: Loading data with batch size 200...\n",
            "2023-12-21 09:28:28 INFO: Original data size: 1404\n",
            "2023-12-21 09:28:28 INFO: Augmented data size: 1536\n",
            "2023-12-21 09:28:29 INFO: Original length = 1536\n",
            "2023-12-21 09:28:29 INFO: Filtered length = 1536\n",
            "2023-12-21 09:28:31 DEBUG: Loaded pretrain from /content/drive/MyDrive/stanza_resources/vi/pretrain/conll17.pt\n",
            "2023-12-21 09:28:32 DEBUG: 122 batches created.\n",
            "2023-12-21 09:28:33 DEBUG: 147 batches created.\n",
            "2023-12-21 09:28:33 INFO: Training parser...\n",
            "2023-12-21 09:28:33 DEBUG: Depparse model loading charmodels: /content/drive/MyDrive/stanza_resources/vi/forward_charlm/conll17.pt and /content/drive/MyDrive/stanza_resources/vi/backward_charlm/conll17.pt\n",
            "2023-12-21 09:28:33 DEBUG: Loading charlm from /content/drive/MyDrive/stanza_resources/vi/forward_charlm/conll17.pt\n",
            "2023-12-21 09:28:34 DEBUG: Loading charlm from /content/drive/MyDrive/stanza_resources/vi/backward_charlm/conll17.pt\n",
            "2023-12-21 09:28:40 INFO: Finished STEP 20/50000, loss = 7.119359 (0.067 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:28:42 INFO: Finished STEP 40/50000, loss = 5.622210 (0.066 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:28:43 INFO: Finished STEP 60/50000, loss = 5.484882 (0.073 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:28:45 INFO: Finished STEP 80/50000, loss = 4.622829 (0.065 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:28:46 INFO: Finished STEP 100/50000, loss = 4.020302 (0.057 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:28:46 INFO: Evaluating on dev set...\n",
            "2023-12-21 09:29:02 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 09:29:02 INFO: 35.62\t29.72\t33.22\n",
            "2023-12-21 09:29:02 INFO: step 100: train_loss = 6.437285, dev_score = 0.3562\n",
            "2023-12-21 09:29:02 INFO: Model saved to saved_models/depparse/vi_vtb_charlm_parser.pt\n",
            "2023-12-21 09:29:02 INFO: new best model saved.\n",
            "2023-12-21 09:29:04 INFO: Finished STEP 120/50000, loss = 2.542401 (0.048 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:29:05 INFO: Finished STEP 140/50000, loss = 4.657547 (0.066 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:29:06 INFO: Finished STEP 160/50000, loss = 3.242100 (0.054 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:29:08 INFO: Finished STEP 180/50000, loss = 4.291184 (0.067 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:29:09 INFO: Finished STEP 200/50000, loss = 2.692072 (0.052 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:29:09 INFO: Evaluating on dev set...\n",
            "2023-12-21 09:29:21 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 09:29:21 INFO: 40.77\t34.04\t37.10\n",
            "2023-12-21 09:29:21 INFO: step 200: train_loss = 4.212509, dev_score = 0.4077\n",
            "2023-12-21 09:29:21 INFO: Model saved to saved_models/depparse/vi_vtb_charlm_parser.pt\n",
            "2023-12-21 09:29:21 INFO: new best model saved.\n",
            "2023-12-21 09:29:23 INFO: Finished STEP 220/50000, loss = 4.769815 (0.072 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:29:24 INFO: Finished STEP 240/50000, loss = 4.794784 (0.068 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:29:26 INFO: Finished STEP 260/50000, loss = 4.345324 (0.079 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:29:27 INFO: Finished STEP 280/50000, loss = 2.427358 (0.048 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:29:28 INFO: Finished STEP 300/50000, loss = 4.086183 (0.067 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:29:28 INFO: Evaluating on dev set...\n",
            "2023-12-21 09:29:40 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 09:29:40 INFO: 46.25\t38.65\t41.24\n",
            "2023-12-21 09:29:40 INFO: step 300: train_loss = 3.962506, dev_score = 0.4625\n",
            "2023-12-21 09:29:40 INFO: Model saved to saved_models/depparse/vi_vtb_charlm_parser.pt\n",
            "2023-12-21 09:29:40 INFO: new best model saved.\n",
            "2023-12-21 09:29:42 INFO: Finished STEP 320/50000, loss = 4.218383 (0.072 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:29:43 INFO: Finished STEP 340/50000, loss = 3.666411 (0.060 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:29:45 INFO: Finished STEP 360/50000, loss = 3.173778 (0.066 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:29:46 INFO: Finished STEP 380/50000, loss = 4.060308 (0.072 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:29:47 INFO: Finished STEP 400/50000, loss = 4.295113 (0.073 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:29:47 INFO: Evaluating on dev set...\n",
            "2023-12-21 09:29:59 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 09:29:59 INFO: 47.77\t39.59\t42.48\n",
            "2023-12-21 09:29:59 INFO: step 400: train_loss = 3.772906, dev_score = 0.4777\n",
            "2023-12-21 09:29:59 INFO: Model saved to saved_models/depparse/vi_vtb_charlm_parser.pt\n",
            "2023-12-21 09:29:59 INFO: new best model saved.\n",
            "2023-12-21 09:30:01 INFO: Finished STEP 420/50000, loss = 3.962310 (0.070 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:30:02 INFO: Finished STEP 440/50000, loss = 2.717696 (0.058 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:30:04 INFO: Finished STEP 460/50000, loss = 4.554776 (0.079 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:30:05 INFO: Finished STEP 480/50000, loss = 2.750847 (0.054 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:30:06 INFO: Finished STEP 500/50000, loss = 3.402763 (0.065 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:30:06 INFO: Evaluating on dev set...\n",
            "2023-12-21 09:30:18 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 09:30:18 INFO: 49.87\t44.06\t46.56\n",
            "2023-12-21 09:30:18 INFO: step 500: train_loss = 3.401459, dev_score = 0.4987\n",
            "2023-12-21 09:30:18 INFO: Model saved to saved_models/depparse/vi_vtb_charlm_parser.pt\n",
            "2023-12-21 09:30:18 INFO: new best model saved.\n",
            "2023-12-21 09:30:20 INFO: Finished STEP 520/50000, loss = 2.205717 (0.054 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:30:21 INFO: Finished STEP 540/50000, loss = 2.572999 (0.046 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:30:23 INFO: Finished STEP 560/50000, loss = 3.133915 (0.066 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:30:24 INFO: Finished STEP 580/50000, loss = 4.079622 (0.070 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:30:26 INFO: Finished STEP 600/50000, loss = 2.767972 (0.057 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:30:26 INFO: Evaluating on dev set...\n",
            "2023-12-21 09:30:38 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 09:30:38 INFO: 51.40\t44.57\t46.71\n",
            "2023-12-21 09:30:38 INFO: step 600: train_loss = 3.427563, dev_score = 0.5140\n",
            "2023-12-21 09:30:38 INFO: Model saved to saved_models/depparse/vi_vtb_charlm_parser.pt\n",
            "2023-12-21 09:30:38 INFO: new best model saved.\n",
            "2023-12-21 09:30:40 INFO: Finished STEP 620/50000, loss = 3.996591 (0.069 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:30:41 INFO: Finished STEP 640/50000, loss = 2.235958 (0.053 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:30:43 INFO: Finished STEP 660/50000, loss = 3.444367 (0.065 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:30:44 INFO: Finished STEP 680/50000, loss = 3.716242 (0.069 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:30:45 INFO: Finished STEP 700/50000, loss = 3.804213 (0.066 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:30:45 INFO: Evaluating on dev set...\n",
            "2023-12-21 09:30:58 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 09:30:58 INFO: 51.35\t46.02\t48.37\n",
            "2023-12-21 09:30:58 INFO: step 700: train_loss = 3.340397, dev_score = 0.5135\n",
            "2023-12-21 09:30:59 INFO: Finished STEP 720/50000, loss = 2.314040 (0.054 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:31:01 INFO: Finished STEP 740/50000, loss = 2.649423 (0.054 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:31:02 INFO: Finished STEP 760/50000, loss = 4.057618 (0.074 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:31:04 INFO: Finished STEP 780/50000, loss = 3.003918 (0.070 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:31:05 INFO: Finished STEP 800/50000, loss = 4.194160 (0.075 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:31:05 INFO: Evaluating on dev set...\n",
            "2023-12-21 09:31:19 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 09:31:19 INFO: 53.73\t46.68\t48.75\n",
            "2023-12-21 09:31:19 INFO: step 800: train_loss = 3.317864, dev_score = 0.5373\n",
            "2023-12-21 09:31:19 INFO: Model saved to saved_models/depparse/vi_vtb_charlm_parser.pt\n",
            "2023-12-21 09:31:19 INFO: new best model saved.\n",
            "2023-12-21 09:31:21 INFO: Finished STEP 820/50000, loss = 3.511115 (0.077 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:31:22 INFO: Finished STEP 840/50000, loss = 2.943477 (0.067 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:31:24 INFO: Finished STEP 860/50000, loss = 2.355497 (0.053 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:31:25 INFO: Finished STEP 880/50000, loss = 3.373525 (0.074 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:31:27 INFO: Finished STEP 900/50000, loss = 3.032167 (0.058 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:31:27 INFO: Evaluating on dev set...\n",
            "2023-12-21 09:31:39 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 09:31:39 INFO: 53.49\t47.16\t49.27\n",
            "2023-12-21 09:31:39 INFO: step 900: train_loss = 3.191998, dev_score = 0.5349\n",
            "2023-12-21 09:31:41 INFO: Finished STEP 920/50000, loss = 3.835137 (0.075 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:31:42 INFO: Finished STEP 940/50000, loss = 3.899664 (0.071 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:31:44 INFO: Finished STEP 960/50000, loss = 3.331515 (0.073 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:31:45 INFO: Finished STEP 980/50000, loss = 3.141528 (0.067 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:31:46 INFO: Finished STEP 1000/50000, loss = 3.918723 (0.069 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:31:46 INFO: Evaluating on dev set...\n",
            "2023-12-21 09:32:00 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 09:32:00 INFO: 52.87\t45.68\t47.44\n",
            "2023-12-21 09:32:00 INFO: step 1000: train_loss = 3.189781, dev_score = 0.5287\n",
            "2023-12-21 09:32:01 INFO: Finished STEP 1020/50000, loss = 3.414425 (0.087 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:32:03 INFO: Finished STEP 1040/50000, loss = 3.434184 (0.077 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:32:04 INFO: Finished STEP 1060/50000, loss = 2.954803 (0.061 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:32:06 INFO: Finished STEP 1080/50000, loss = 2.374608 (0.061 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:32:07 INFO: Finished STEP 1100/50000, loss = 3.057219 (0.064 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:32:07 INFO: Evaluating on dev set...\n",
            "2023-12-21 09:32:20 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 09:32:20 INFO: 52.54\t46.51\t48.68\n",
            "2023-12-21 09:32:20 INFO: step 1100: train_loss = 3.224835, dev_score = 0.5254\n",
            "2023-12-21 09:32:22 INFO: Finished STEP 1120/50000, loss = 3.271522 (0.068 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:32:23 INFO: Finished STEP 1140/50000, loss = 2.595445 (0.070 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:32:24 INFO: Finished STEP 1160/50000, loss = 3.278097 (0.072 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:32:26 INFO: Finished STEP 1180/50000, loss = 2.464210 (0.051 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:32:27 INFO: Finished STEP 1200/50000, loss = 2.551778 (0.056 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:32:27 INFO: Evaluating on dev set...\n",
            "2023-12-21 09:32:40 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 09:32:40 INFO: 54.22\t47.41\t49.21\n",
            "2023-12-21 09:32:40 INFO: step 1200: train_loss = 3.104428, dev_score = 0.5422\n",
            "2023-12-21 09:32:40 INFO: Model saved to saved_models/depparse/vi_vtb_charlm_parser.pt\n",
            "2023-12-21 09:32:40 INFO: new best model saved.\n",
            "2023-12-21 09:32:42 INFO: Finished STEP 1220/50000, loss = 2.922527 (0.067 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:32:43 INFO: Finished STEP 1240/50000, loss = 3.223473 (0.068 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:32:44 INFO: Finished STEP 1260/50000, loss = 3.448351 (0.070 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:32:46 INFO: Finished STEP 1280/50000, loss = 3.878959 (0.067 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:32:48 INFO: Finished STEP 1300/50000, loss = 3.496140 (0.075 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:32:48 INFO: Evaluating on dev set...\n",
            "2023-12-21 09:32:59 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 09:32:59 INFO: 54.81\t48.95\t51.35\n",
            "2023-12-21 09:32:59 INFO: step 1300: train_loss = 3.038392, dev_score = 0.5481\n",
            "2023-12-21 09:32:59 INFO: Model saved to saved_models/depparse/vi_vtb_charlm_parser.pt\n",
            "2023-12-21 09:32:59 INFO: new best model saved.\n",
            "2023-12-21 09:33:01 INFO: Finished STEP 1320/50000, loss = 3.148085 (0.081 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:33:03 INFO: Finished STEP 1340/50000, loss = 3.470073 (0.072 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:33:04 INFO: Finished STEP 1360/50000, loss = 3.361330 (0.063 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:33:05 INFO: Finished STEP 1380/50000, loss = 2.500641 (0.081 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:33:07 INFO: Finished STEP 1400/50000, loss = 3.111171 (0.070 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:33:07 INFO: Evaluating on dev set...\n",
            "2023-12-21 09:33:19 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 09:33:19 INFO: 55.20\t48.12\t49.93\n",
            "2023-12-21 09:33:19 INFO: step 1400: train_loss = 2.962767, dev_score = 0.5520\n",
            "2023-12-21 09:33:19 INFO: Model saved to saved_models/depparse/vi_vtb_charlm_parser.pt\n",
            "2023-12-21 09:33:19 INFO: new best model saved.\n",
            "2023-12-21 09:33:21 INFO: Finished STEP 1420/50000, loss = 3.190470 (0.073 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:33:22 INFO: Finished STEP 1440/50000, loss = 2.619059 (0.065 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:33:24 INFO: Finished STEP 1460/50000, loss = 2.989581 (0.064 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:33:25 INFO: Finished STEP 1480/50000, loss = 2.477812 (0.056 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:33:27 INFO: Finished STEP 1500/50000, loss = 3.451975 (0.066 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:33:27 INFO: Evaluating on dev set...\n",
            "2023-12-21 09:33:39 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 09:33:39 INFO: 56.82\t50.04\t51.82\n",
            "2023-12-21 09:33:39 INFO: step 1500: train_loss = 3.029510, dev_score = 0.5682\n",
            "2023-12-21 09:33:40 INFO: Model saved to saved_models/depparse/vi_vtb_charlm_parser.pt\n",
            "2023-12-21 09:33:40 INFO: new best model saved.\n",
            "2023-12-21 09:33:41 INFO: Finished STEP 1520/50000, loss = 2.970526 (0.071 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:33:43 INFO: Finished STEP 1540/50000, loss = 3.832914 (0.075 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:33:44 INFO: Finished STEP 1560/50000, loss = 3.154813 (0.064 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:33:46 INFO: Finished STEP 1580/50000, loss = 3.811974 (0.074 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:33:47 INFO: Finished STEP 1600/50000, loss = 2.454531 (0.067 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:33:47 INFO: Evaluating on dev set...\n",
            "2023-12-21 09:33:58 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 09:33:58 INFO: 54.77\t48.17\t50.15\n",
            "2023-12-21 09:33:58 INFO: step 1600: train_loss = 3.099987, dev_score = 0.5477\n",
            "2023-12-21 09:34:00 INFO: Finished STEP 1620/50000, loss = 2.823643 (0.078 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:34:01 INFO: Finished STEP 1640/50000, loss = 3.173384 (0.065 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:34:03 INFO: Finished STEP 1660/50000, loss = 2.587825 (0.063 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:34:04 INFO: Finished STEP 1680/50000, loss = 3.169866 (0.071 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:34:06 INFO: Finished STEP 1700/50000, loss = 3.020272 (0.068 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:34:06 INFO: Evaluating on dev set...\n",
            "2023-12-21 09:34:18 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 09:34:18 INFO: 55.96\t50.11\t51.79\n",
            "2023-12-21 09:34:18 INFO: step 1700: train_loss = 3.048905, dev_score = 0.5596\n",
            "2023-12-21 09:34:20 INFO: Finished STEP 1720/50000, loss = 3.077353 (0.073 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:34:21 INFO: Finished STEP 1740/50000, loss = 2.910601 (0.074 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:34:23 INFO: Finished STEP 1760/50000, loss = 3.816926 (0.071 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:34:24 INFO: Finished STEP 1780/50000, loss = 2.944107 (0.073 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:34:25 INFO: Finished STEP 1800/50000, loss = 2.670696 (0.062 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:34:25 INFO: Evaluating on dev set...\n",
            "2023-12-21 09:34:37 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 09:34:37 INFO: 56.36\t50.40\t52.06\n",
            "2023-12-21 09:34:37 INFO: step 1800: train_loss = 2.973777, dev_score = 0.5636\n",
            "2023-12-21 09:34:38 INFO: Finished STEP 1820/50000, loss = 2.595575 (0.056 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:34:40 INFO: Finished STEP 1840/50000, loss = 2.398901 (0.053 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:34:41 INFO: Finished STEP 1860/50000, loss = 2.031198 (0.044 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:34:43 INFO: Finished STEP 1880/50000, loss = 2.913218 (0.069 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:34:44 INFO: Finished STEP 1900/50000, loss = 3.293877 (0.078 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:34:44 INFO: Evaluating on dev set...\n",
            "2023-12-21 09:34:56 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 09:34:56 INFO: 54.87\t49.78\t51.62\n",
            "2023-12-21 09:34:56 INFO: step 1900: train_loss = 2.936512, dev_score = 0.5487\n",
            "2023-12-21 09:34:57 INFO: Finished STEP 1920/50000, loss = 1.980951 (0.053 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:34:59 INFO: Finished STEP 1940/50000, loss = 2.661705 (0.064 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:35:00 INFO: Finished STEP 1960/50000, loss = 2.286441 (0.054 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:35:02 INFO: Finished STEP 1980/50000, loss = 3.175623 (0.062 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:35:03 INFO: Finished STEP 2000/50000, loss = 3.995293 (0.078 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:35:03 INFO: Evaluating on dev set...\n",
            "2023-12-21 09:35:15 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 09:35:15 INFO: 56.62\t50.79\t52.63\n",
            "2023-12-21 09:35:15 INFO: step 2000: train_loss = 2.986132, dev_score = 0.5662\n",
            "2023-12-21 09:35:17 INFO: Finished STEP 2020/50000, loss = 2.307700 (0.057 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:35:18 INFO: Finished STEP 2040/50000, loss = 2.727500 (0.077 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:35:20 INFO: Finished STEP 2060/50000, loss = 2.232342 (0.064 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:35:21 INFO: Finished STEP 2080/50000, loss = 3.211496 (0.073 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:35:23 INFO: Finished STEP 2100/50000, loss = 2.587581 (0.064 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:35:23 INFO: Evaluating on dev set...\n",
            "2023-12-21 09:35:34 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 09:35:34 INFO: 54.54\t48.51\t50.32\n",
            "2023-12-21 09:35:34 INFO: step 2100: train_loss = 2.957906, dev_score = 0.5454\n",
            "2023-12-21 09:35:36 INFO: Finished STEP 2120/50000, loss = 2.917161 (0.076 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:35:37 INFO: Finished STEP 2140/50000, loss = 3.676241 (0.073 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:35:39 INFO: Finished STEP 2160/50000, loss = 3.100787 (0.077 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:35:40 INFO: Finished STEP 2180/50000, loss = 3.257625 (0.077 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:35:41 INFO: Finished STEP 2200/50000, loss = 2.976552 (0.062 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:35:41 INFO: Evaluating on dev set...\n",
            "2023-12-21 09:35:53 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 09:35:53 INFO: 54.51\t48.34\t50.04\n",
            "2023-12-21 09:35:53 INFO: step 2200: train_loss = 3.010230, dev_score = 0.5451\n",
            "2023-12-21 09:35:55 INFO: Finished STEP 2220/50000, loss = 2.498125 (0.063 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:35:56 INFO: Finished STEP 2240/50000, loss = 3.242513 (0.076 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:35:58 INFO: Finished STEP 2260/50000, loss = 3.622918 (0.075 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:35:59 INFO: Finished STEP 2280/50000, loss = 3.563899 (0.074 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:36:01 INFO: Finished STEP 2300/50000, loss = 1.643115 (0.050 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:36:01 INFO: Evaluating on dev set...\n",
            "2023-12-21 09:36:13 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 09:36:13 INFO: 56.07\t49.18\t51.15\n",
            "2023-12-21 09:36:13 INFO: step 2300: train_loss = 2.969137, dev_score = 0.5607\n",
            "2023-12-21 09:36:14 INFO: Finished STEP 2320/50000, loss = 3.282967 (0.069 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:36:16 INFO: Finished STEP 2340/50000, loss = 3.952128 (0.072 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:36:17 INFO: Finished STEP 2360/50000, loss = 3.413566 (0.073 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:36:18 INFO: Finished STEP 2380/50000, loss = 1.826061 (0.058 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:36:20 INFO: Finished STEP 2400/50000, loss = 3.433920 (0.079 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:36:20 INFO: Evaluating on dev set...\n",
            "2023-12-21 09:36:32 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 09:36:32 INFO: 54.54\t49.05\t50.59\n",
            "2023-12-21 09:36:32 INFO: step 2400: train_loss = 2.937960, dev_score = 0.5454\n",
            "2023-12-21 09:36:33 INFO: Finished STEP 2420/50000, loss = 3.479366 (0.072 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:36:35 INFO: Finished STEP 2440/50000, loss = 2.435577 (0.055 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:36:36 INFO: Finished STEP 2460/50000, loss = 3.053658 (0.072 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:36:38 INFO: Finished STEP 2480/50000, loss = 3.154743 (0.073 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:36:39 INFO: Finished STEP 2500/50000, loss = 2.912336 (0.064 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:36:39 INFO: Evaluating on dev set...\n",
            "2023-12-21 09:36:51 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 09:36:51 INFO: 54.66\t48.64\t50.53\n",
            "2023-12-21 09:36:51 INFO: step 2500: train_loss = 2.940323, dev_score = 0.5466\n",
            "2023-12-21 09:36:52 INFO: Finished STEP 2520/50000, loss = 3.506043 (0.071 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:36:54 INFO: Finished STEP 2540/50000, loss = 3.076447 (0.074 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:36:55 INFO: Finished STEP 2560/50000, loss = 3.336295 (0.071 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:36:57 INFO: Finished STEP 2580/50000, loss = 3.117475 (0.070 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:36:58 INFO: Finished STEP 2600/50000, loss = 3.654313 (0.072 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:36:58 INFO: Evaluating on dev set...\n",
            "2023-12-21 09:37:11 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 09:37:11 INFO: 55.95\t49.60\t51.68\n",
            "2023-12-21 09:37:11 INFO: step 2600: train_loss = 2.961353, dev_score = 0.5595\n",
            "2023-12-21 09:37:13 INFO: Finished STEP 2620/50000, loss = 3.013545 (0.081 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:37:14 INFO: Finished STEP 2640/50000, loss = 1.879372 (0.053 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:37:15 INFO: Finished STEP 2660/50000, loss = 1.902851 (0.053 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:37:17 INFO: Finished STEP 2680/50000, loss = 3.030894 (0.075 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:37:18 INFO: Finished STEP 2700/50000, loss = 3.318523 (0.078 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:37:18 INFO: Evaluating on dev set...\n",
            "2023-12-21 09:37:30 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 09:37:30 INFO: 55.64\t50.00\t51.76\n",
            "2023-12-21 09:37:30 INFO: step 2700: train_loss = 2.933834, dev_score = 0.5564\n",
            "2023-12-21 09:37:32 INFO: Finished STEP 2720/50000, loss = 1.959102 (0.059 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:37:33 INFO: Finished STEP 2740/50000, loss = 2.778493 (0.073 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:37:35 INFO: Finished STEP 2760/50000, loss = 3.500841 (0.070 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:37:36 INFO: Finished STEP 2780/50000, loss = 3.472106 (0.079 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:37:38 INFO: Finished STEP 2800/50000, loss = 3.318814 (0.078 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:37:38 INFO: Evaluating on dev set...\n",
            "2023-12-21 09:37:49 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 09:37:49 INFO: 54.77\t48.48\t50.47\n",
            "2023-12-21 09:37:49 INFO: step 2800: train_loss = 2.888196, dev_score = 0.5477\n",
            "2023-12-21 09:37:51 INFO: Finished STEP 2820/50000, loss = 3.253654 (0.069 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:37:53 INFO: Finished STEP 2840/50000, loss = 1.744887 (0.056 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:37:54 INFO: Finished STEP 2860/50000, loss = 2.760867 (0.068 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:37:55 INFO: Finished STEP 2880/50000, loss = 3.117360 (0.072 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:37:57 INFO: Finished STEP 2900/50000, loss = 3.612769 (0.075 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:37:57 INFO: Evaluating on dev set...\n",
            "2023-12-21 09:38:09 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 09:38:09 INFO: 55.74\t49.45\t51.56\n",
            "2023-12-21 09:38:09 INFO: step 2900: train_loss = 2.942295, dev_score = 0.5574\n",
            "2023-12-21 09:38:11 INFO: Finished STEP 2920/50000, loss = 2.572223 (0.065 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:38:12 INFO: Finished STEP 2940/50000, loss = 3.693805 (0.077 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:38:14 INFO: Finished STEP 2960/50000, loss = 3.582317 (0.076 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:38:15 INFO: Finished STEP 2980/50000, loss = 3.222100 (0.078 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:38:17 INFO: Finished STEP 3000/50000, loss = 3.434161 (0.071 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:38:17 INFO: Evaluating on dev set...\n",
            "2023-12-21 09:38:29 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 09:38:29 INFO: 56.33\t49.74\t51.77\n",
            "2023-12-21 09:38:29 INFO: step 3000: train_loss = 2.886346, dev_score = 0.5633\n",
            "2023-12-21 09:38:30 INFO: Finished STEP 3020/50000, loss = 2.857428 (0.063 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:38:32 INFO: Finished STEP 3040/50000, loss = 3.492802 (0.075 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:38:33 INFO: Finished STEP 3060/50000, loss = 2.659122 (0.060 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:38:35 INFO: Finished STEP 3080/50000, loss = 2.818970 (0.078 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:38:37 INFO: Finished STEP 3100/50000, loss = 3.596489 (0.069 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:38:37 INFO: Evaluating on dev set...\n",
            "2023-12-21 09:38:48 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 09:38:48 INFO: 55.41\t49.96\t51.93\n",
            "2023-12-21 09:38:48 INFO: step 3100: train_loss = 2.960410, dev_score = 0.5541\n",
            "2023-12-21 09:38:50 INFO: Finished STEP 3120/50000, loss = 3.210240 (0.073 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:38:51 INFO: Finished STEP 3140/50000, loss = 2.655156 (0.066 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:38:53 INFO: Finished STEP 3160/50000, loss = 1.908737 (0.055 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:38:54 INFO: Finished STEP 3180/50000, loss = 3.002125 (0.074 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:38:56 INFO: Finished STEP 3200/50000, loss = 3.447670 (0.075 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:38:56 INFO: Evaluating on dev set...\n",
            "2023-12-21 09:39:08 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 09:39:08 INFO: 55.50\t49.13\t51.26\n",
            "2023-12-21 09:39:08 INFO: step 3200: train_loss = 2.935495, dev_score = 0.5550\n",
            "2023-12-21 09:39:10 INFO: Finished STEP 3220/50000, loss = 1.687738 (0.054 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:39:11 INFO: Finished STEP 3240/50000, loss = 1.945159 (0.052 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:39:12 INFO: Finished STEP 3260/50000, loss = 3.895130 (0.074 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:39:14 INFO: Finished STEP 3280/50000, loss = 2.316230 (0.060 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:39:15 INFO: Finished STEP 3300/50000, loss = 3.130776 (0.082 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:39:15 INFO: Evaluating on dev set...\n",
            "2023-12-21 09:39:27 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 09:39:27 INFO: 56.11\t49.78\t51.79\n",
            "2023-12-21 09:39:27 INFO: step 3300: train_loss = 2.876816, dev_score = 0.5611\n",
            "2023-12-21 09:39:28 INFO: Finished STEP 3320/50000, loss = 3.071812 (0.070 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:39:30 INFO: Finished STEP 3340/50000, loss = 1.654036 (0.047 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:39:31 INFO: Finished STEP 3360/50000, loss = 3.720683 (0.079 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:39:33 INFO: Finished STEP 3380/50000, loss = 2.812363 (0.077 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:39:34 INFO: Finished STEP 3400/50000, loss = 2.987482 (0.069 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:39:34 INFO: Evaluating on dev set...\n",
            "2023-12-21 09:39:46 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 09:39:46 INFO: 55.37\t47.69\t50.06\n",
            "2023-12-21 09:39:46 INFO: step 3400: train_loss = 2.905514, dev_score = 0.5537\n",
            "2023-12-21 09:39:48 INFO: Finished STEP 3420/50000, loss = 2.924338 (0.073 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:39:49 INFO: Finished STEP 3440/50000, loss = 3.345943 (0.063 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:39:50 INFO: Finished STEP 3460/50000, loss = 2.276536 (0.058 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:39:52 INFO: Finished STEP 3480/50000, loss = 3.525912 (0.079 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:39:53 INFO: Finished STEP 3500/50000, loss = 3.477591 (0.073 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:39:53 INFO: Evaluating on dev set...\n",
            "2023-12-21 09:40:06 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 09:40:06 INFO: 55.06\t48.59\t50.91\n",
            "2023-12-21 09:40:06 INFO: step 3500: train_loss = 2.891550, dev_score = 0.5506\n",
            "2023-12-21 09:40:08 INFO: Finished STEP 3520/50000, loss = 3.381889 (0.075 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:40:09 INFO: Finished STEP 3540/50000, loss = 3.381397 (0.077 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:40:11 INFO: Finished STEP 3560/50000, loss = 2.920471 (0.079 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:40:12 INFO: Finished STEP 3580/50000, loss = 3.391478 (0.066 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:40:13 INFO: Finished STEP 3600/50000, loss = 1.923787 (0.055 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:40:13 INFO: Evaluating on dev set...\n",
            "2023-12-21 09:40:26 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 09:40:26 INFO: 53.66\t47.43\t49.55\n",
            "2023-12-21 09:40:26 INFO: step 3600: train_loss = 2.893569, dev_score = 0.5366\n",
            "2023-12-21 09:40:27 INFO: Finished STEP 3620/50000, loss = 2.957186 (0.077 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:40:29 INFO: Finished STEP 3640/50000, loss = 2.621888 (0.063 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:40:30 INFO: Finished STEP 3660/50000, loss = 2.802574 (0.073 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:40:32 INFO: Finished STEP 3680/50000, loss = 2.794715 (0.060 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:40:33 INFO: Finished STEP 3700/50000, loss = 2.925739 (0.069 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:40:33 INFO: Evaluating on dev set...\n",
            "2023-12-21 09:40:47 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 09:40:47 INFO: 55.86\t49.27\t51.33\n",
            "2023-12-21 09:40:47 INFO: step 3700: train_loss = 2.898331, dev_score = 0.5586\n",
            "2023-12-21 09:40:48 INFO: Finished STEP 3720/50000, loss = 3.147268 (0.072 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:40:50 INFO: Finished STEP 3740/50000, loss = 3.503041 (0.077 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:40:51 INFO: Finished STEP 3760/50000, loss = 3.313187 (0.077 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:40:52 INFO: Finished STEP 3780/50000, loss = 2.402359 (0.055 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:40:54 INFO: Finished STEP 3800/50000, loss = 3.378973 (0.084 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:40:54 INFO: Evaluating on dev set...\n",
            "2023-12-21 09:41:06 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 09:41:06 INFO: 56.73\t50.12\t52.11\n",
            "2023-12-21 09:41:06 INFO: step 3800: train_loss = 2.932287, dev_score = 0.5673\n",
            "2023-12-21 09:41:07 INFO: Finished STEP 3820/50000, loss = 2.667048 (0.062 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:41:09 INFO: Finished STEP 3840/50000, loss = 3.597613 (0.075 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:41:10 INFO: Finished STEP 3860/50000, loss = 2.979270 (0.071 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:41:11 INFO: Finished STEP 3880/50000, loss = 2.355374 (0.056 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:41:13 INFO: Finished STEP 3900/50000, loss = 3.450593 (0.075 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:41:13 INFO: Evaluating on dev set...\n",
            "2023-12-21 09:41:25 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 09:41:25 INFO: 53.83\t48.00\t49.73\n",
            "2023-12-21 09:41:25 INFO: step 3900: train_loss = 2.879834, dev_score = 0.5383\n",
            "2023-12-21 09:41:27 INFO: Finished STEP 3920/50000, loss = 2.603976 (0.065 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:41:28 INFO: Finished STEP 3940/50000, loss = 1.936131 (0.054 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:41:29 INFO: Finished STEP 3960/50000, loss = 2.308925 (0.057 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:41:31 INFO: Finished STEP 3980/50000, loss = 2.202580 (0.058 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:41:33 INFO: Finished STEP 4000/50000, loss = 2.971459 (0.069 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:41:33 INFO: Evaluating on dev set...\n",
            "2023-12-21 09:41:45 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 09:41:45 INFO: 55.67\t48.96\t51.07\n",
            "2023-12-21 09:41:45 INFO: step 4000: train_loss = 2.841214, dev_score = 0.5567\n",
            "2023-12-21 09:41:47 INFO: Finished STEP 4020/50000, loss = 3.769487 (0.071 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:41:48 INFO: Finished STEP 4040/50000, loss = 3.440618 (0.068 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:41:49 INFO: Finished STEP 4060/50000, loss = 3.600950 (0.073 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:41:51 INFO: Finished STEP 4080/50000, loss = 3.324787 (0.080 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:41:52 INFO: Finished STEP 4100/50000, loss = 2.912360 (0.078 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:41:52 INFO: Evaluating on dev set...\n",
            "2023-12-21 09:42:04 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 09:42:04 INFO: 53.87\t48.02\t49.94\n",
            "2023-12-21 09:42:04 INFO: step 4100: train_loss = 2.970152, dev_score = 0.5387\n",
            "2023-12-21 09:42:05 INFO: Finished STEP 4120/50000, loss = 2.939753 (0.070 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:42:06 INFO: Finished STEP 4140/50000, loss = 2.099544 (0.054 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:42:08 INFO: Finished STEP 4160/50000, loss = 3.384731 (0.069 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:42:09 INFO: Finished STEP 4180/50000, loss = 3.458980 (0.074 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:42:11 INFO: Finished STEP 4200/50000, loss = 3.440565 (0.076 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:42:11 INFO: Evaluating on dev set...\n",
            "2023-12-21 09:42:23 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 09:42:23 INFO: 57.08\t50.91\t53.13\n",
            "2023-12-21 09:42:23 INFO: step 4200: train_loss = 2.835457, dev_score = 0.5708\n",
            "2023-12-21 09:42:23 INFO: Model saved to saved_models/depparse/vi_vtb_charlm_parser.pt\n",
            "2023-12-21 09:42:23 INFO: new best model saved.\n",
            "2023-12-21 09:42:25 INFO: Finished STEP 4220/50000, loss = 3.323799 (0.082 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:42:27 INFO: Finished STEP 4240/50000, loss = 3.399769 (0.090 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:42:28 INFO: Finished STEP 4260/50000, loss = 3.280182 (0.076 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:42:29 INFO: Finished STEP 4280/50000, loss = 2.663271 (0.065 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:42:31 INFO: Finished STEP 4300/50000, loss = 3.025564 (0.064 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:42:31 INFO: Evaluating on dev set...\n",
            "2023-12-21 09:42:44 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 09:42:44 INFO: 55.56\t49.11\t51.32\n",
            "2023-12-21 09:42:44 INFO: step 4300: train_loss = 2.900751, dev_score = 0.5556\n",
            "2023-12-21 09:42:45 INFO: Finished STEP 4320/50000, loss = 3.607835 (0.083 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:42:47 INFO: Finished STEP 4340/50000, loss = 2.928047 (0.074 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:42:48 INFO: Finished STEP 4360/50000, loss = 1.954705 (0.061 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:42:50 INFO: Finished STEP 4380/50000, loss = 3.319777 (0.072 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:42:51 INFO: Finished STEP 4400/50000, loss = 3.717882 (0.077 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:42:51 INFO: Evaluating on dev set...\n",
            "2023-12-21 09:43:03 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 09:43:03 INFO: 54.82\t47.74\t49.87\n",
            "2023-12-21 09:43:03 INFO: step 4400: train_loss = 2.916446, dev_score = 0.5482\n",
            "2023-12-21 09:43:04 INFO: Finished STEP 4420/50000, loss = 3.120208 (0.079 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:43:06 INFO: Finished STEP 4440/50000, loss = 2.589139 (0.060 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:43:07 INFO: Finished STEP 4460/50000, loss = 3.273851 (0.075 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:43:09 INFO: Finished STEP 4480/50000, loss = 2.435291 (0.068 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:43:10 INFO: Finished STEP 4500/50000, loss = 2.467792 (0.066 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:43:10 INFO: Evaluating on dev set...\n",
            "2023-12-21 09:43:22 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 09:43:22 INFO: 56.52\t50.00\t52.05\n",
            "2023-12-21 09:43:22 INFO: step 4500: train_loss = 2.871721, dev_score = 0.5652\n",
            "2023-12-21 09:43:24 INFO: Finished STEP 4520/50000, loss = 3.521446 (0.076 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:43:25 INFO: Finished STEP 4540/50000, loss = 3.601251 (0.074 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:43:27 INFO: Finished STEP 4560/50000, loss = 2.811932 (0.071 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:43:28 INFO: Finished STEP 4580/50000, loss = 3.754444 (0.073 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:43:29 INFO: Finished STEP 4600/50000, loss = 0.790408 (0.044 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:43:29 INFO: Evaluating on dev set...\n",
            "2023-12-21 09:43:42 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 09:43:42 INFO: 55.83\t49.55\t51.68\n",
            "2023-12-21 09:43:42 INFO: step 4600: train_loss = 2.828285, dev_score = 0.5583\n",
            "2023-12-21 09:43:44 INFO: Finished STEP 4620/50000, loss = 3.592416 (0.075 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:43:45 INFO: Finished STEP 4640/50000, loss = 3.018493 (0.067 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:43:47 INFO: Finished STEP 4660/50000, loss = 2.356768 (0.063 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:43:48 INFO: Finished STEP 4680/50000, loss = 2.422475 (0.061 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:43:49 INFO: Finished STEP 4700/50000, loss = 3.560489 (0.073 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:43:49 INFO: Evaluating on dev set...\n",
            "2023-12-21 09:44:02 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 09:44:02 INFO: 54.58\t48.62\t50.73\n",
            "2023-12-21 09:44:02 INFO: step 4700: train_loss = 2.852966, dev_score = 0.5458\n",
            "2023-12-21 09:44:03 INFO: Finished STEP 4720/50000, loss = 3.149074 (0.066 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:44:05 INFO: Finished STEP 4740/50000, loss = 1.992248 (0.061 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:44:06 INFO: Finished STEP 4760/50000, loss = 2.726117 (0.067 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:44:08 INFO: Finished STEP 4780/50000, loss = 3.636259 (0.071 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:44:09 INFO: Finished STEP 4800/50000, loss = 2.547118 (0.059 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:44:09 INFO: Evaluating on dev set...\n",
            "2023-12-21 09:44:21 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 09:44:21 INFO: 55.99\t48.99\t51.16\n",
            "2023-12-21 09:44:21 INFO: step 4800: train_loss = 2.870709, dev_score = 0.5599\n",
            "2023-12-21 09:44:22 INFO: Finished STEP 4820/50000, loss = 3.526788 (0.075 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:44:24 INFO: Finished STEP 4840/50000, loss = 3.300323 (0.078 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:44:25 INFO: Finished STEP 4860/50000, loss = 3.551725 (0.066 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:44:27 INFO: Finished STEP 4880/50000, loss = 3.000702 (0.073 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:44:28 INFO: Finished STEP 4900/50000, loss = 2.705458 (0.067 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:44:28 INFO: Evaluating on dev set...\n",
            "2023-12-21 09:44:41 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 09:44:41 INFO: 55.86\t49.26\t51.43\n",
            "2023-12-21 09:44:41 INFO: step 4900: train_loss = 2.842336, dev_score = 0.5586\n",
            "2023-12-21 09:44:43 INFO: Finished STEP 4920/50000, loss = 2.321046 (0.063 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:44:44 INFO: Finished STEP 4940/50000, loss = 2.302651 (0.062 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:44:45 INFO: Finished STEP 4960/50000, loss = 3.366973 (0.071 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:44:47 INFO: Finished STEP 4980/50000, loss = 1.909721 (0.055 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:44:48 INFO: Finished STEP 5000/50000, loss = 3.652251 (0.073 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:44:48 INFO: Evaluating on dev set...\n",
            "2023-12-21 09:45:00 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 09:45:00 INFO: 55.69\t49.23\t51.22\n",
            "2023-12-21 09:45:00 INFO: step 5000: train_loss = 2.939416, dev_score = 0.5569\n",
            "2023-12-21 09:45:02 INFO: Finished STEP 5020/50000, loss = 3.107489 (0.071 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:45:03 INFO: Finished STEP 5040/50000, loss = 3.963770 (0.054 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:45:04 INFO: Finished STEP 5060/50000, loss = 2.941479 (0.076 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:45:06 INFO: Finished STEP 5080/50000, loss = 2.979865 (0.074 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:45:07 INFO: Finished STEP 5100/50000, loss = 2.755484 (0.078 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:45:07 INFO: Evaluating on dev set...\n",
            "2023-12-21 09:45:20 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 09:45:20 INFO: 54.73\t48.32\t50.27\n",
            "2023-12-21 09:45:20 INFO: step 5100: train_loss = 2.846167, dev_score = 0.5473\n",
            "2023-12-21 09:45:21 INFO: Finished STEP 5120/50000, loss = 3.590849 (0.076 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:45:23 INFO: Finished STEP 5140/50000, loss = 2.730168 (0.068 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:45:24 INFO: Finished STEP 5160/50000, loss = 2.735399 (0.066 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:45:25 INFO: Finished STEP 5180/50000, loss = 3.162926 (0.071 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:45:27 INFO: Finished STEP 5200/50000, loss = 3.246350 (0.071 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:45:27 INFO: Evaluating on dev set...\n",
            "2023-12-21 09:45:39 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 09:45:39 INFO: 56.21\t48.95\t51.03\n",
            "2023-12-21 09:45:39 INFO: step 5200: train_loss = 2.839828, dev_score = 0.5621\n",
            "2023-12-21 09:45:41 INFO: Finished STEP 5220/50000, loss = 2.112399 (0.061 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:45:42 INFO: Finished STEP 5240/50000, loss = 3.313340 (0.080 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:45:44 INFO: Finished STEP 5260/50000, loss = 3.216815 (0.073 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:45:45 INFO: Finished STEP 5280/50000, loss = 3.647877 (0.074 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:45:47 INFO: Finished STEP 5300/50000, loss = 3.178291 (0.071 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:45:47 INFO: Evaluating on dev set...\n",
            "2023-12-21 09:45:59 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 09:45:59 INFO: 54.04\t47.40\t49.57\n",
            "2023-12-21 09:45:59 INFO: step 5300: train_loss = 2.876780, dev_score = 0.5404\n",
            "2023-12-21 09:46:00 INFO: Finished STEP 5320/50000, loss = 2.937559 (0.071 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:46:02 INFO: Finished STEP 5340/50000, loss = 3.008511 (0.076 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:46:03 INFO: Finished STEP 5360/50000, loss = 3.142783 (0.062 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:46:04 INFO: Finished STEP 5380/50000, loss = 2.198114 (0.067 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:46:06 INFO: Finished STEP 5400/50000, loss = 3.029628 (0.074 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:46:06 INFO: Evaluating on dev set...\n",
            "2023-12-21 09:46:18 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 09:46:18 INFO: 54.69\t48.21\t50.26\n",
            "2023-12-21 09:46:18 INFO: step 5400: train_loss = 2.817552, dev_score = 0.5469\n",
            "2023-12-21 09:46:19 INFO: Finished STEP 5420/50000, loss = 2.894292 (0.064 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:46:21 INFO: Finished STEP 5440/50000, loss = 3.422551 (0.073 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:46:22 INFO: Finished STEP 5460/50000, loss = 2.656013 (0.077 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:46:24 INFO: Finished STEP 5480/50000, loss = 2.692994 (0.070 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:46:25 INFO: Finished STEP 5500/50000, loss = 2.251646 (0.068 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:46:25 INFO: Evaluating on dev set...\n",
            "2023-12-21 09:46:37 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 09:46:37 INFO: 55.42\t49.35\t51.43\n",
            "2023-12-21 09:46:37 INFO: step 5500: train_loss = 2.855824, dev_score = 0.5542\n",
            "2023-12-21 09:46:38 INFO: Finished STEP 5520/50000, loss = 1.960954 (0.046 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:46:40 INFO: Finished STEP 5540/50000, loss = 3.200528 (0.075 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:46:41 INFO: Finished STEP 5560/50000, loss = 2.387949 (0.055 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:46:43 INFO: Finished STEP 5580/50000, loss = 2.362083 (0.066 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:46:44 INFO: Finished STEP 5600/50000, loss = 2.989393 (0.076 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:46:44 INFO: Evaluating on dev set...\n",
            "2023-12-21 09:46:56 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 09:46:56 INFO: 55.47\t48.78\t50.83\n",
            "2023-12-21 09:46:56 INFO: step 5600: train_loss = 2.861350, dev_score = 0.5547\n",
            "2023-12-21 09:46:58 INFO: Finished STEP 5620/50000, loss = 2.591731 (0.071 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:46:59 INFO: Finished STEP 5640/50000, loss = 3.506117 (0.073 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:47:01 INFO: Finished STEP 5660/50000, loss = 3.130526 (0.071 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:47:02 INFO: Finished STEP 5680/50000, loss = 1.362538 (0.057 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:47:04 INFO: Finished STEP 5700/50000, loss = 3.501735 (0.077 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:47:04 INFO: Evaluating on dev set...\n",
            "2023-12-21 09:47:15 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 09:47:15 INFO: 56.17\t49.83\t51.60\n",
            "2023-12-21 09:47:15 INFO: step 5700: train_loss = 2.820725, dev_score = 0.5617\n",
            "2023-12-21 09:47:16 INFO: Finished STEP 5720/50000, loss = 3.535525 (0.072 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:47:18 INFO: Finished STEP 5740/50000, loss = 3.725414 (0.077 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:47:19 INFO: Finished STEP 5760/50000, loss = 2.315478 (0.051 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:47:21 INFO: Finished STEP 5780/50000, loss = 3.505697 (0.073 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:47:22 INFO: Finished STEP 5800/50000, loss = 2.289626 (0.066 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:47:22 INFO: Evaluating on dev set...\n",
            "2023-12-21 09:47:34 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 09:47:34 INFO: 55.78\t49.55\t51.57\n",
            "2023-12-21 09:47:34 INFO: step 5800: train_loss = 2.898198, dev_score = 0.5578\n",
            "2023-12-21 09:47:36 INFO: Finished STEP 5820/50000, loss = 2.679234 (0.065 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:47:37 INFO: Finished STEP 5840/50000, loss = 2.917506 (0.073 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:47:39 INFO: Finished STEP 5860/50000, loss = 2.712748 (0.070 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:47:40 INFO: Finished STEP 5880/50000, loss = 2.857107 (0.078 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:47:42 INFO: Finished STEP 5900/50000, loss = 3.272943 (0.075 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:47:42 INFO: Evaluating on dev set...\n",
            "2023-12-21 09:47:54 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 09:47:54 INFO: 54.64\t48.02\t49.87\n",
            "2023-12-21 09:47:54 INFO: step 5900: train_loss = 2.835076, dev_score = 0.5464\n",
            "2023-12-21 09:47:55 INFO: Finished STEP 5920/50000, loss = 3.878077 (0.073 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:47:57 INFO: Finished STEP 5940/50000, loss = 2.585838 (0.063 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:47:58 INFO: Finished STEP 5960/50000, loss = 3.625787 (0.071 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:48:00 INFO: Finished STEP 5980/50000, loss = 1.970532 (0.068 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:48:01 INFO: Finished STEP 6000/50000, loss = 2.824703 (0.069 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:48:01 INFO: Evaluating on dev set...\n",
            "2023-12-21 09:48:13 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 09:48:13 INFO: 54.92\t48.76\t50.94\n",
            "2023-12-21 09:48:13 INFO: step 6000: train_loss = 2.832954, dev_score = 0.5492\n",
            "2023-12-21 09:48:14 INFO: Finished STEP 6020/50000, loss = 2.553486 (0.056 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:48:16 INFO: Finished STEP 6040/50000, loss = 2.653577 (0.069 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:48:17 INFO: Finished STEP 6060/50000, loss = 3.061372 (0.077 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:48:19 INFO: Finished STEP 6080/50000, loss = 3.065964 (0.074 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:48:20 INFO: Finished STEP 6100/50000, loss = 2.440906 (0.066 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:48:20 INFO: Evaluating on dev set...\n",
            "2023-12-21 09:48:32 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 09:48:32 INFO: 56.32\t49.92\t51.89\n",
            "2023-12-21 09:48:32 INFO: step 6100: train_loss = 2.879330, dev_score = 0.5632\n",
            "2023-12-21 09:48:34 INFO: Finished STEP 6120/50000, loss = 3.080926 (0.076 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:48:35 INFO: Finished STEP 6140/50000, loss = 3.466227 (0.070 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:48:37 INFO: Finished STEP 6160/50000, loss = 3.485650 (0.077 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:48:38 INFO: Finished STEP 6180/50000, loss = 1.986097 (0.068 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:48:40 INFO: Finished STEP 6200/50000, loss = 2.351181 (0.062 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:48:40 INFO: Evaluating on dev set...\n",
            "2023-12-21 09:48:51 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 09:48:51 INFO: 56.44\t50.35\t52.28\n",
            "2023-12-21 09:48:51 INFO: step 6200: train_loss = 2.845908, dev_score = 0.5644\n",
            "2023-12-21 09:48:53 INFO: Finished STEP 6220/50000, loss = 2.455815 (0.066 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:48:54 INFO: Finished STEP 6240/50000, loss = 2.893163 (0.076 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:48:56 INFO: Finished STEP 6260/50000, loss = 3.178992 (0.078 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:48:57 INFO: Finished STEP 6280/50000, loss = 3.501497 (0.080 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:48:59 INFO: Finished STEP 6300/50000, loss = 3.100317 (0.072 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:48:59 INFO: Evaluating on dev set...\n",
            "2023-12-21 09:49:10 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 09:49:10 INFO: 54.99\t48.91\t51.26\n",
            "2023-12-21 09:49:10 INFO: step 6300: train_loss = 2.844161, dev_score = 0.5499\n",
            "2023-12-21 09:49:11 INFO: Finished STEP 6320/50000, loss = 3.198599 (0.070 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:49:13 INFO: Finished STEP 6340/50000, loss = 2.144151 (0.063 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:49:14 INFO: Finished STEP 6360/50000, loss = 3.831531 (0.078 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:49:16 INFO: Finished STEP 6380/50000, loss = 4.325888 (0.079 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:49:17 INFO: Finished STEP 6400/50000, loss = 3.022164 (0.065 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:49:17 INFO: Evaluating on dev set...\n",
            "2023-12-21 09:49:30 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 09:49:30 INFO: 55.79\t49.86\t52.10\n",
            "2023-12-21 09:49:30 INFO: step 6400: train_loss = 2.898637, dev_score = 0.5579\n",
            "2023-12-21 09:49:31 INFO: Finished STEP 6420/50000, loss = 2.597934 (0.074 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:49:33 INFO: Finished STEP 6440/50000, loss = 3.863761 (0.072 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:49:34 INFO: Finished STEP 6460/50000, loss = 3.326584 (0.073 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:49:35 INFO: Finished STEP 6480/50000, loss = 1.982281 (0.055 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:49:37 INFO: Finished STEP 6500/50000, loss = 2.748488 (0.075 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:49:37 INFO: Evaluating on dev set...\n",
            "2023-12-21 09:49:49 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 09:49:49 INFO: 53.20\t47.22\t49.47\n",
            "2023-12-21 09:49:49 INFO: step 6500: train_loss = 2.834934, dev_score = 0.5320\n",
            "2023-12-21 09:49:50 INFO: Finished STEP 6520/50000, loss = 3.498289 (0.073 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:49:52 INFO: Finished STEP 6540/50000, loss = 2.969862 (0.076 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:49:53 INFO: Finished STEP 6560/50000, loss = 2.297550 (0.067 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:49:55 INFO: Finished STEP 6580/50000, loss = 3.404312 (0.073 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:49:56 INFO: Finished STEP 6600/50000, loss = 2.786610 (0.069 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:49:56 INFO: Evaluating on dev set...\n",
            "2023-12-21 09:50:08 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 09:50:08 INFO: 54.82\t48.65\t50.91\n",
            "2023-12-21 09:50:08 INFO: step 6600: train_loss = 2.822707, dev_score = 0.5482\n",
            "2023-12-21 09:50:10 INFO: Finished STEP 6620/50000, loss = 3.361192 (0.079 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:50:11 INFO: Finished STEP 6640/50000, loss = 3.343158 (0.082 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:50:13 INFO: Finished STEP 6660/50000, loss = 3.574880 (0.072 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:50:14 INFO: Finished STEP 6680/50000, loss = 1.612507 (0.055 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:50:16 INFO: Finished STEP 6700/50000, loss = 2.995564 (0.075 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:50:16 INFO: Evaluating on dev set...\n",
            "2023-12-21 09:50:29 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 09:50:29 INFO: 55.53\t49.33\t51.32\n",
            "2023-12-21 09:50:29 INFO: step 6700: train_loss = 2.880795, dev_score = 0.5553\n",
            "2023-12-21 09:50:30 INFO: Finished STEP 6720/50000, loss = 4.370668 (0.075 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:50:32 INFO: Finished STEP 6740/50000, loss = 2.635230 (0.074 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:50:33 INFO: Finished STEP 6760/50000, loss = 3.090977 (0.070 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:50:35 INFO: Finished STEP 6780/50000, loss = 1.966682 (0.058 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:50:36 INFO: Finished STEP 6800/50000, loss = 3.451970 (0.073 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:50:36 INFO: Evaluating on dev set...\n",
            "2023-12-21 09:50:48 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 09:50:48 INFO: 55.94\t48.77\t51.00\n",
            "2023-12-21 09:50:48 INFO: step 6800: train_loss = 2.904821, dev_score = 0.5594\n",
            "2023-12-21 09:50:49 INFO: Finished STEP 6820/50000, loss = 3.141109 (0.077 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:50:51 INFO: Finished STEP 6840/50000, loss = 3.744873 (0.083 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:50:52 INFO: Finished STEP 6860/50000, loss = 3.085480 (0.069 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:50:54 INFO: Finished STEP 6880/50000, loss = 2.448967 (0.045 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:50:55 INFO: Finished STEP 6900/50000, loss = 3.384408 (0.076 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:50:55 INFO: Evaluating on dev set...\n",
            "2023-12-21 09:51:07 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 09:51:07 INFO: 55.03\t48.50\t50.89\n",
            "2023-12-21 09:51:07 INFO: step 6900: train_loss = 2.882401, dev_score = 0.5503\n",
            "2023-12-21 09:51:09 INFO: Finished STEP 6920/50000, loss = 3.569638 (0.068 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:51:10 INFO: Finished STEP 6940/50000, loss = 2.997596 (0.075 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:51:12 INFO: Finished STEP 6960/50000, loss = 2.318858 (0.057 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:51:13 INFO: Finished STEP 6980/50000, loss = 3.214005 (0.077 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:51:15 INFO: Finished STEP 7000/50000, loss = 2.618991 (0.068 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:51:15 INFO: Evaluating on dev set...\n",
            "2023-12-21 09:51:27 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 09:51:27 INFO: 55.08\t49.09\t51.39\n",
            "2023-12-21 09:51:27 INFO: step 7000: train_loss = 2.841634, dev_score = 0.5508\n",
            "2023-12-21 09:51:29 INFO: Finished STEP 7020/50000, loss = 3.114039 (0.077 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:51:30 INFO: Finished STEP 7040/50000, loss = 1.942683 (0.057 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:51:32 INFO: Finished STEP 7060/50000, loss = 2.353109 (0.064 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:51:33 INFO: Finished STEP 7080/50000, loss = 3.029512 (0.076 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:51:35 INFO: Finished STEP 7100/50000, loss = 1.913291 (0.054 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:51:35 INFO: Evaluating on dev set...\n",
            "2023-12-21 09:51:47 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 09:51:47 INFO: 55.88\t49.09\t51.41\n",
            "2023-12-21 09:51:47 INFO: step 7100: train_loss = 2.828324, dev_score = 0.5588\n",
            "2023-12-21 09:51:49 INFO: Finished STEP 7120/50000, loss = 3.157573 (0.075 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:51:50 INFO: Finished STEP 7140/50000, loss = 2.070249 (0.054 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:51:52 INFO: Finished STEP 7160/50000, loss = 2.582168 (0.065 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:51:53 INFO: Finished STEP 7180/50000, loss = 3.577469 (0.075 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:51:55 INFO: Finished STEP 7200/50000, loss = 3.275790 (0.074 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:51:55 INFO: Evaluating on dev set...\n",
            "2023-12-21 09:52:06 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 09:52:06 INFO: 54.60\t48.72\t50.77\n",
            "2023-12-21 09:52:06 INFO: step 7200: train_loss = 2.887541, dev_score = 0.5460\n",
            "2023-12-21 09:52:06 INFO: Switching to AMSGrad\n",
            "2023-12-21 09:52:08 INFO: Finished STEP 7220/50000, loss = 3.456947 (0.079 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:52:10 INFO: Finished STEP 7240/50000, loss = 3.696561 (0.073 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:52:11 INFO: Finished STEP 7260/50000, loss = 2.342781 (0.058 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:52:13 INFO: Finished STEP 7280/50000, loss = 3.220202 (0.073 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:52:14 INFO: Finished STEP 7300/50000, loss = 2.744901 (0.076 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:52:14 INFO: Evaluating on dev set...\n",
            "2023-12-21 09:52:26 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 09:52:26 INFO: 54.56\t48.68\t50.78\n",
            "2023-12-21 09:52:26 INFO: step 7300: train_loss = 2.825835, dev_score = 0.5456\n",
            "2023-12-21 09:52:28 INFO: Finished STEP 7320/50000, loss = 2.948405 (0.071 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:52:29 INFO: Finished STEP 7340/50000, loss = 3.142179 (0.067 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:52:31 INFO: Finished STEP 7360/50000, loss = 3.107043 (0.083 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:52:33 INFO: Finished STEP 7380/50000, loss = 2.188506 (0.057 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:52:34 INFO: Finished STEP 7400/50000, loss = 2.756346 (0.074 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:52:34 INFO: Evaluating on dev set...\n",
            "2023-12-21 09:52:46 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 09:52:46 INFO: 56.67\t50.22\t52.52\n",
            "2023-12-21 09:52:46 INFO: step 7400: train_loss = 2.823957, dev_score = 0.5667\n",
            "2023-12-21 09:52:48 INFO: Finished STEP 7420/50000, loss = 2.681869 (0.075 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:52:49 INFO: Finished STEP 7440/50000, loss = 3.195795 (0.068 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:52:50 INFO: Finished STEP 7460/50000, loss = 3.046828 (0.076 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:52:52 INFO: Finished STEP 7480/50000, loss = 2.813085 (0.080 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:52:54 INFO: Finished STEP 7500/50000, loss = 2.651723 (0.074 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:52:54 INFO: Evaluating on dev set...\n",
            "2023-12-21 09:53:06 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 09:53:06 INFO: 56.18\t50.06\t52.10\n",
            "2023-12-21 09:53:06 INFO: step 7500: train_loss = 2.690678, dev_score = 0.5618\n",
            "2023-12-21 09:53:07 INFO: Finished STEP 7520/50000, loss = 2.173610 (0.063 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:53:09 INFO: Finished STEP 7540/50000, loss = 2.308807 (0.077 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:53:10 INFO: Finished STEP 7560/50000, loss = 2.960362 (0.078 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:53:12 INFO: Finished STEP 7580/50000, loss = 2.982391 (0.076 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:53:13 INFO: Finished STEP 7600/50000, loss = 3.358889 (0.076 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:53:13 INFO: Evaluating on dev set...\n",
            "2023-12-21 09:53:25 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 09:53:25 INFO: 55.71\t50.20\t52.35\n",
            "2023-12-21 09:53:25 INFO: step 7600: train_loss = 2.660257, dev_score = 0.5571\n",
            "2023-12-21 09:53:27 INFO: Finished STEP 7620/50000, loss = 1.933279 (0.058 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:53:28 INFO: Finished STEP 7640/50000, loss = 3.236941 (0.074 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:53:30 INFO: Finished STEP 7660/50000, loss = 1.956076 (0.063 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:53:31 INFO: Finished STEP 7680/50000, loss = 3.052955 (0.071 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:53:33 INFO: Finished STEP 7700/50000, loss = 2.420668 (0.064 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:53:33 INFO: Evaluating on dev set...\n",
            "2023-12-21 09:53:45 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 09:53:45 INFO: 56.37\t50.07\t52.13\n",
            "2023-12-21 09:53:45 INFO: step 7700: train_loss = 2.585193, dev_score = 0.5637\n",
            "2023-12-21 09:53:46 INFO: Finished STEP 7720/50000, loss = 2.324071 (0.070 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:53:48 INFO: Finished STEP 7740/50000, loss = 2.420479 (0.069 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:53:49 INFO: Finished STEP 7760/50000, loss = 3.046096 (0.072 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:53:51 INFO: Finished STEP 7780/50000, loss = 2.070624 (0.066 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:53:52 INFO: Finished STEP 7800/50000, loss = 2.417788 (0.075 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:53:52 INFO: Evaluating on dev set...\n",
            "2023-12-21 09:54:03 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 09:54:03 INFO: 56.90\t50.60\t52.72\n",
            "2023-12-21 09:54:03 INFO: step 7800: train_loss = 2.595387, dev_score = 0.5690\n",
            "2023-12-21 09:54:05 INFO: Finished STEP 7820/50000, loss = 1.803979 (0.053 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:54:07 INFO: Finished STEP 7840/50000, loss = 3.101126 (0.076 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:54:08 INFO: Finished STEP 7860/50000, loss = 3.168109 (0.079 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:54:10 INFO: Finished STEP 7880/50000, loss = 1.950105 (0.060 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:54:11 INFO: Finished STEP 7900/50000, loss = 2.217184 (0.064 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:54:11 INFO: Evaluating on dev set...\n",
            "2023-12-21 09:54:23 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 09:54:23 INFO: 57.51\t51.45\t53.62\n",
            "2023-12-21 09:54:23 INFO: step 7900: train_loss = 2.557640, dev_score = 0.5751\n",
            "2023-12-21 09:54:23 INFO: Model saved to saved_models/depparse/vi_vtb_charlm_parser.pt\n",
            "2023-12-21 09:54:23 INFO: new best model saved.\n",
            "2023-12-21 09:54:25 INFO: Finished STEP 7920/50000, loss = 1.866917 (0.058 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:54:26 INFO: Finished STEP 7940/50000, loss = 1.778319 (0.055 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:54:28 INFO: Finished STEP 7960/50000, loss = 2.367797 (0.074 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:54:29 INFO: Finished STEP 7980/50000, loss = 1.759544 (0.055 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:54:31 INFO: Finished STEP 8000/50000, loss = 2.684852 (0.075 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:54:31 INFO: Evaluating on dev set...\n",
            "2023-12-21 09:54:43 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 09:54:43 INFO: 57.01\t51.35\t53.51\n",
            "2023-12-21 09:54:43 INFO: step 8000: train_loss = 2.627859, dev_score = 0.5701\n",
            "2023-12-21 09:54:45 INFO: Finished STEP 8020/50000, loss = 2.538285 (0.078 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:54:47 INFO: Finished STEP 8040/50000, loss = 2.029308 (0.067 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:54:48 INFO: Finished STEP 8060/50000, loss = 2.472092 (0.068 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:54:50 INFO: Finished STEP 8080/50000, loss = 2.649213 (0.073 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:54:51 INFO: Finished STEP 8100/50000, loss = 2.716882 (0.068 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:54:51 INFO: Evaluating on dev set...\n",
            "2023-12-21 09:55:03 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 09:55:03 INFO: 59.27\t52.85\t54.92\n",
            "2023-12-21 09:55:03 INFO: step 8100: train_loss = 2.549204, dev_score = 0.5927\n",
            "2023-12-21 09:55:04 INFO: Model saved to saved_models/depparse/vi_vtb_charlm_parser.pt\n",
            "2023-12-21 09:55:04 INFO: new best model saved.\n",
            "2023-12-21 09:55:06 INFO: Finished STEP 8120/50000, loss = 2.039134 (0.049 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:55:07 INFO: Finished STEP 8140/50000, loss = 2.078773 (0.066 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:55:09 INFO: Finished STEP 8160/50000, loss = 1.967272 (0.067 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:55:10 INFO: Finished STEP 8180/50000, loss = 2.087018 (0.055 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:55:11 INFO: Finished STEP 8200/50000, loss = 3.008511 (0.075 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:55:11 INFO: Evaluating on dev set...\n",
            "2023-12-21 09:55:23 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 09:55:23 INFO: 57.40\t51.35\t53.34\n",
            "2023-12-21 09:55:23 INFO: step 8200: train_loss = 2.492192, dev_score = 0.5740\n",
            "2023-12-21 09:55:25 INFO: Finished STEP 8220/50000, loss = 2.395751 (0.070 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:55:26 INFO: Finished STEP 8240/50000, loss = 2.468897 (0.074 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:55:28 INFO: Finished STEP 8260/50000, loss = 2.995837 (0.077 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:55:29 INFO: Finished STEP 8280/50000, loss = 2.000626 (0.079 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:55:31 INFO: Finished STEP 8300/50000, loss = 2.803499 (0.080 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:55:31 INFO: Evaluating on dev set...\n",
            "2023-12-21 09:55:42 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 09:55:42 INFO: 58.10\t52.15\t54.25\n",
            "2023-12-21 09:55:42 INFO: step 8300: train_loss = 2.490779, dev_score = 0.5810\n",
            "2023-12-21 09:55:44 INFO: Finished STEP 8320/50000, loss = 2.807047 (0.078 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:55:45 INFO: Finished STEP 8340/50000, loss = 1.711487 (0.057 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:55:47 INFO: Finished STEP 8360/50000, loss = 2.664276 (0.070 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:55:49 INFO: Finished STEP 8380/50000, loss = 3.125229 (0.078 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:55:50 INFO: Finished STEP 8400/50000, loss = 2.393917 (0.074 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:55:50 INFO: Evaluating on dev set...\n",
            "2023-12-21 09:56:03 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 09:56:03 INFO: 57.81\t51.93\t53.98\n",
            "2023-12-21 09:56:03 INFO: step 8400: train_loss = 2.464026, dev_score = 0.5781\n",
            "2023-12-21 09:56:04 INFO: Finished STEP 8420/50000, loss = 2.724269 (0.075 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:56:06 INFO: Finished STEP 8440/50000, loss = 2.405351 (0.072 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:56:07 INFO: Finished STEP 8460/50000, loss = 2.603618 (0.071 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:56:09 INFO: Finished STEP 8480/50000, loss = 2.576191 (0.073 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:56:10 INFO: Finished STEP 8500/50000, loss = 2.238333 (0.073 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:56:10 INFO: Evaluating on dev set...\n",
            "2023-12-21 09:56:22 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 09:56:22 INFO: 57.61\t52.31\t54.46\n",
            "2023-12-21 09:56:22 INFO: step 8500: train_loss = 2.444062, dev_score = 0.5761\n",
            "2023-12-21 09:56:24 INFO: Finished STEP 8520/50000, loss = 1.132915 (0.052 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:56:25 INFO: Finished STEP 8540/50000, loss = 2.197687 (0.069 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:56:27 INFO: Finished STEP 8560/50000, loss = 2.912473 (0.076 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:56:28 INFO: Finished STEP 8580/50000, loss = 1.996622 (0.069 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:56:30 INFO: Finished STEP 8600/50000, loss = 2.967101 (0.078 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:56:30 INFO: Evaluating on dev set...\n",
            "2023-12-21 09:56:41 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 09:56:41 INFO: 58.20\t52.36\t54.47\n",
            "2023-12-21 09:56:41 INFO: step 8600: train_loss = 2.432200, dev_score = 0.5820\n",
            "2023-12-21 09:56:43 INFO: Finished STEP 8620/50000, loss = 2.208387 (0.056 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:56:44 INFO: Finished STEP 8640/50000, loss = 3.003602 (0.082 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:56:46 INFO: Finished STEP 8660/50000, loss = 2.778911 (0.078 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:56:48 INFO: Finished STEP 8680/50000, loss = 2.211177 (0.066 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:56:49 INFO: Finished STEP 8700/50000, loss = 1.944659 (0.071 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:56:49 INFO: Evaluating on dev set...\n",
            "2023-12-21 09:57:01 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 09:57:01 INFO: 58.01\t52.21\t54.32\n",
            "2023-12-21 09:57:01 INFO: step 8700: train_loss = 2.415180, dev_score = 0.5801\n",
            "2023-12-21 09:57:03 INFO: Finished STEP 8720/50000, loss = 2.011201 (0.077 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:57:04 INFO: Finished STEP 8740/50000, loss = 2.907450 (0.078 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:57:06 INFO: Finished STEP 8760/50000, loss = 2.237819 (0.069 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:57:07 INFO: Finished STEP 8780/50000, loss = 2.555783 (0.063 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:57:09 INFO: Finished STEP 8800/50000, loss = 2.382732 (0.069 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:57:09 INFO: Evaluating on dev set...\n",
            "2023-12-21 09:57:21 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 09:57:21 INFO: 58.33\t53.10\t54.97\n",
            "2023-12-21 09:57:21 INFO: step 8800: train_loss = 2.480385, dev_score = 0.5833\n",
            "2023-12-21 09:57:22 INFO: Finished STEP 8820/50000, loss = 1.915570 (0.063 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:57:24 INFO: Finished STEP 8840/50000, loss = 1.576919 (0.057 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:57:25 INFO: Finished STEP 8860/50000, loss = 2.766363 (0.084 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:57:27 INFO: Finished STEP 8880/50000, loss = 2.749276 (0.077 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:57:28 INFO: Finished STEP 8900/50000, loss = 2.872016 (0.075 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:57:28 INFO: Evaluating on dev set...\n",
            "2023-12-21 09:57:40 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 09:57:40 INFO: 57.92\t52.12\t54.13\n",
            "2023-12-21 09:57:40 INFO: step 8900: train_loss = 2.444231, dev_score = 0.5792\n",
            "2023-12-21 09:57:42 INFO: Finished STEP 8920/50000, loss = 2.358671 (0.068 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:57:43 INFO: Finished STEP 8940/50000, loss = 1.939449 (0.070 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:57:45 INFO: Finished STEP 8960/50000, loss = 2.296813 (0.067 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:57:46 INFO: Finished STEP 8980/50000, loss = 2.266453 (0.072 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:57:48 INFO: Finished STEP 9000/50000, loss = 1.871818 (0.070 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:57:48 INFO: Evaluating on dev set...\n",
            "2023-12-21 09:58:00 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 09:58:00 INFO: 57.82\t52.32\t54.29\n",
            "2023-12-21 09:58:00 INFO: step 9000: train_loss = 2.375108, dev_score = 0.5782\n",
            "2023-12-21 09:58:02 INFO: Finished STEP 9020/50000, loss = 2.896665 (0.077 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:58:03 INFO: Finished STEP 9040/50000, loss = 1.183963 (0.050 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:58:05 INFO: Finished STEP 9060/50000, loss = 2.760893 (0.079 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:58:06 INFO: Finished STEP 9080/50000, loss = 3.222287 (0.077 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:58:07 INFO: Finished STEP 9100/50000, loss = 2.954824 (0.074 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:58:07 INFO: Evaluating on dev set...\n",
            "2023-12-21 09:58:19 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 09:58:19 INFO: 58.81\t52.79\t54.94\n",
            "2023-12-21 09:58:19 INFO: step 9100: train_loss = 2.440244, dev_score = 0.5881\n",
            "2023-12-21 09:58:21 INFO: Finished STEP 9120/50000, loss = 2.267603 (0.072 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:58:22 INFO: Finished STEP 9140/50000, loss = 2.727214 (0.075 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:58:24 INFO: Finished STEP 9160/50000, loss = 2.122202 (0.076 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:58:25 INFO: Finished STEP 9180/50000, loss = 2.224188 (0.067 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:58:27 INFO: Finished STEP 9200/50000, loss = 2.425067 (0.073 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:58:27 INFO: Evaluating on dev set...\n",
            "2023-12-21 09:58:38 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 09:58:38 INFO: 57.75\t51.77\t53.80\n",
            "2023-12-21 09:58:38 INFO: step 9200: train_loss = 2.449263, dev_score = 0.5775\n",
            "2023-12-21 09:58:40 INFO: Finished STEP 9220/50000, loss = 2.884379 (0.078 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:58:42 INFO: Finished STEP 9240/50000, loss = 1.703344 (0.055 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:58:43 INFO: Finished STEP 9260/50000, loss = 2.296523 (0.066 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:58:44 INFO: Finished STEP 9280/50000, loss = 1.914326 (0.062 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:58:46 INFO: Finished STEP 9300/50000, loss = 2.453727 (0.071 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:58:46 INFO: Evaluating on dev set...\n",
            "2023-12-21 09:58:58 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 09:58:58 INFO: 57.95\t52.05\t54.12\n",
            "2023-12-21 09:58:58 INFO: step 9300: train_loss = 2.382516, dev_score = 0.5795\n",
            "2023-12-21 09:59:00 INFO: Finished STEP 9320/50000, loss = 2.477324 (0.078 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:59:01 INFO: Finished STEP 9340/50000, loss = 2.775748 (0.079 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:59:03 INFO: Finished STEP 9360/50000, loss = 2.817792 (0.073 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:59:04 INFO: Finished STEP 9380/50000, loss = 2.704092 (0.074 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:59:06 INFO: Finished STEP 9400/50000, loss = 2.116938 (0.077 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:59:06 INFO: Evaluating on dev set...\n",
            "2023-12-21 09:59:17 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 09:59:17 INFO: 58.26\t52.84\t54.81\n",
            "2023-12-21 09:59:17 INFO: step 9400: train_loss = 2.355488, dev_score = 0.5826\n",
            "2023-12-21 09:59:19 INFO: Finished STEP 9420/50000, loss = 1.611848 (0.057 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:59:20 INFO: Finished STEP 9440/50000, loss = 2.951837 (0.075 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:59:22 INFO: Finished STEP 9460/50000, loss = 1.948143 (0.071 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:59:23 INFO: Finished STEP 9480/50000, loss = 1.729398 (0.068 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:59:25 INFO: Finished STEP 9500/50000, loss = 2.886239 (0.075 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:59:25 INFO: Evaluating on dev set...\n",
            "2023-12-21 09:59:37 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 09:59:37 INFO: 58.37\t52.48\t54.48\n",
            "2023-12-21 09:59:37 INFO: step 9500: train_loss = 2.384158, dev_score = 0.5837\n",
            "2023-12-21 09:59:38 INFO: Finished STEP 9520/50000, loss = 1.686095 (0.066 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:59:40 INFO: Finished STEP 9540/50000, loss = 1.819332 (0.069 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:59:41 INFO: Finished STEP 9560/50000, loss = 2.482236 (0.076 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:59:43 INFO: Finished STEP 9580/50000, loss = 2.107299 (0.070 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:59:45 INFO: Finished STEP 9600/50000, loss = 1.318438 (0.058 sec/batch), lr: 0.003000\n",
            "2023-12-21 09:59:45 INFO: Evaluating on dev set...\n",
            "2023-12-21 09:59:57 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 09:59:57 INFO: 58.32\t52.66\t54.64\n",
            "2023-12-21 09:59:57 INFO: step 9600: train_loss = 2.315699, dev_score = 0.5832\n",
            "2023-12-21 09:59:59 INFO: Finished STEP 9620/50000, loss = 1.781234 (0.067 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:00:00 INFO: Finished STEP 9640/50000, loss = 2.053039 (0.070 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:00:02 INFO: Finished STEP 9660/50000, loss = 1.945074 (0.075 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:00:03 INFO: Finished STEP 9680/50000, loss = 2.099220 (0.060 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:00:05 INFO: Finished STEP 9700/50000, loss = 2.063755 (0.078 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:00:05 INFO: Evaluating on dev set...\n",
            "2023-12-21 10:00:16 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 10:00:16 INFO: 59.60\t53.26\t55.25\n",
            "2023-12-21 10:00:16 INFO: step 9700: train_loss = 2.304544, dev_score = 0.5960\n",
            "2023-12-21 10:00:17 INFO: Model saved to saved_models/depparse/vi_vtb_charlm_parser.pt\n",
            "2023-12-21 10:00:17 INFO: new best model saved.\n",
            "2023-12-21 10:00:18 INFO: Finished STEP 9720/50000, loss = 3.314919 (0.076 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:00:20 INFO: Finished STEP 9740/50000, loss = 2.624324 (0.078 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:00:21 INFO: Finished STEP 9760/50000, loss = 3.110761 (0.073 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:00:23 INFO: Finished STEP 9780/50000, loss = 2.324975 (0.073 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:00:24 INFO: Finished STEP 9800/50000, loss = 3.052387 (0.078 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:00:24 INFO: Evaluating on dev set...\n",
            "2023-12-21 10:00:36 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 10:00:36 INFO: 58.84\t52.80\t54.85\n",
            "2023-12-21 10:00:36 INFO: step 9800: train_loss = 2.361977, dev_score = 0.5884\n",
            "2023-12-21 10:00:38 INFO: Finished STEP 9820/50000, loss = 2.046175 (0.065 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:00:39 INFO: Finished STEP 9840/50000, loss = 1.391206 (0.058 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:00:41 INFO: Finished STEP 9860/50000, loss = 1.838654 (0.068 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:00:43 INFO: Finished STEP 9880/50000, loss = 2.744111 (0.073 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:00:44 INFO: Finished STEP 9900/50000, loss = 2.277392 (0.080 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:00:44 INFO: Evaluating on dev set...\n",
            "2023-12-21 10:00:56 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 10:00:56 INFO: 58.63\t52.57\t54.60\n",
            "2023-12-21 10:00:56 INFO: step 9900: train_loss = 2.333426, dev_score = 0.5863\n",
            "2023-12-21 10:00:58 INFO: Finished STEP 9920/50000, loss = 2.822868 (0.072 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:00:59 INFO: Finished STEP 9940/50000, loss = 1.522877 (0.057 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:01:01 INFO: Finished STEP 9960/50000, loss = 2.217327 (0.063 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:01:02 INFO: Finished STEP 9980/50000, loss = 2.663976 (0.077 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:01:03 INFO: Finished STEP 10000/50000, loss = 2.614446 (0.075 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:01:03 INFO: Evaluating on dev set...\n",
            "2023-12-21 10:01:15 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 10:01:15 INFO: 59.17\t53.18\t55.22\n",
            "2023-12-21 10:01:15 INFO: step 10000: train_loss = 2.333248, dev_score = 0.5917\n",
            "2023-12-21 10:01:17 INFO: Finished STEP 10020/50000, loss = 2.209995 (0.075 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:01:18 INFO: Finished STEP 10040/50000, loss = 2.912675 (0.074 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:01:20 INFO: Finished STEP 10060/50000, loss = 1.920420 (0.059 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:01:21 INFO: Finished STEP 10080/50000, loss = 2.762600 (0.073 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:01:23 INFO: Finished STEP 10100/50000, loss = 2.411036 (0.072 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:01:23 INFO: Evaluating on dev set...\n",
            "2023-12-21 10:01:34 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 10:01:34 INFO: 58.93\t52.71\t54.68\n",
            "2023-12-21 10:01:34 INFO: step 10100: train_loss = 2.277775, dev_score = 0.5893\n",
            "2023-12-21 10:01:36 INFO: Finished STEP 10120/50000, loss = 2.575200 (0.090 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:01:37 INFO: Finished STEP 10140/50000, loss = 2.100619 (0.064 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:01:39 INFO: Finished STEP 10160/50000, loss = 2.072296 (0.077 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:01:40 INFO: Finished STEP 10180/50000, loss = 2.131125 (0.070 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:01:42 INFO: Finished STEP 10200/50000, loss = 2.463724 (0.072 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:01:42 INFO: Evaluating on dev set...\n",
            "2023-12-21 10:01:54 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 10:01:54 INFO: 59.19\t53.45\t55.42\n",
            "2023-12-21 10:01:54 INFO: step 10200: train_loss = 2.304146, dev_score = 0.5919\n",
            "2023-12-21 10:01:56 INFO: Finished STEP 10220/50000, loss = 1.804869 (0.055 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:01:57 INFO: Finished STEP 10240/50000, loss = 1.896653 (0.057 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:01:59 INFO: Finished STEP 10260/50000, loss = 2.482363 (0.081 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:02:00 INFO: Finished STEP 10280/50000, loss = 3.044204 (0.078 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:02:02 INFO: Finished STEP 10300/50000, loss = 1.424830 (0.057 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:02:02 INFO: Evaluating on dev set...\n",
            "2023-12-21 10:02:13 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 10:02:13 INFO: 58.71\t52.71\t54.67\n",
            "2023-12-21 10:02:13 INFO: step 10300: train_loss = 2.287841, dev_score = 0.5871\n",
            "2023-12-21 10:02:15 INFO: Finished STEP 10320/50000, loss = 1.902548 (0.059 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:02:16 INFO: Finished STEP 10340/50000, loss = 2.416299 (0.069 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:02:18 INFO: Finished STEP 10360/50000, loss = 2.488880 (0.080 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:02:19 INFO: Finished STEP 10380/50000, loss = 3.118390 (0.087 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:02:21 INFO: Finished STEP 10400/50000, loss = 2.374399 (0.075 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:02:21 INFO: Evaluating on dev set...\n",
            "2023-12-21 10:02:32 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 10:02:32 INFO: 59.29\t53.27\t55.19\n",
            "2023-12-21 10:02:32 INFO: step 10400: train_loss = 2.322300, dev_score = 0.5929\n",
            "2023-12-21 10:02:34 INFO: Finished STEP 10420/50000, loss = 2.430391 (0.075 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:02:35 INFO: Finished STEP 10440/50000, loss = 2.386626 (0.076 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:02:37 INFO: Finished STEP 10460/50000, loss = 1.933820 (0.067 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:02:38 INFO: Finished STEP 10480/50000, loss = 2.553858 (0.075 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:02:40 INFO: Finished STEP 10500/50000, loss = 2.063730 (0.076 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:02:40 INFO: Evaluating on dev set...\n",
            "2023-12-21 10:02:52 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 10:02:52 INFO: 59.34\t53.84\t55.69\n",
            "2023-12-21 10:02:52 INFO: step 10500: train_loss = 2.245252, dev_score = 0.5934\n",
            "2023-12-21 10:02:53 INFO: Finished STEP 10520/50000, loss = 2.882361 (0.079 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:02:55 INFO: Finished STEP 10540/50000, loss = 2.045144 (0.065 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:02:56 INFO: Finished STEP 10560/50000, loss = 2.916924 (0.076 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:02:58 INFO: Finished STEP 10580/50000, loss = 3.245908 (0.073 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:02:59 INFO: Finished STEP 10600/50000, loss = 2.409144 (0.067 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:02:59 INFO: Evaluating on dev set...\n",
            "2023-12-21 10:03:11 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 10:03:11 INFO: 59.89\t54.21\t56.11\n",
            "2023-12-21 10:03:11 INFO: step 10600: train_loss = 2.268798, dev_score = 0.5989\n",
            "2023-12-21 10:03:11 INFO: Model saved to saved_models/depparse/vi_vtb_charlm_parser.pt\n",
            "2023-12-21 10:03:11 INFO: new best model saved.\n",
            "2023-12-21 10:03:13 INFO: Finished STEP 10620/50000, loss = 2.445684 (0.066 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:03:15 INFO: Finished STEP 10640/50000, loss = 2.212177 (0.070 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:03:16 INFO: Finished STEP 10660/50000, loss = 2.409394 (0.072 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:03:18 INFO: Finished STEP 10680/50000, loss = 2.939170 (0.074 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:03:19 INFO: Finished STEP 10700/50000, loss = 2.366372 (0.078 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:03:19 INFO: Evaluating on dev set...\n",
            "2023-12-21 10:03:31 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 10:03:31 INFO: 59.38\t53.16\t55.14\n",
            "2023-12-21 10:03:31 INFO: step 10700: train_loss = 2.286913, dev_score = 0.5938\n",
            "2023-12-21 10:03:32 INFO: Finished STEP 10720/50000, loss = 1.868661 (0.056 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:03:34 INFO: Finished STEP 10740/50000, loss = 2.390828 (0.075 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:03:35 INFO: Finished STEP 10760/50000, loss = 2.287555 (0.076 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:03:37 INFO: Finished STEP 10780/50000, loss = 1.418599 (0.057 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:03:38 INFO: Finished STEP 10800/50000, loss = 2.762205 (0.084 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:03:38 INFO: Evaluating on dev set...\n",
            "2023-12-21 10:03:51 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 10:03:51 INFO: 59.81\t53.34\t55.19\n",
            "2023-12-21 10:03:51 INFO: step 10800: train_loss = 2.288840, dev_score = 0.5981\n",
            "2023-12-21 10:03:52 INFO: Finished STEP 10820/50000, loss = 1.800531 (0.053 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:03:54 INFO: Finished STEP 10840/50000, loss = 2.752702 (0.076 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:03:55 INFO: Finished STEP 10860/50000, loss = 2.277822 (0.066 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:03:57 INFO: Finished STEP 10880/50000, loss = 1.563278 (0.056 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:03:58 INFO: Finished STEP 10900/50000, loss = 2.210795 (0.077 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:03:58 INFO: Evaluating on dev set...\n",
            "2023-12-21 10:04:10 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 10:04:10 INFO: 60.14\t53.63\t55.66\n",
            "2023-12-21 10:04:10 INFO: step 10900: train_loss = 2.207656, dev_score = 0.6014\n",
            "2023-12-21 10:04:11 INFO: Model saved to saved_models/depparse/vi_vtb_charlm_parser.pt\n",
            "2023-12-21 10:04:11 INFO: new best model saved.\n",
            "2023-12-21 10:04:12 INFO: Finished STEP 10920/50000, loss = 2.281455 (0.070 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:04:14 INFO: Finished STEP 10940/50000, loss = 3.472938 (0.075 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:04:15 INFO: Finished STEP 10960/50000, loss = 2.707104 (0.080 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:04:17 INFO: Finished STEP 10980/50000, loss = 2.389716 (0.085 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:04:19 INFO: Finished STEP 11000/50000, loss = 2.051819 (0.059 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:04:19 INFO: Evaluating on dev set...\n",
            "2023-12-21 10:04:30 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 10:04:30 INFO: 59.87\t53.97\t55.88\n",
            "2023-12-21 10:04:30 INFO: step 11000: train_loss = 2.282873, dev_score = 0.5987\n",
            "2023-12-21 10:04:32 INFO: Finished STEP 11020/50000, loss = 2.740602 (0.079 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:04:33 INFO: Finished STEP 11040/50000, loss = 2.011193 (0.067 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:04:35 INFO: Finished STEP 11060/50000, loss = 3.060448 (0.075 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:04:36 INFO: Finished STEP 11080/50000, loss = 2.155183 (0.070 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:04:38 INFO: Finished STEP 11100/50000, loss = 2.165906 (0.072 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:04:38 INFO: Evaluating on dev set...\n",
            "2023-12-21 10:04:50 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 10:04:50 INFO: 59.64\t53.85\t55.92\n",
            "2023-12-21 10:04:50 INFO: step 11100: train_loss = 2.178278, dev_score = 0.5964\n",
            "2023-12-21 10:04:51 INFO: Finished STEP 11120/50000, loss = 1.933865 (0.068 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:04:53 INFO: Finished STEP 11140/50000, loss = 1.931825 (0.063 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:04:54 INFO: Finished STEP 11160/50000, loss = 2.731877 (0.076 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:04:56 INFO: Finished STEP 11180/50000, loss = 2.372233 (0.076 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:04:57 INFO: Finished STEP 11200/50000, loss = 2.709401 (0.073 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:04:57 INFO: Evaluating on dev set...\n",
            "2023-12-21 10:05:09 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 10:05:09 INFO: 60.24\t54.24\t56.28\n",
            "2023-12-21 10:05:09 INFO: step 11200: train_loss = 2.220570, dev_score = 0.6024\n",
            "2023-12-21 10:05:09 INFO: Model saved to saved_models/depparse/vi_vtb_charlm_parser.pt\n",
            "2023-12-21 10:05:09 INFO: new best model saved.\n",
            "2023-12-21 10:05:11 INFO: Finished STEP 11220/50000, loss = 1.756309 (0.059 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:05:12 INFO: Finished STEP 11240/50000, loss = 2.665457 (0.074 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:05:14 INFO: Finished STEP 11260/50000, loss = 2.674218 (0.075 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:05:15 INFO: Finished STEP 11280/50000, loss = 2.675381 (0.074 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:05:17 INFO: Finished STEP 11300/50000, loss = 1.780834 (0.100 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:05:17 INFO: Evaluating on dev set...\n",
            "2023-12-21 10:05:29 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 10:05:29 INFO: 60.31\t54.10\t56.03\n",
            "2023-12-21 10:05:29 INFO: step 11300: train_loss = 2.231712, dev_score = 0.6031\n",
            "2023-12-21 10:05:30 INFO: Model saved to saved_models/depparse/vi_vtb_charlm_parser.pt\n",
            "2023-12-21 10:05:30 INFO: new best model saved.\n",
            "2023-12-21 10:05:31 INFO: Finished STEP 11320/50000, loss = 2.359176 (0.075 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:05:33 INFO: Finished STEP 11340/50000, loss = 1.260492 (0.049 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:05:34 INFO: Finished STEP 11360/50000, loss = 2.085880 (0.070 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:05:36 INFO: Finished STEP 11380/50000, loss = 2.772489 (0.077 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:05:37 INFO: Finished STEP 11400/50000, loss = 2.741351 (0.077 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:05:37 INFO: Evaluating on dev set...\n",
            "2023-12-21 10:05:49 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 10:05:49 INFO: 59.43\t53.55\t55.47\n",
            "2023-12-21 10:05:49 INFO: step 11400: train_loss = 2.168403, dev_score = 0.5943\n",
            "2023-12-21 10:05:51 INFO: Finished STEP 11420/50000, loss = 2.415622 (0.072 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:05:52 INFO: Finished STEP 11440/50000, loss = 2.268409 (0.080 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:05:54 INFO: Finished STEP 11460/50000, loss = 2.401023 (0.074 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:05:55 INFO: Finished STEP 11480/50000, loss = 1.739087 (0.067 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:05:57 INFO: Finished STEP 11500/50000, loss = 2.502276 (0.076 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:05:57 INFO: Evaluating on dev set...\n",
            "2023-12-21 10:06:08 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 10:06:08 INFO: 60.20\t54.62\t56.56\n",
            "2023-12-21 10:06:08 INFO: step 11500: train_loss = 2.231748, dev_score = 0.6020\n",
            "2023-12-21 10:06:09 INFO: Finished STEP 11520/50000, loss = 1.782614 (0.065 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:06:11 INFO: Finished STEP 11540/50000, loss = 1.960224 (0.066 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:06:12 INFO: Finished STEP 11560/50000, loss = 1.933627 (0.066 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:06:14 INFO: Finished STEP 11580/50000, loss = 2.960298 (0.073 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:06:16 INFO: Finished STEP 11600/50000, loss = 2.271749 (0.075 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:06:16 INFO: Evaluating on dev set...\n",
            "2023-12-21 10:06:27 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 10:06:27 INFO: 60.16\t54.10\t56.05\n",
            "2023-12-21 10:06:27 INFO: step 11600: train_loss = 2.181588, dev_score = 0.6016\n",
            "2023-12-21 10:06:29 INFO: Finished STEP 11620/50000, loss = 2.216501 (0.068 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:06:30 INFO: Finished STEP 11640/50000, loss = 2.447405 (0.079 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:06:32 INFO: Finished STEP 11660/50000, loss = 2.160756 (0.070 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:06:33 INFO: Finished STEP 11680/50000, loss = 2.873624 (0.078 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:06:35 INFO: Finished STEP 11700/50000, loss = 1.661396 (0.055 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:06:35 INFO: Evaluating on dev set...\n",
            "2023-12-21 10:06:47 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 10:06:47 INFO: 60.61\t54.62\t56.53\n",
            "2023-12-21 10:06:47 INFO: step 11700: train_loss = 2.186970, dev_score = 0.6061\n",
            "2023-12-21 10:06:47 INFO: Model saved to saved_models/depparse/vi_vtb_charlm_parser.pt\n",
            "2023-12-21 10:06:47 INFO: new best model saved.\n",
            "2023-12-21 10:06:49 INFO: Finished STEP 11720/50000, loss = 2.973839 (0.078 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:06:50 INFO: Finished STEP 11740/50000, loss = 2.476651 (0.078 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:06:52 INFO: Finished STEP 11760/50000, loss = 2.506632 (0.079 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:06:53 INFO: Finished STEP 11780/50000, loss = 2.089262 (0.081 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:06:55 INFO: Finished STEP 11800/50000, loss = 1.968238 (0.063 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:06:55 INFO: Evaluating on dev set...\n",
            "2023-12-21 10:07:07 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 10:07:07 INFO: 59.73\t53.90\t55.87\n",
            "2023-12-21 10:07:07 INFO: step 11800: train_loss = 2.234890, dev_score = 0.5973\n",
            "2023-12-21 10:07:08 INFO: Finished STEP 11820/50000, loss = 1.837672 (0.057 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:07:09 INFO: Finished STEP 11840/50000, loss = 2.152972 (0.079 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:07:11 INFO: Finished STEP 11860/50000, loss = 2.095559 (0.077 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:07:13 INFO: Finished STEP 11880/50000, loss = 1.525749 (0.063 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:07:14 INFO: Finished STEP 11900/50000, loss = 2.504119 (0.074 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:07:14 INFO: Evaluating on dev set...\n",
            "2023-12-21 10:07:26 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 10:07:26 INFO: 60.25\t54.68\t56.55\n",
            "2023-12-21 10:07:26 INFO: step 11900: train_loss = 2.144752, dev_score = 0.6025\n",
            "2023-12-21 10:07:27 INFO: Finished STEP 11920/50000, loss = 2.000878 (0.080 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:07:29 INFO: Finished STEP 11940/50000, loss = 2.208240 (0.075 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:07:31 INFO: Finished STEP 11960/50000, loss = 2.316972 (0.077 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:07:32 INFO: Finished STEP 11980/50000, loss = 2.124141 (0.067 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:07:34 INFO: Finished STEP 12000/50000, loss = 2.277954 (0.069 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:07:34 INFO: Evaluating on dev set...\n",
            "2023-12-21 10:07:45 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 10:07:45 INFO: 60.90\t54.57\t56.57\n",
            "2023-12-21 10:07:45 INFO: step 12000: train_loss = 2.214422, dev_score = 0.6090\n",
            "2023-12-21 10:07:45 INFO: Model saved to saved_models/depparse/vi_vtb_charlm_parser.pt\n",
            "2023-12-21 10:07:45 INFO: new best model saved.\n",
            "2023-12-21 10:07:47 INFO: Finished STEP 12020/50000, loss = 1.184128 (0.047 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:07:48 INFO: Finished STEP 12040/50000, loss = 2.440894 (0.074 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:07:50 INFO: Finished STEP 12060/50000, loss = 2.309932 (0.075 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:07:51 INFO: Finished STEP 12080/50000, loss = 2.473476 (0.075 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:07:53 INFO: Finished STEP 12100/50000, loss = 1.812531 (0.068 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:07:53 INFO: Evaluating on dev set...\n",
            "2023-12-21 10:08:05 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 10:08:05 INFO: 61.00\t55.14\t57.10\n",
            "2023-12-21 10:08:05 INFO: step 12100: train_loss = 2.157154, dev_score = 0.6100\n",
            "2023-12-21 10:08:05 INFO: Model saved to saved_models/depparse/vi_vtb_charlm_parser.pt\n",
            "2023-12-21 10:08:05 INFO: new best model saved.\n",
            "2023-12-21 10:08:07 INFO: Finished STEP 12120/50000, loss = 2.360207 (0.072 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:08:09 INFO: Finished STEP 12140/50000, loss = 1.615107 (0.058 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:08:10 INFO: Finished STEP 12160/50000, loss = 1.215573 (0.056 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:08:12 INFO: Finished STEP 12180/50000, loss = 1.562874 (0.060 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:08:13 INFO: Finished STEP 12200/50000, loss = 1.924165 (0.066 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:08:13 INFO: Evaluating on dev set...\n",
            "2023-12-21 10:08:25 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 10:08:25 INFO: 60.91\t54.94\t56.98\n",
            "2023-12-21 10:08:25 INFO: step 12200: train_loss = 2.195148, dev_score = 0.6091\n",
            "2023-12-21 10:08:27 INFO: Finished STEP 12220/50000, loss = 2.164357 (0.066 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:08:28 INFO: Finished STEP 12240/50000, loss = 2.908477 (0.066 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:08:30 INFO: Finished STEP 12260/50000, loss = 0.912599 (0.054 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:08:31 INFO: Finished STEP 12280/50000, loss = 2.768453 (0.075 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:08:33 INFO: Finished STEP 12300/50000, loss = 2.099052 (0.067 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:08:33 INFO: Evaluating on dev set...\n",
            "2023-12-21 10:08:45 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 10:08:45 INFO: 61.00\t55.17\t57.03\n",
            "2023-12-21 10:08:45 INFO: step 12300: train_loss = 2.204177, dev_score = 0.6100\n",
            "2023-12-21 10:08:46 INFO: Finished STEP 12320/50000, loss = 2.581119 (0.073 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:08:47 INFO: Finished STEP 12340/50000, loss = 1.755324 (0.064 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:08:49 INFO: Finished STEP 12360/50000, loss = 2.760700 (0.071 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:08:50 INFO: Finished STEP 12380/50000, loss = 2.134461 (0.079 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:08:52 INFO: Finished STEP 12400/50000, loss = 2.580579 (0.073 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:08:52 INFO: Evaluating on dev set...\n",
            "2023-12-21 10:09:04 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 10:09:04 INFO: 61.05\t55.45\t57.23\n",
            "2023-12-21 10:09:04 INFO: step 12400: train_loss = 2.146805, dev_score = 0.6105\n",
            "2023-12-21 10:09:05 INFO: Model saved to saved_models/depparse/vi_vtb_charlm_parser.pt\n",
            "2023-12-21 10:09:05 INFO: new best model saved.\n",
            "2023-12-21 10:09:06 INFO: Finished STEP 12420/50000, loss = 1.836076 (0.070 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:09:08 INFO: Finished STEP 12440/50000, loss = 2.516638 (0.080 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:09:09 INFO: Finished STEP 12460/50000, loss = 2.380334 (0.070 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:09:11 INFO: Finished STEP 12480/50000, loss = 1.425736 (0.057 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:09:12 INFO: Finished STEP 12500/50000, loss = 2.830724 (0.079 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:09:12 INFO: Evaluating on dev set...\n",
            "2023-12-21 10:09:24 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 10:09:24 INFO: 60.89\t54.78\t56.68\n",
            "2023-12-21 10:09:24 INFO: step 12500: train_loss = 2.159422, dev_score = 0.6089\n",
            "2023-12-21 10:09:26 INFO: Finished STEP 12520/50000, loss = 2.196097 (0.069 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:09:27 INFO: Finished STEP 12540/50000, loss = 2.635352 (0.077 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:09:29 INFO: Finished STEP 12560/50000, loss = 2.270967 (0.074 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:09:31 INFO: Finished STEP 12580/50000, loss = 2.718405 (0.078 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:09:32 INFO: Finished STEP 12600/50000, loss = 2.366889 (0.073 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:09:32 INFO: Evaluating on dev set...\n",
            "2023-12-21 10:09:45 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 10:09:45 INFO: 60.17\t54.75\t56.61\n",
            "2023-12-21 10:09:45 INFO: step 12600: train_loss = 2.209826, dev_score = 0.6017\n",
            "2023-12-21 10:09:46 INFO: Finished STEP 12620/50000, loss = 2.116706 (0.073 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:09:48 INFO: Finished STEP 12640/50000, loss = 2.553353 (0.076 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:09:49 INFO: Finished STEP 12660/50000, loss = 2.786180 (0.079 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:09:51 INFO: Finished STEP 12680/50000, loss = 1.014537 (0.057 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:09:52 INFO: Finished STEP 12700/50000, loss = 2.737791 (0.074 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:09:52 INFO: Evaluating on dev set...\n",
            "2023-12-21 10:10:04 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 10:10:04 INFO: 60.64\t54.93\t56.84\n",
            "2023-12-21 10:10:04 INFO: step 12700: train_loss = 2.165283, dev_score = 0.6064\n",
            "2023-12-21 10:10:05 INFO: Finished STEP 12720/50000, loss = 2.472106 (0.070 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:10:06 INFO: Finished STEP 12740/50000, loss = 1.487819 (0.057 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:10:08 INFO: Finished STEP 12760/50000, loss = 2.828150 (0.075 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:10:09 INFO: Finished STEP 12780/50000, loss = 1.825583 (0.075 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:10:11 INFO: Finished STEP 12800/50000, loss = 2.331705 (0.071 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:10:11 INFO: Evaluating on dev set...\n",
            "2023-12-21 10:10:22 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 10:10:22 INFO: 61.26\t55.59\t57.38\n",
            "2023-12-21 10:10:22 INFO: step 12800: train_loss = 2.110408, dev_score = 0.6126\n",
            "2023-12-21 10:10:23 INFO: Model saved to saved_models/depparse/vi_vtb_charlm_parser.pt\n",
            "2023-12-21 10:10:23 INFO: new best model saved.\n",
            "2023-12-21 10:10:24 INFO: Finished STEP 12820/50000, loss = 2.550476 (0.072 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:10:26 INFO: Finished STEP 12840/50000, loss = 2.018090 (0.079 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:10:27 INFO: Finished STEP 12860/50000, loss = 1.654591 (0.062 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:10:29 INFO: Finished STEP 12880/50000, loss = 2.462230 (0.070 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:10:30 INFO: Finished STEP 12900/50000, loss = 2.215180 (0.074 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:10:30 INFO: Evaluating on dev set...\n",
            "2023-12-21 10:10:43 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 10:10:43 INFO: 60.49\t54.84\t56.62\n",
            "2023-12-21 10:10:43 INFO: step 12900: train_loss = 2.145712, dev_score = 0.6049\n",
            "2023-12-21 10:10:45 INFO: Finished STEP 12920/50000, loss = 2.069395 (0.072 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:10:46 INFO: Finished STEP 12940/50000, loss = 2.396290 (0.074 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:10:48 INFO: Finished STEP 12960/50000, loss = 2.803856 (0.077 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:10:49 INFO: Finished STEP 12980/50000, loss = 2.483295 (0.074 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:10:51 INFO: Finished STEP 13000/50000, loss = 1.504069 (0.057 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:10:51 INFO: Evaluating on dev set...\n",
            "2023-12-21 10:11:02 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 10:11:02 INFO: 61.12\t55.50\t57.25\n",
            "2023-12-21 10:11:02 INFO: step 13000: train_loss = 2.102129, dev_score = 0.6112\n",
            "2023-12-21 10:11:04 INFO: Finished STEP 13020/50000, loss = 2.214120 (0.074 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:11:05 INFO: Finished STEP 13040/50000, loss = 2.308297 (0.073 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:11:07 INFO: Finished STEP 13060/50000, loss = 2.229421 (0.074 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:11:08 INFO: Finished STEP 13080/50000, loss = 2.427384 (0.078 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:11:10 INFO: Finished STEP 13100/50000, loss = 2.237863 (0.079 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:11:10 INFO: Evaluating on dev set...\n",
            "2023-12-21 10:11:21 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 10:11:21 INFO: 60.91\t54.54\t56.54\n",
            "2023-12-21 10:11:21 INFO: step 13100: train_loss = 2.155541, dev_score = 0.6091\n",
            "2023-12-21 10:11:22 INFO: Finished STEP 13120/50000, loss = 2.270782 (0.076 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:11:24 INFO: Finished STEP 13140/50000, loss = 2.392497 (0.080 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:11:26 INFO: Finished STEP 13160/50000, loss = 2.266751 (0.076 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:11:27 INFO: Finished STEP 13180/50000, loss = 2.174303 (0.073 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:11:29 INFO: Finished STEP 13200/50000, loss = 2.296126 (0.067 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:11:29 INFO: Evaluating on dev set...\n",
            "2023-12-21 10:11:41 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 10:11:41 INFO: 61.23\t55.26\t57.07\n",
            "2023-12-21 10:11:41 INFO: step 13200: train_loss = 2.158031, dev_score = 0.6123\n",
            "2023-12-21 10:11:42 INFO: Finished STEP 13220/50000, loss = 1.468941 (0.057 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:11:44 INFO: Finished STEP 13240/50000, loss = 1.167080 (0.057 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:11:45 INFO: Finished STEP 13260/50000, loss = 2.185162 (0.072 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:11:47 INFO: Finished STEP 13280/50000, loss = 1.811005 (0.065 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:11:48 INFO: Finished STEP 13300/50000, loss = 1.668320 (0.069 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:11:48 INFO: Evaluating on dev set...\n",
            "2023-12-21 10:12:00 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 10:12:00 INFO: 61.10\t54.88\t56.66\n",
            "2023-12-21 10:12:00 INFO: step 13300: train_loss = 2.113807, dev_score = 0.6110\n",
            "2023-12-21 10:12:02 INFO: Finished STEP 13320/50000, loss = 1.545084 (0.061 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:12:03 INFO: Finished STEP 13340/50000, loss = 2.162038 (0.072 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:12:04 INFO: Finished STEP 13360/50000, loss = 2.503755 (0.075 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:12:06 INFO: Finished STEP 13380/50000, loss = 2.674311 (0.075 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:12:08 INFO: Finished STEP 13400/50000, loss = 2.439165 (0.082 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:12:08 INFO: Evaluating on dev set...\n",
            "2023-12-21 10:12:19 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 10:12:19 INFO: 60.70\t54.88\t56.74\n",
            "2023-12-21 10:12:19 INFO: step 13400: train_loss = 2.095719, dev_score = 0.6070\n",
            "2023-12-21 10:12:20 INFO: Finished STEP 13420/50000, loss = 2.434205 (0.075 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:12:22 INFO: Finished STEP 13440/50000, loss = 2.526083 (0.075 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:12:23 INFO: Finished STEP 13460/50000, loss = 1.653256 (0.076 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:12:25 INFO: Finished STEP 13480/50000, loss = 1.726909 (0.066 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:12:26 INFO: Finished STEP 13500/50000, loss = 2.769326 (0.076 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:12:26 INFO: Evaluating on dev set...\n",
            "2023-12-21 10:12:39 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 10:12:39 INFO: 61.10\t55.25\t57.17\n",
            "2023-12-21 10:12:39 INFO: step 13500: train_loss = 2.150982, dev_score = 0.6110\n",
            "2023-12-21 10:12:41 INFO: Finished STEP 13520/50000, loss = 2.360849 (0.070 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:12:42 INFO: Finished STEP 13540/50000, loss = 2.562686 (0.074 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:12:44 INFO: Finished STEP 13560/50000, loss = 1.841840 (0.063 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:12:45 INFO: Finished STEP 13580/50000, loss = 1.856135 (0.068 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:12:47 INFO: Finished STEP 13600/50000, loss = 1.354092 (0.057 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:12:47 INFO: Evaluating on dev set...\n",
            "2023-12-21 10:12:58 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 10:12:58 INFO: 60.84\t54.67\t56.60\n",
            "2023-12-21 10:12:58 INFO: step 13600: train_loss = 2.056072, dev_score = 0.6084\n",
            "2023-12-21 10:13:00 INFO: Finished STEP 13620/50000, loss = 2.405672 (0.082 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:13:01 INFO: Finished STEP 13640/50000, loss = 1.759867 (0.064 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:13:03 INFO: Finished STEP 13660/50000, loss = 2.723346 (0.072 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:13:04 INFO: Finished STEP 13680/50000, loss = 2.745384 (0.077 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:13:06 INFO: Finished STEP 13700/50000, loss = 2.742638 (0.073 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:13:06 INFO: Evaluating on dev set...\n",
            "2023-12-21 10:13:18 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 10:13:18 INFO: 60.71\t55.14\t57.03\n",
            "2023-12-21 10:13:18 INFO: step 13700: train_loss = 2.160354, dev_score = 0.6071\n",
            "2023-12-21 10:13:19 INFO: Finished STEP 13720/50000, loss = 2.450900 (0.075 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:13:21 INFO: Finished STEP 13740/50000, loss = 1.846262 (0.071 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:13:22 INFO: Finished STEP 13760/50000, loss = 1.795177 (0.067 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:13:24 INFO: Finished STEP 13780/50000, loss = 1.653499 (0.066 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:13:25 INFO: Finished STEP 13800/50000, loss = 1.950817 (0.075 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:13:25 INFO: Evaluating on dev set...\n",
            "2023-12-21 10:13:38 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 10:13:38 INFO: 60.59\t54.31\t56.33\n",
            "2023-12-21 10:13:38 INFO: step 13800: train_loss = 2.117763, dev_score = 0.6059\n",
            "2023-12-21 10:13:39 INFO: Finished STEP 13820/50000, loss = 2.500512 (0.075 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:13:41 INFO: Finished STEP 13840/50000, loss = 1.617095 (0.061 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:13:42 INFO: Finished STEP 13860/50000, loss = 2.029790 (0.067 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:13:44 INFO: Finished STEP 13880/50000, loss = 2.376809 (0.076 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:13:45 INFO: Finished STEP 13900/50000, loss = 2.448757 (0.077 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:13:45 INFO: Evaluating on dev set...\n",
            "2023-12-21 10:13:57 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 10:13:57 INFO: 60.55\t54.53\t56.40\n",
            "2023-12-21 10:13:57 INFO: step 13900: train_loss = 2.143237, dev_score = 0.6055\n",
            "2023-12-21 10:13:58 INFO: Finished STEP 13920/50000, loss = 1.772589 (0.062 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:14:00 INFO: Finished STEP 13940/50000, loss = 2.385557 (0.078 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:14:01 INFO: Finished STEP 13960/50000, loss = 1.916344 (0.063 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:14:03 INFO: Finished STEP 13980/50000, loss = 1.870394 (0.064 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:14:04 INFO: Finished STEP 14000/50000, loss = 2.622602 (0.074 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:14:04 INFO: Evaluating on dev set...\n",
            "2023-12-21 10:14:16 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 10:14:16 INFO: 61.13\t54.82\t56.77\n",
            "2023-12-21 10:14:16 INFO: step 14000: train_loss = 2.108167, dev_score = 0.6113\n",
            "2023-12-21 10:14:17 INFO: Finished STEP 14020/50000, loss = 2.249347 (0.072 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:14:19 INFO: Finished STEP 14040/50000, loss = 2.716669 (0.073 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:14:20 INFO: Finished STEP 14060/50000, loss = 1.932342 (0.071 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:14:22 INFO: Finished STEP 14080/50000, loss = 1.540261 (0.058 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:14:23 INFO: Finished STEP 14100/50000, loss = 2.045788 (0.068 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:14:23 INFO: Evaluating on dev set...\n",
            "2023-12-21 10:14:36 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 10:14:36 INFO: 60.33\t54.52\t56.40\n",
            "2023-12-21 10:14:36 INFO: step 14100: train_loss = 2.113586, dev_score = 0.6033\n",
            "2023-12-21 10:14:37 INFO: Finished STEP 14120/50000, loss = 1.858126 (0.079 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:14:39 INFO: Finished STEP 14140/50000, loss = 2.452524 (0.074 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:14:40 INFO: Finished STEP 14160/50000, loss = 2.323406 (0.068 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:14:42 INFO: Finished STEP 14180/50000, loss = 1.307230 (0.057 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:14:43 INFO: Finished STEP 14200/50000, loss = 1.824598 (0.060 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:14:43 INFO: Evaluating on dev set...\n",
            "2023-12-21 10:14:54 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 10:14:54 INFO: 61.27\t55.22\t57.23\n",
            "2023-12-21 10:14:54 INFO: step 14200: train_loss = 2.090430, dev_score = 0.6127\n",
            "2023-12-21 10:14:55 INFO: Model saved to saved_models/depparse/vi_vtb_charlm_parser.pt\n",
            "2023-12-21 10:14:55 INFO: new best model saved.\n",
            "2023-12-21 10:14:56 INFO: Finished STEP 14220/50000, loss = 1.595996 (0.062 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:14:58 INFO: Finished STEP 14240/50000, loss = 3.139321 (0.077 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:14:59 INFO: Finished STEP 14260/50000, loss = 2.936952 (0.070 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:15:01 INFO: Finished STEP 14280/50000, loss = 1.912806 (0.078 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:15:02 INFO: Finished STEP 14300/50000, loss = 1.974649 (0.064 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:15:02 INFO: Evaluating on dev set...\n",
            "2023-12-21 10:15:14 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 10:15:14 INFO: 61.10\t54.97\t56.97\n",
            "2023-12-21 10:15:14 INFO: step 14300: train_loss = 2.089125, dev_score = 0.6110\n",
            "2023-12-21 10:15:15 INFO: Finished STEP 14320/50000, loss = 2.256673 (0.078 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:15:17 INFO: Finished STEP 14340/50000, loss = 2.692714 (0.079 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:15:18 INFO: Finished STEP 14360/50000, loss = 1.255839 (0.049 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:15:20 INFO: Finished STEP 14380/50000, loss = 2.616685 (0.078 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:15:21 INFO: Finished STEP 14400/50000, loss = 1.530055 (0.068 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:15:21 INFO: Evaluating on dev set...\n",
            "2023-12-21 10:15:33 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 10:15:33 INFO: 61.17\t54.70\t56.60\n",
            "2023-12-21 10:15:33 INFO: step 14400: train_loss = 2.106495, dev_score = 0.6117\n",
            "2023-12-21 10:15:35 INFO: Finished STEP 14420/50000, loss = 1.425537 (0.058 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:15:36 INFO: Finished STEP 14440/50000, loss = 2.653914 (0.085 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:15:38 INFO: Finished STEP 14460/50000, loss = 1.458727 (0.053 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:15:39 INFO: Finished STEP 14480/50000, loss = 2.767078 (0.068 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:15:41 INFO: Finished STEP 14500/50000, loss = 2.109530 (0.070 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:15:41 INFO: Evaluating on dev set...\n",
            "2023-12-21 10:15:52 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 10:15:52 INFO: 60.95\t54.66\t56.54\n",
            "2023-12-21 10:15:52 INFO: step 14500: train_loss = 2.079766, dev_score = 0.6095\n",
            "2023-12-21 10:15:54 INFO: Finished STEP 14520/50000, loss = 2.380211 (0.072 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:15:56 INFO: Finished STEP 14540/50000, loss = 2.317944 (0.080 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:15:57 INFO: Finished STEP 14560/50000, loss = 1.820608 (0.081 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:15:59 INFO: Finished STEP 14580/50000, loss = 1.779500 (0.073 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:16:00 INFO: Finished STEP 14600/50000, loss = 0.672256 (0.048 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:16:00 INFO: Evaluating on dev set...\n",
            "2023-12-21 10:16:11 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 10:16:11 INFO: 60.80\t54.76\t56.56\n",
            "2023-12-21 10:16:11 INFO: step 14600: train_loss = 2.129648, dev_score = 0.6080\n",
            "2023-12-21 10:16:13 INFO: Finished STEP 14620/50000, loss = 2.160436 (0.074 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:16:14 INFO: Finished STEP 14640/50000, loss = 2.557034 (0.081 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:16:16 INFO: Finished STEP 14660/50000, loss = 2.257578 (0.070 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:16:17 INFO: Finished STEP 14680/50000, loss = 1.412113 (0.057 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:16:19 INFO: Finished STEP 14700/50000, loss = 2.660118 (0.073 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:16:19 INFO: Evaluating on dev set...\n",
            "2023-12-21 10:16:31 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 10:16:31 INFO: 61.25\t55.24\t57.13\n",
            "2023-12-21 10:16:31 INFO: step 14700: train_loss = 2.074408, dev_score = 0.6125\n",
            "2023-12-21 10:16:33 INFO: Finished STEP 14720/50000, loss = 2.174998 (0.076 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:16:34 INFO: Finished STEP 14740/50000, loss = 2.533918 (0.076 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:16:36 INFO: Finished STEP 14760/50000, loss = 2.002609 (0.074 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:16:37 INFO: Finished STEP 14780/50000, loss = 1.828740 (0.068 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:16:38 INFO: Finished STEP 14800/50000, loss = 2.295939 (0.075 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:16:38 INFO: Evaluating on dev set...\n",
            "2023-12-21 10:16:50 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 10:16:50 INFO: 61.83\t56.04\t57.88\n",
            "2023-12-21 10:16:50 INFO: step 14800: train_loss = 2.035634, dev_score = 0.6183\n",
            "2023-12-21 10:16:51 INFO: Model saved to saved_models/depparse/vi_vtb_charlm_parser.pt\n",
            "2023-12-21 10:16:51 INFO: new best model saved.\n",
            "2023-12-21 10:16:52 INFO: Finished STEP 14820/50000, loss = 2.808254 (0.077 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:16:54 INFO: Finished STEP 14840/50000, loss = 1.812169 (0.067 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:16:55 INFO: Finished STEP 14860/50000, loss = 2.372669 (0.079 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:16:57 INFO: Finished STEP 14880/50000, loss = 2.506652 (0.089 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:16:58 INFO: Finished STEP 14900/50000, loss = 2.487120 (0.075 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:16:58 INFO: Evaluating on dev set...\n",
            "2023-12-21 10:17:10 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 10:17:10 INFO: 60.55\t54.38\t56.35\n",
            "2023-12-21 10:17:10 INFO: step 14900: train_loss = 2.055883, dev_score = 0.6055\n",
            "2023-12-21 10:17:12 INFO: Finished STEP 14920/50000, loss = 2.174938 (0.071 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:17:13 INFO: Finished STEP 14940/50000, loss = 2.252976 (0.082 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:17:15 INFO: Finished STEP 14960/50000, loss = 1.985346 (0.062 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:17:16 INFO: Finished STEP 14980/50000, loss = 2.161710 (0.081 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:17:18 INFO: Finished STEP 15000/50000, loss = 1.778396 (0.068 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:17:18 INFO: Evaluating on dev set...\n",
            "2023-12-21 10:17:30 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 10:17:30 INFO: 61.05\t54.89\t56.81\n",
            "2023-12-21 10:17:30 INFO: step 15000: train_loss = 2.058473, dev_score = 0.6105\n",
            "2023-12-21 10:17:31 INFO: Finished STEP 15020/50000, loss = 2.312529 (0.075 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:17:33 INFO: Finished STEP 15040/50000, loss = 2.179976 (0.074 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:17:34 INFO: Finished STEP 15060/50000, loss = 2.223982 (0.073 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:17:36 INFO: Finished STEP 15080/50000, loss = 1.670842 (0.074 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:17:37 INFO: Finished STEP 15100/50000, loss = 2.437292 (0.071 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:17:37 INFO: Evaluating on dev set...\n",
            "2023-12-21 10:17:49 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 10:17:49 INFO: 61.56\t55.68\t57.64\n",
            "2023-12-21 10:17:49 INFO: step 15100: train_loss = 2.047222, dev_score = 0.6156\n",
            "2023-12-21 10:17:50 INFO: Finished STEP 15120/50000, loss = 2.317218 (0.084 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:17:52 INFO: Finished STEP 15140/50000, loss = 2.318941 (0.079 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:17:53 INFO: Finished STEP 15160/50000, loss = 2.074285 (0.067 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:17:55 INFO: Finished STEP 15180/50000, loss = 1.849910 (0.064 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:17:57 INFO: Finished STEP 15200/50000, loss = 2.453802 (0.082 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:17:57 INFO: Evaluating on dev set...\n",
            "2023-12-21 10:18:08 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 10:18:08 INFO: 61.49\t55.53\t57.62\n",
            "2023-12-21 10:18:08 INFO: step 15200: train_loss = 2.086050, dev_score = 0.6149\n",
            "2023-12-21 10:18:10 INFO: Finished STEP 15220/50000, loss = 1.888453 (0.069 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:18:11 INFO: Finished STEP 15240/50000, loss = 1.980989 (0.078 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:18:13 INFO: Finished STEP 15260/50000, loss = 2.690829 (0.076 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:18:15 INFO: Finished STEP 15280/50000, loss = 2.333949 (0.081 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:18:16 INFO: Finished STEP 15300/50000, loss = 1.488858 (0.060 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:18:16 INFO: Evaluating on dev set...\n",
            "2023-12-21 10:18:28 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 10:18:28 INFO: 60.81\t54.88\t56.90\n",
            "2023-12-21 10:18:28 INFO: step 15300: train_loss = 2.058662, dev_score = 0.6081\n",
            "2023-12-21 10:18:29 INFO: Finished STEP 15320/50000, loss = 1.670706 (0.068 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:18:31 INFO: Finished STEP 15340/50000, loss = 2.273946 (0.084 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:18:32 INFO: Finished STEP 15360/50000, loss = 2.614153 (0.076 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:18:34 INFO: Finished STEP 15380/50000, loss = 2.286815 (0.083 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:18:35 INFO: Finished STEP 15400/50000, loss = 1.651717 (0.058 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:18:35 INFO: Evaluating on dev set...\n",
            "2023-12-21 10:18:47 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 10:18:47 INFO: 60.72\t54.70\t56.67\n",
            "2023-12-21 10:18:47 INFO: step 15400: train_loss = 1.994456, dev_score = 0.6072\n",
            "2023-12-21 10:18:49 INFO: Finished STEP 15420/50000, loss = 2.619429 (0.078 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:18:50 INFO: Finished STEP 15440/50000, loss = 2.050005 (0.076 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:18:52 INFO: Finished STEP 15460/50000, loss = 2.524284 (0.069 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:18:53 INFO: Finished STEP 15480/50000, loss = 1.622930 (0.069 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:18:55 INFO: Finished STEP 15500/50000, loss = 2.086282 (0.068 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:18:55 INFO: Evaluating on dev set...\n",
            "2023-12-21 10:19:06 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 10:19:06 INFO: 61.44\t55.85\t57.86\n",
            "2023-12-21 10:19:06 INFO: step 15500: train_loss = 2.043350, dev_score = 0.6144\n",
            "2023-12-21 10:19:08 INFO: Finished STEP 15520/50000, loss = 2.430814 (0.072 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:19:09 INFO: Finished STEP 15540/50000, loss = 2.145535 (0.073 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:19:11 INFO: Finished STEP 15560/50000, loss = 1.784312 (0.061 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:19:12 INFO: Finished STEP 15580/50000, loss = 2.065569 (0.065 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:19:14 INFO: Finished STEP 15600/50000, loss = 1.736864 (0.067 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:19:14 INFO: Evaluating on dev set...\n",
            "2023-12-21 10:19:25 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 10:19:25 INFO: 61.77\t55.72\t57.62\n",
            "2023-12-21 10:19:25 INFO: step 15600: train_loss = 2.082506, dev_score = 0.6177\n",
            "2023-12-21 10:19:27 INFO: Finished STEP 15620/50000, loss = 2.519702 (0.080 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:19:28 INFO: Finished STEP 15640/50000, loss = 2.332354 (0.074 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:19:30 INFO: Finished STEP 15660/50000, loss = 1.571059 (0.073 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:19:31 INFO: Finished STEP 15680/50000, loss = 2.598469 (0.074 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:19:33 INFO: Finished STEP 15700/50000, loss = 2.181313 (0.074 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:19:33 INFO: Evaluating on dev set...\n",
            "2023-12-21 10:19:45 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 10:19:45 INFO: 61.48\t55.65\t57.50\n",
            "2023-12-21 10:19:45 INFO: step 15700: train_loss = 2.057282, dev_score = 0.6148\n",
            "2023-12-21 10:19:46 INFO: Finished STEP 15720/50000, loss = 1.653023 (0.060 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:19:48 INFO: Finished STEP 15740/50000, loss = 1.832752 (0.072 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:19:49 INFO: Finished STEP 15760/50000, loss = 2.572100 (0.075 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:19:51 INFO: Finished STEP 15780/50000, loss = 1.415860 (0.056 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:19:52 INFO: Finished STEP 15800/50000, loss = 2.128374 (0.066 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:19:52 INFO: Evaluating on dev set...\n",
            "2023-12-21 10:20:04 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 10:20:04 INFO: 61.57\t55.75\t57.60\n",
            "2023-12-21 10:20:04 INFO: step 15800: train_loss = 1.989236, dev_score = 0.6157\n",
            "2023-12-21 10:20:05 INFO: Finished STEP 15820/50000, loss = 2.539950 (0.073 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:20:07 INFO: Finished STEP 15840/50000, loss = 1.353244 (0.058 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:20:08 INFO: Finished STEP 15860/50000, loss = 2.066998 (0.078 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:20:10 INFO: Finished STEP 15880/50000, loss = 1.814590 (0.074 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:20:11 INFO: Finished STEP 15900/50000, loss = 2.202280 (0.066 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:20:11 INFO: Evaluating on dev set...\n",
            "2023-12-21 10:20:23 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 10:20:23 INFO: 61.17\t55.27\t57.27\n",
            "2023-12-21 10:20:23 INFO: step 15900: train_loss = 2.064233, dev_score = 0.6117\n",
            "2023-12-21 10:20:24 INFO: Finished STEP 15920/50000, loss = 1.866742 (0.076 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:20:26 INFO: Finished STEP 15940/50000, loss = 2.050238 (0.070 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:20:28 INFO: Finished STEP 15960/50000, loss = 2.109911 (0.076 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:20:29 INFO: Finished STEP 15980/50000, loss = 2.556599 (0.073 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:20:30 INFO: Finished STEP 16000/50000, loss = 1.668755 (0.066 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:20:30 INFO: Evaluating on dev set...\n",
            "2023-12-21 10:20:42 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 10:20:42 INFO: 61.44\t55.69\t57.55\n",
            "2023-12-21 10:20:42 INFO: step 16000: train_loss = 2.017393, dev_score = 0.6144\n",
            "2023-12-21 10:20:44 INFO: Finished STEP 16020/50000, loss = 2.581912 (0.081 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:20:45 INFO: Finished STEP 16040/50000, loss = 2.134463 (0.068 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:20:47 INFO: Finished STEP 16060/50000, loss = 2.735084 (0.077 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:20:48 INFO: Finished STEP 16080/50000, loss = 2.159636 (0.080 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:20:50 INFO: Finished STEP 16100/50000, loss = 2.307802 (0.072 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:20:50 INFO: Evaluating on dev set...\n",
            "2023-12-21 10:21:01 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 10:21:01 INFO: 61.42\t55.40\t57.37\n",
            "2023-12-21 10:21:01 INFO: step 16100: train_loss = 2.072856, dev_score = 0.6142\n",
            "2023-12-21 10:21:03 INFO: Finished STEP 16120/50000, loss = 1.501563 (0.055 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:21:04 INFO: Finished STEP 16140/50000, loss = 2.514025 (0.068 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:21:06 INFO: Finished STEP 16160/50000, loss = 3.113685 (0.076 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:21:08 INFO: Finished STEP 16180/50000, loss = 2.192836 (0.073 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:21:09 INFO: Finished STEP 16200/50000, loss = 2.270958 (0.077 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:21:09 INFO: Evaluating on dev set...\n",
            "2023-12-21 10:21:21 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 10:21:21 INFO: 61.13\t55.17\t57.14\n",
            "2023-12-21 10:21:21 INFO: step 16200: train_loss = 2.006060, dev_score = 0.6113\n",
            "2023-12-21 10:21:22 INFO: Finished STEP 16220/50000, loss = 2.031198 (0.077 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:21:24 INFO: Finished STEP 16240/50000, loss = 2.642898 (0.072 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:21:25 INFO: Finished STEP 16260/50000, loss = 1.797259 (0.066 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:21:27 INFO: Finished STEP 16280/50000, loss = 1.142345 (0.055 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:21:28 INFO: Finished STEP 16300/50000, loss = 2.767569 (0.076 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:21:28 INFO: Evaluating on dev set...\n",
            "2023-12-21 10:21:40 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 10:21:40 INFO: 61.93\t55.92\t57.97\n",
            "2023-12-21 10:21:40 INFO: step 16300: train_loss = 2.058347, dev_score = 0.6193\n",
            "2023-12-21 10:21:41 INFO: Model saved to saved_models/depparse/vi_vtb_charlm_parser.pt\n",
            "2023-12-21 10:21:41 INFO: new best model saved.\n",
            "2023-12-21 10:21:42 INFO: Finished STEP 16320/50000, loss = 1.531204 (0.059 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:21:44 INFO: Finished STEP 16340/50000, loss = 2.585262 (0.070 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:21:45 INFO: Finished STEP 16360/50000, loss = 1.575619 (0.061 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:21:47 INFO: Finished STEP 16380/50000, loss = 2.177048 (0.074 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:21:48 INFO: Finished STEP 16400/50000, loss = 2.132033 (0.072 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:21:48 INFO: Evaluating on dev set...\n",
            "2023-12-21 10:22:00 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 10:22:00 INFO: 61.24\t55.48\t57.42\n",
            "2023-12-21 10:22:00 INFO: step 16400: train_loss = 2.020985, dev_score = 0.6124\n",
            "2023-12-21 10:22:02 INFO: Finished STEP 16420/50000, loss = 2.194948 (0.069 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:22:03 INFO: Finished STEP 16440/50000, loss = 1.869425 (0.073 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:22:05 INFO: Finished STEP 16460/50000, loss = 2.318422 (0.080 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:22:06 INFO: Finished STEP 16480/50000, loss = 2.163251 (0.078 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:22:08 INFO: Finished STEP 16500/50000, loss = 2.432235 (0.072 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:22:08 INFO: Evaluating on dev set...\n",
            "2023-12-21 10:22:19 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 10:22:19 INFO: 61.73\t55.97\t57.98\n",
            "2023-12-21 10:22:19 INFO: step 16500: train_loss = 1.985422, dev_score = 0.6173\n",
            "2023-12-21 10:22:20 INFO: Finished STEP 16520/50000, loss = 2.275928 (0.065 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:22:22 INFO: Finished STEP 16540/50000, loss = 2.024838 (0.084 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:22:23 INFO: Finished STEP 16560/50000, loss = 1.863423 (0.066 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:22:25 INFO: Finished STEP 16580/50000, loss = 2.171695 (0.079 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:22:26 INFO: Finished STEP 16600/50000, loss = 1.535556 (0.054 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:22:26 INFO: Evaluating on dev set...\n",
            "2023-12-21 10:22:38 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 10:22:38 INFO: 61.53\t55.69\t57.47\n",
            "2023-12-21 10:22:38 INFO: step 16600: train_loss = 2.059096, dev_score = 0.6153\n",
            "2023-12-21 10:22:40 INFO: Finished STEP 16620/50000, loss = 2.331158 (0.073 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:22:42 INFO: Finished STEP 16640/50000, loss = 2.728790 (0.076 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:22:43 INFO: Finished STEP 16660/50000, loss = 2.777027 (0.079 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:22:44 INFO: Finished STEP 16680/50000, loss = 1.815079 (0.080 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:22:46 INFO: Finished STEP 16700/50000, loss = 2.171127 (0.072 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:22:46 INFO: Evaluating on dev set...\n",
            "2023-12-21 10:22:57 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 10:22:57 INFO: 61.57\t56.06\t57.95\n",
            "2023-12-21 10:22:57 INFO: step 16700: train_loss = 2.032209, dev_score = 0.6157\n",
            "2023-12-21 10:22:59 INFO: Finished STEP 16720/50000, loss = 2.104666 (0.075 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:23:00 INFO: Finished STEP 16740/50000, loss = 1.800043 (0.061 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:23:02 INFO: Finished STEP 16760/50000, loss = 2.547649 (0.076 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:23:03 INFO: Finished STEP 16780/50000, loss = 2.650289 (0.074 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:23:05 INFO: Finished STEP 16800/50000, loss = 2.293478 (0.071 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:23:05 INFO: Evaluating on dev set...\n",
            "2023-12-21 10:23:16 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 10:23:16 INFO: 61.52\t56.14\t57.92\n",
            "2023-12-21 10:23:16 INFO: step 16800: train_loss = 2.003629, dev_score = 0.6152\n",
            "2023-12-21 10:23:18 INFO: Finished STEP 16820/50000, loss = 1.925742 (0.069 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:23:19 INFO: Finished STEP 16840/50000, loss = 1.046468 (0.054 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:23:21 INFO: Finished STEP 16860/50000, loss = 1.916784 (0.069 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:23:22 INFO: Finished STEP 16880/50000, loss = 1.588745 (0.067 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:23:23 INFO: Finished STEP 16900/50000, loss = 1.354841 (0.055 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:23:23 INFO: Evaluating on dev set...\n",
            "2023-12-21 10:23:36 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 10:23:36 INFO: 61.51\t55.50\t57.30\n",
            "2023-12-21 10:23:36 INFO: step 16900: train_loss = 1.958185, dev_score = 0.6151\n",
            "2023-12-21 10:23:37 INFO: Finished STEP 16920/50000, loss = 2.822078 (0.081 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:23:39 INFO: Finished STEP 16940/50000, loss = 2.594498 (0.076 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:23:40 INFO: Finished STEP 16960/50000, loss = 1.597919 (0.057 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:23:42 INFO: Finished STEP 16980/50000, loss = 1.475909 (0.062 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:23:43 INFO: Finished STEP 17000/50000, loss = 2.065511 (0.069 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:23:43 INFO: Evaluating on dev set...\n",
            "2023-12-21 10:23:55 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 10:23:55 INFO: 61.29\t55.42\t57.27\n",
            "2023-12-21 10:23:55 INFO: step 17000: train_loss = 2.032701, dev_score = 0.6129\n",
            "2023-12-21 10:23:56 INFO: Finished STEP 17020/50000, loss = 2.204285 (0.067 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:23:58 INFO: Finished STEP 17040/50000, loss = 2.310664 (0.076 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:23:59 INFO: Finished STEP 17060/50000, loss = 1.990456 (0.067 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:24:01 INFO: Finished STEP 17080/50000, loss = 1.775865 (0.069 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:24:02 INFO: Finished STEP 17100/50000, loss = 2.845860 (0.079 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:24:02 INFO: Evaluating on dev set...\n",
            "2023-12-21 10:24:14 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 10:24:14 INFO: 62.14\t56.21\t58.06\n",
            "2023-12-21 10:24:14 INFO: step 17100: train_loss = 2.027662, dev_score = 0.6214\n",
            "2023-12-21 10:24:14 INFO: Model saved to saved_models/depparse/vi_vtb_charlm_parser.pt\n",
            "2023-12-21 10:24:14 INFO: new best model saved.\n",
            "2023-12-21 10:24:16 INFO: Finished STEP 17120/50000, loss = 1.853548 (0.077 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:24:17 INFO: Finished STEP 17140/50000, loss = 2.232281 (0.074 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:24:19 INFO: Finished STEP 17160/50000, loss = 1.950627 (0.072 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:24:20 INFO: Finished STEP 17180/50000, loss = 1.502328 (0.056 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:24:22 INFO: Finished STEP 17200/50000, loss = 2.225193 (0.069 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:24:22 INFO: Evaluating on dev set...\n",
            "2023-12-21 10:24:34 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 10:24:34 INFO: 61.70\t55.29\t57.17\n",
            "2023-12-21 10:24:34 INFO: step 17200: train_loss = 1.962286, dev_score = 0.6170\n",
            "2023-12-21 10:24:35 INFO: Finished STEP 17220/50000, loss = 1.043161 (0.054 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:24:37 INFO: Finished STEP 17240/50000, loss = 1.675016 (0.068 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:24:38 INFO: Finished STEP 17260/50000, loss = 1.527650 (0.056 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:24:40 INFO: Finished STEP 17280/50000, loss = 1.196301 (0.058 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:24:41 INFO: Finished STEP 17300/50000, loss = 2.011930 (0.074 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:24:41 INFO: Evaluating on dev set...\n",
            "2023-12-21 10:24:53 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 10:24:53 INFO: 61.93\t56.50\t58.41\n",
            "2023-12-21 10:24:53 INFO: step 17300: train_loss = 1.989364, dev_score = 0.6193\n",
            "2023-12-21 10:24:54 INFO: Finished STEP 17320/50000, loss = 1.754705 (0.063 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:24:56 INFO: Finished STEP 17340/50000, loss = 1.785702 (0.065 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:24:57 INFO: Finished STEP 17360/50000, loss = 2.508420 (0.080 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:24:59 INFO: Finished STEP 17380/50000, loss = 1.518620 (0.067 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:25:00 INFO: Finished STEP 17400/50000, loss = 1.729680 (0.056 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:25:00 INFO: Evaluating on dev set...\n",
            "2023-12-21 10:25:11 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 10:25:11 INFO: 61.78\t55.57\t57.36\n",
            "2023-12-21 10:25:11 INFO: step 17400: train_loss = 1.978209, dev_score = 0.6178\n",
            "2023-12-21 10:25:13 INFO: Finished STEP 17420/50000, loss = 2.274544 (0.074 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:25:15 INFO: Finished STEP 17440/50000, loss = 2.009658 (0.069 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:25:16 INFO: Finished STEP 17460/50000, loss = 1.775771 (0.073 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:25:18 INFO: Finished STEP 17480/50000, loss = 1.822467 (0.075 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:25:19 INFO: Finished STEP 17500/50000, loss = 1.197336 (0.054 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:25:19 INFO: Evaluating on dev set...\n",
            "2023-12-21 10:25:31 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 10:25:31 INFO: 62.06\t56.08\t57.89\n",
            "2023-12-21 10:25:31 INFO: step 17500: train_loss = 1.991800, dev_score = 0.6206\n",
            "2023-12-21 10:25:33 INFO: Finished STEP 17520/50000, loss = 2.044872 (0.078 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:25:34 INFO: Finished STEP 17540/50000, loss = 1.873499 (0.063 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:25:36 INFO: Finished STEP 17560/50000, loss = 2.193141 (0.074 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:25:37 INFO: Finished STEP 17580/50000, loss = 2.006951 (0.069 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:25:39 INFO: Finished STEP 17600/50000, loss = 1.919801 (0.077 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:25:39 INFO: Evaluating on dev set...\n",
            "2023-12-21 10:25:51 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 10:25:51 INFO: 61.63\t55.92\t57.70\n",
            "2023-12-21 10:25:51 INFO: step 17600: train_loss = 1.958372, dev_score = 0.6163\n",
            "2023-12-21 10:25:52 INFO: Finished STEP 17620/50000, loss = 2.225585 (0.084 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:25:54 INFO: Finished STEP 17640/50000, loss = 2.407316 (0.076 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:25:55 INFO: Finished STEP 17660/50000, loss = 1.839126 (0.067 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:25:57 INFO: Finished STEP 17680/50000, loss = 2.304273 (0.073 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:25:58 INFO: Finished STEP 17700/50000, loss = 2.405916 (0.075 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:25:58 INFO: Evaluating on dev set...\n",
            "2023-12-21 10:26:10 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 10:26:10 INFO: 61.92\t56.23\t58.16\n",
            "2023-12-21 10:26:10 INFO: step 17700: train_loss = 2.026381, dev_score = 0.6192\n",
            "2023-12-21 10:26:11 INFO: Finished STEP 17720/50000, loss = 2.844414 (0.081 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:26:13 INFO: Finished STEP 17740/50000, loss = 1.895605 (0.072 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:26:14 INFO: Finished STEP 17760/50000, loss = 2.354486 (0.075 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:26:16 INFO: Finished STEP 17780/50000, loss = 1.615507 (0.070 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:26:17 INFO: Finished STEP 17800/50000, loss = 0.708499 (0.052 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:26:17 INFO: Evaluating on dev set...\n",
            "2023-12-21 10:26:29 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 10:26:29 INFO: 61.56\t56.05\t57.85\n",
            "2023-12-21 10:26:29 INFO: step 17800: train_loss = 1.954456, dev_score = 0.6156\n",
            "2023-12-21 10:26:31 INFO: Finished STEP 17820/50000, loss = 2.408889 (0.068 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:26:32 INFO: Finished STEP 17840/50000, loss = 2.823349 (0.077 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:26:34 INFO: Finished STEP 17860/50000, loss = 2.243171 (0.072 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:26:35 INFO: Finished STEP 17880/50000, loss = 2.477217 (0.079 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:26:37 INFO: Finished STEP 17900/50000, loss = 1.135947 (0.056 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:26:37 INFO: Evaluating on dev set...\n",
            "2023-12-21 10:26:48 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 10:26:48 INFO: 61.40\t55.50\t57.39\n",
            "2023-12-21 10:26:48 INFO: step 17900: train_loss = 1.951568, dev_score = 0.6140\n",
            "2023-12-21 10:26:50 INFO: Finished STEP 17920/50000, loss = 1.620820 (0.068 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:26:51 INFO: Finished STEP 17940/50000, loss = 1.569691 (0.061 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:26:53 INFO: Finished STEP 17960/50000, loss = 2.323299 (0.082 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:26:54 INFO: Finished STEP 17980/50000, loss = 1.735496 (0.077 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:26:56 INFO: Finished STEP 18000/50000, loss = 2.317977 (0.074 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:26:56 INFO: Evaluating on dev set...\n",
            "2023-12-21 10:27:07 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 10:27:07 INFO: 62.00\t56.08\t57.97\n",
            "2023-12-21 10:27:07 INFO: step 18000: train_loss = 2.029074, dev_score = 0.6200\n",
            "2023-12-21 10:27:09 INFO: Finished STEP 18020/50000, loss = 1.865234 (0.075 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:27:10 INFO: Finished STEP 18040/50000, loss = 1.499582 (0.065 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:27:12 INFO: Finished STEP 18060/50000, loss = 1.608051 (0.057 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:27:13 INFO: Finished STEP 18080/50000, loss = 2.267449 (0.078 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:27:15 INFO: Finished STEP 18100/50000, loss = 2.158227 (0.088 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:27:15 INFO: Evaluating on dev set...\n",
            "2023-12-21 10:27:27 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 10:27:27 INFO: 62.45\t56.59\t58.47\n",
            "2023-12-21 10:27:27 INFO: step 18100: train_loss = 1.966995, dev_score = 0.6245\n",
            "2023-12-21 10:27:28 INFO: Model saved to saved_models/depparse/vi_vtb_charlm_parser.pt\n",
            "2023-12-21 10:27:28 INFO: new best model saved.\n",
            "2023-12-21 10:27:29 INFO: Finished STEP 18120/50000, loss = 1.950206 (0.072 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:27:31 INFO: Finished STEP 18140/50000, loss = 2.207975 (0.073 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:27:32 INFO: Finished STEP 18160/50000, loss = 1.615272 (0.066 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:27:34 INFO: Finished STEP 18180/50000, loss = 1.947419 (0.081 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:27:35 INFO: Finished STEP 18200/50000, loss = 2.705288 (0.077 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:27:35 INFO: Evaluating on dev set...\n",
            "2023-12-21 10:27:48 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 10:27:48 INFO: 61.92\t56.27\t58.07\n",
            "2023-12-21 10:27:48 INFO: step 18200: train_loss = 1.897213, dev_score = 0.6192\n",
            "2023-12-21 10:27:49 INFO: Finished STEP 18220/50000, loss = 1.482459 (0.056 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:27:51 INFO: Finished STEP 18240/50000, loss = 2.027757 (0.074 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:27:52 INFO: Finished STEP 18260/50000, loss = 2.025378 (0.077 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:27:54 INFO: Finished STEP 18280/50000, loss = 1.440345 (0.054 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:27:55 INFO: Finished STEP 18300/50000, loss = 2.250722 (0.077 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:27:55 INFO: Evaluating on dev set...\n",
            "2023-12-21 10:28:07 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 10:28:07 INFO: 62.03\t56.06\t57.90\n",
            "2023-12-21 10:28:07 INFO: step 18300: train_loss = 1.957386, dev_score = 0.6203\n",
            "2023-12-21 10:28:08 INFO: Finished STEP 18320/50000, loss = 1.993912 (0.068 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:28:10 INFO: Finished STEP 18340/50000, loss = 1.978814 (0.070 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:28:11 INFO: Finished STEP 18360/50000, loss = 1.364454 (0.060 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:28:13 INFO: Finished STEP 18380/50000, loss = 1.730345 (0.078 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:28:14 INFO: Finished STEP 18400/50000, loss = 1.812670 (0.074 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:28:14 INFO: Evaluating on dev set...\n",
            "2023-12-21 10:28:26 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 10:28:26 INFO: 62.06\t56.43\t58.24\n",
            "2023-12-21 10:28:26 INFO: step 18400: train_loss = 1.960845, dev_score = 0.6206\n",
            "2023-12-21 10:28:28 INFO: Finished STEP 18420/50000, loss = 2.105094 (0.084 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:28:29 INFO: Finished STEP 18440/50000, loss = 2.141567 (0.077 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:28:31 INFO: Finished STEP 18460/50000, loss = 1.209361 (0.051 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:28:32 INFO: Finished STEP 18480/50000, loss = 2.315847 (0.078 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:28:34 INFO: Finished STEP 18500/50000, loss = 2.334191 (0.076 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:28:34 INFO: Evaluating on dev set...\n",
            "2023-12-21 10:28:46 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 10:28:46 INFO: 62.26\t56.37\t58.16\n",
            "2023-12-21 10:28:46 INFO: step 18500: train_loss = 1.946583, dev_score = 0.6226\n",
            "2023-12-21 10:28:47 INFO: Finished STEP 18520/50000, loss = 1.667300 (0.056 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:28:49 INFO: Finished STEP 18540/50000, loss = 1.656677 (0.063 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:28:50 INFO: Finished STEP 18560/50000, loss = 1.739422 (0.078 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:28:52 INFO: Finished STEP 18580/50000, loss = 1.285238 (0.062 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:28:53 INFO: Finished STEP 18600/50000, loss = 2.139669 (0.074 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:28:53 INFO: Evaluating on dev set...\n",
            "2023-12-21 10:29:05 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 10:29:05 INFO: 62.43\t56.65\t58.49\n",
            "2023-12-21 10:29:05 INFO: step 18600: train_loss = 1.920998, dev_score = 0.6243\n",
            "2023-12-21 10:29:06 INFO: Finished STEP 18620/50000, loss = 2.245546 (0.081 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:29:08 INFO: Finished STEP 18640/50000, loss = 1.957027 (0.066 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:29:09 INFO: Finished STEP 18660/50000, loss = 1.445136 (0.066 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:29:11 INFO: Finished STEP 18680/50000, loss = 1.616160 (0.059 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:29:12 INFO: Finished STEP 18700/50000, loss = 2.023613 (0.068 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:29:12 INFO: Evaluating on dev set...\n",
            "2023-12-21 10:29:24 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 10:29:24 INFO: 62.38\t56.77\t58.52\n",
            "2023-12-21 10:29:24 INFO: step 18700: train_loss = 1.999736, dev_score = 0.6238\n",
            "2023-12-21 10:29:26 INFO: Finished STEP 18720/50000, loss = 1.903793 (0.069 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:29:28 INFO: Finished STEP 18740/50000, loss = 1.933807 (0.079 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:29:29 INFO: Finished STEP 18760/50000, loss = 2.226750 (0.072 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:29:31 INFO: Finished STEP 18780/50000, loss = 2.285162 (0.071 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:29:32 INFO: Finished STEP 18800/50000, loss = 1.712730 (0.083 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:29:32 INFO: Evaluating on dev set...\n",
            "2023-12-21 10:29:44 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 10:29:44 INFO: 61.38\t55.17\t57.02\n",
            "2023-12-21 10:29:44 INFO: step 18800: train_loss = 1.948959, dev_score = 0.6138\n",
            "2023-12-21 10:29:45 INFO: Finished STEP 18820/50000, loss = 2.310963 (0.074 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:29:47 INFO: Finished STEP 18840/50000, loss = 2.164564 (0.081 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:29:48 INFO: Finished STEP 18860/50000, loss = 1.342715 (0.055 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:29:50 INFO: Finished STEP 18880/50000, loss = 2.158807 (0.081 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:29:51 INFO: Finished STEP 18900/50000, loss = 2.450478 (0.084 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:29:51 INFO: Evaluating on dev set...\n",
            "2023-12-21 10:30:03 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 10:30:03 INFO: 61.57\t55.17\t56.97\n",
            "2023-12-21 10:30:03 INFO: step 18900: train_loss = 1.927741, dev_score = 0.6157\n",
            "2023-12-21 10:30:04 INFO: Finished STEP 18920/50000, loss = 1.716872 (0.070 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:30:06 INFO: Finished STEP 18940/50000, loss = 2.347736 (0.076 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:30:07 INFO: Finished STEP 18960/50000, loss = 1.518356 (0.068 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:30:09 INFO: Finished STEP 18980/50000, loss = 1.186228 (0.057 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:30:10 INFO: Finished STEP 19000/50000, loss = 1.683565 (0.062 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:30:10 INFO: Evaluating on dev set...\n",
            "2023-12-21 10:30:23 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 10:30:23 INFO: 61.90\t56.09\t57.92\n",
            "2023-12-21 10:30:23 INFO: step 19000: train_loss = 1.970458, dev_score = 0.6190\n",
            "2023-12-21 10:30:25 INFO: Finished STEP 19020/50000, loss = 2.004250 (0.080 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:30:26 INFO: Finished STEP 19040/50000, loss = 1.677647 (0.071 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:30:28 INFO: Finished STEP 19060/50000, loss = 1.687850 (0.062 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:30:29 INFO: Finished STEP 19080/50000, loss = 1.376563 (0.065 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:30:31 INFO: Finished STEP 19100/50000, loss = 1.179849 (0.056 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:30:31 INFO: Evaluating on dev set...\n",
            "2023-12-21 10:30:42 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 10:30:42 INFO: 61.64\t55.44\t57.29\n",
            "2023-12-21 10:30:42 INFO: step 19100: train_loss = 1.869680, dev_score = 0.6164\n",
            "2023-12-21 10:30:44 INFO: Finished STEP 19120/50000, loss = 2.173959 (0.076 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:30:45 INFO: Finished STEP 19140/50000, loss = 2.021964 (0.076 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:30:47 INFO: Finished STEP 19160/50000, loss = 1.748442 (0.067 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:30:48 INFO: Finished STEP 19180/50000, loss = 2.174910 (0.075 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:30:50 INFO: Finished STEP 19200/50000, loss = 2.242083 (0.078 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:30:50 INFO: Evaluating on dev set...\n",
            "2023-12-21 10:31:02 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 10:31:02 INFO: 62.09\t56.06\t57.90\n",
            "2023-12-21 10:31:02 INFO: step 19200: train_loss = 1.957364, dev_score = 0.6209\n",
            "2023-12-21 10:31:03 INFO: Finished STEP 19220/50000, loss = 2.109432 (0.079 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:31:05 INFO: Finished STEP 19240/50000, loss = 1.205988 (0.054 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:31:06 INFO: Finished STEP 19260/50000, loss = 2.219390 (0.080 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:31:08 INFO: Finished STEP 19280/50000, loss = 1.935330 (0.084 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:31:09 INFO: Finished STEP 19300/50000, loss = 2.284776 (0.077 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:31:09 INFO: Evaluating on dev set...\n",
            "2023-12-21 10:31:22 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 10:31:22 INFO: 62.23\t56.47\t58.20\n",
            "2023-12-21 10:31:22 INFO: step 19300: train_loss = 1.921418, dev_score = 0.6223\n",
            "2023-12-21 10:31:23 INFO: Finished STEP 19320/50000, loss = 2.411979 (0.076 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:31:25 INFO: Finished STEP 19340/50000, loss = 0.428813 (0.045 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:31:26 INFO: Finished STEP 19360/50000, loss = 1.758746 (0.074 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:31:28 INFO: Finished STEP 19380/50000, loss = 1.925200 (0.077 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:31:29 INFO: Finished STEP 19400/50000, loss = 2.383770 (0.077 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:31:29 INFO: Evaluating on dev set...\n",
            "2023-12-21 10:31:41 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 10:31:41 INFO: 62.03\t55.97\t57.74\n",
            "2023-12-21 10:31:41 INFO: step 19400: train_loss = 1.916747, dev_score = 0.6203\n",
            "2023-12-21 10:31:43 INFO: Finished STEP 19420/50000, loss = 1.415888 (0.058 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:31:44 INFO: Finished STEP 19440/50000, loss = 2.532798 (0.076 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:31:46 INFO: Finished STEP 19460/50000, loss = 1.669993 (0.073 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:31:47 INFO: Finished STEP 19480/50000, loss = 2.479671 (0.075 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:31:49 INFO: Finished STEP 19500/50000, loss = 2.331255 (0.073 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:31:49 INFO: Evaluating on dev set...\n",
            "2023-12-21 10:32:00 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 10:32:00 INFO: 61.81\t55.76\t57.71\n",
            "2023-12-21 10:32:00 INFO: step 19500: train_loss = 1.900177, dev_score = 0.6181\n",
            "2023-12-21 10:32:02 INFO: Finished STEP 19520/50000, loss = 1.796843 (0.077 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:32:03 INFO: Finished STEP 19540/50000, loss = 1.941888 (0.064 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:32:05 INFO: Finished STEP 19560/50000, loss = 1.712018 (0.065 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:32:06 INFO: Finished STEP 19580/50000, loss = 2.288181 (0.067 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:32:08 INFO: Finished STEP 19600/50000, loss = 1.737977 (0.072 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:32:08 INFO: Evaluating on dev set...\n",
            "2023-12-21 10:32:20 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 10:32:20 INFO: 61.85\t55.97\t57.85\n",
            "2023-12-21 10:32:20 INFO: step 19600: train_loss = 1.924896, dev_score = 0.6185\n",
            "2023-12-21 10:32:22 INFO: Finished STEP 19620/50000, loss = 2.073279 (0.081 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:32:23 INFO: Finished STEP 19640/50000, loss = 1.205062 (0.051 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:32:25 INFO: Finished STEP 19660/50000, loss = 1.447198 (0.056 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:32:26 INFO: Finished STEP 19680/50000, loss = 1.503409 (0.057 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:32:28 INFO: Finished STEP 19700/50000, loss = 1.494950 (0.071 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:32:28 INFO: Evaluating on dev set...\n",
            "2023-12-21 10:32:39 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 10:32:39 INFO: 62.17\t56.24\t58.00\n",
            "2023-12-21 10:32:39 INFO: step 19700: train_loss = 1.878878, dev_score = 0.6217\n",
            "2023-12-21 10:32:40 INFO: Finished STEP 19720/50000, loss = 2.107312 (0.067 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:32:42 INFO: Finished STEP 19740/50000, loss = 2.253731 (0.074 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:32:43 INFO: Finished STEP 19760/50000, loss = 1.703735 (0.067 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:32:45 INFO: Finished STEP 19780/50000, loss = 1.593691 (0.067 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:32:46 INFO: Finished STEP 19800/50000, loss = 1.541970 (0.064 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:32:46 INFO: Evaluating on dev set...\n",
            "2023-12-21 10:32:58 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 10:32:58 INFO: 61.88\t56.38\t58.21\n",
            "2023-12-21 10:32:58 INFO: step 19800: train_loss = 1.941972, dev_score = 0.6188\n",
            "2023-12-21 10:33:00 INFO: Finished STEP 19820/50000, loss = 2.108908 (0.073 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:33:01 INFO: Finished STEP 19840/50000, loss = 1.793226 (0.071 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:33:03 INFO: Finished STEP 19860/50000, loss = 1.918008 (0.067 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:33:04 INFO: Finished STEP 19880/50000, loss = 1.846694 (0.064 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:33:06 INFO: Finished STEP 19900/50000, loss = 2.010314 (0.071 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:33:06 INFO: Evaluating on dev set...\n",
            "2023-12-21 10:33:18 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 10:33:18 INFO: 61.62\t56.13\t57.89\n",
            "2023-12-21 10:33:18 INFO: step 19900: train_loss = 1.903533, dev_score = 0.6162\n",
            "2023-12-21 10:33:20 INFO: Finished STEP 19920/50000, loss = 1.320431 (0.058 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:33:21 INFO: Finished STEP 19940/50000, loss = 2.352027 (0.080 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:33:23 INFO: Finished STEP 19960/50000, loss = 1.833812 (0.065 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:33:24 INFO: Finished STEP 19980/50000, loss = 1.445474 (0.068 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:33:26 INFO: Finished STEP 20000/50000, loss = 2.256316 (0.070 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:33:26 INFO: Evaluating on dev set...\n",
            "2023-12-21 10:33:37 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 10:33:37 INFO: 61.75\t55.97\t57.77\n",
            "2023-12-21 10:33:37 INFO: step 20000: train_loss = 1.960703, dev_score = 0.6175\n",
            "2023-12-21 10:33:38 INFO: Finished STEP 20020/50000, loss = 2.237904 (0.075 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:33:40 INFO: Finished STEP 20040/50000, loss = 1.219165 (0.058 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:33:41 INFO: Finished STEP 20060/50000, loss = 1.604534 (0.058 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:33:43 INFO: Finished STEP 20080/50000, loss = 2.072837 (0.071 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:33:44 INFO: Finished STEP 20100/50000, loss = 1.177135 (0.057 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:33:44 INFO: Evaluating on dev set...\n",
            "2023-12-21 10:33:56 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 10:33:56 INFO: 62.38\t56.50\t58.30\n",
            "2023-12-21 10:33:56 INFO: step 20100: train_loss = 1.851784, dev_score = 0.6238\n",
            "2023-12-21 10:33:58 INFO: Finished STEP 20120/50000, loss = 1.886575 (0.084 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:33:59 INFO: Finished STEP 20140/50000, loss = 1.473512 (0.070 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:34:01 INFO: Finished STEP 20160/50000, loss = 2.813914 (0.081 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:34:02 INFO: Finished STEP 20180/50000, loss = 2.994879 (0.077 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:34:04 INFO: Finished STEP 20200/50000, loss = 2.385514 (0.076 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:34:04 INFO: Evaluating on dev set...\n",
            "2023-12-21 10:34:16 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 10:34:16 INFO: 61.51\t55.75\t57.52\n",
            "2023-12-21 10:34:16 INFO: step 20200: train_loss = 1.908050, dev_score = 0.6151\n",
            "2023-12-21 10:34:18 INFO: Finished STEP 20220/50000, loss = 2.316058 (0.080 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:34:19 INFO: Finished STEP 20240/50000, loss = 0.743850 (0.054 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:34:21 INFO: Finished STEP 20260/50000, loss = 1.835713 (0.074 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:34:22 INFO: Finished STEP 20280/50000, loss = 2.542655 (0.073 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:34:24 INFO: Finished STEP 20300/50000, loss = 2.421899 (0.075 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:34:24 INFO: Evaluating on dev set...\n",
            "2023-12-21 10:34:36 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 10:34:36 INFO: 62.10\t56.15\t57.99\n",
            "2023-12-21 10:34:36 INFO: step 20300: train_loss = 1.948758, dev_score = 0.6210\n",
            "2023-12-21 10:34:37 INFO: Finished STEP 20320/50000, loss = 2.167873 (0.075 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:34:39 INFO: Finished STEP 20340/50000, loss = 1.772504 (0.067 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:34:40 INFO: Finished STEP 20360/50000, loss = 1.890828 (0.071 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:34:42 INFO: Finished STEP 20380/50000, loss = 2.054360 (0.081 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:34:43 INFO: Finished STEP 20400/50000, loss = 2.306424 (0.084 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:34:43 INFO: Evaluating on dev set...\n",
            "2023-12-21 10:34:55 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 10:34:55 INFO: 62.00\t55.89\t57.65\n",
            "2023-12-21 10:34:55 INFO: step 20400: train_loss = 1.865704, dev_score = 0.6200\n",
            "2023-12-21 10:34:56 INFO: Finished STEP 20420/50000, loss = 2.230204 (0.073 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:34:58 INFO: Finished STEP 20440/50000, loss = 2.295156 (0.077 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:34:59 INFO: Finished STEP 20460/50000, loss = 1.979036 (0.081 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:35:01 INFO: Finished STEP 20480/50000, loss = 2.639909 (0.075 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:35:02 INFO: Finished STEP 20500/50000, loss = 1.971155 (0.083 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:35:02 INFO: Evaluating on dev set...\n",
            "2023-12-21 10:35:14 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 10:35:14 INFO: 61.96\t56.32\t58.06\n",
            "2023-12-21 10:35:14 INFO: step 20500: train_loss = 1.933914, dev_score = 0.6196\n",
            "2023-12-21 10:35:16 INFO: Finished STEP 20520/50000, loss = 2.225016 (0.075 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:35:17 INFO: Finished STEP 20540/50000, loss = 2.247374 (0.077 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:35:19 INFO: Finished STEP 20560/50000, loss = 2.380274 (0.078 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:35:20 INFO: Finished STEP 20580/50000, loss = 1.303717 (0.052 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:35:22 INFO: Finished STEP 20600/50000, loss = 1.364635 (0.061 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:35:22 INFO: Evaluating on dev set...\n",
            "2023-12-21 10:35:33 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 10:35:33 INFO: 62.16\t56.47\t58.26\n",
            "2023-12-21 10:35:33 INFO: step 20600: train_loss = 1.895545, dev_score = 0.6216\n",
            "2023-12-21 10:35:35 INFO: Finished STEP 20620/50000, loss = 1.851732 (0.077 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:35:36 INFO: Finished STEP 20640/50000, loss = 1.733191 (0.071 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:35:38 INFO: Finished STEP 20660/50000, loss = 1.688467 (0.076 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:35:39 INFO: Finished STEP 20680/50000, loss = 0.704404 (0.050 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:35:41 INFO: Finished STEP 20700/50000, loss = 1.699865 (0.070 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:35:41 INFO: Evaluating on dev set...\n",
            "2023-12-21 10:35:52 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 10:35:52 INFO: 62.03\t55.98\t57.78\n",
            "2023-12-21 10:35:52 INFO: step 20700: train_loss = 1.932259, dev_score = 0.6203\n",
            "2023-12-21 10:35:54 INFO: Finished STEP 20720/50000, loss = 2.064860 (0.076 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:35:55 INFO: Finished STEP 20740/50000, loss = 1.909338 (0.066 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:35:57 INFO: Finished STEP 20760/50000, loss = 1.971142 (0.081 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:35:58 INFO: Finished STEP 20780/50000, loss = 1.465777 (0.064 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:36:00 INFO: Finished STEP 20800/50000, loss = 2.165542 (0.071 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:36:00 INFO: Evaluating on dev set...\n",
            "2023-12-21 10:36:12 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 10:36:12 INFO: 62.10\t56.01\t57.87\n",
            "2023-12-21 10:36:12 INFO: step 20800: train_loss = 1.864326, dev_score = 0.6210\n",
            "2023-12-21 10:36:14 INFO: Finished STEP 20820/50000, loss = 1.763162 (0.077 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:36:15 INFO: Finished STEP 20840/50000, loss = 2.267775 (0.074 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:36:17 INFO: Finished STEP 20860/50000, loss = 1.077551 (0.053 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:36:18 INFO: Finished STEP 20880/50000, loss = 1.769907 (0.080 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:36:20 INFO: Finished STEP 20900/50000, loss = 2.386444 (0.075 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:36:20 INFO: Evaluating on dev set...\n",
            "2023-12-21 10:36:31 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 10:36:31 INFO: 62.02\t56.28\t58.10\n",
            "2023-12-21 10:36:31 INFO: step 20900: train_loss = 1.856855, dev_score = 0.6202\n",
            "2023-12-21 10:36:33 INFO: Finished STEP 20920/50000, loss = 2.156134 (0.074 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:36:34 INFO: Finished STEP 20940/50000, loss = 2.047106 (0.068 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:36:36 INFO: Finished STEP 20960/50000, loss = 2.149747 (0.074 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:36:37 INFO: Finished STEP 20980/50000, loss = 2.089220 (0.070 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:36:39 INFO: Finished STEP 21000/50000, loss = 2.166203 (0.082 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:36:39 INFO: Evaluating on dev set...\n",
            "2023-12-21 10:36:50 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 10:36:50 INFO: 61.62\t55.61\t57.42\n",
            "2023-12-21 10:36:50 INFO: step 21000: train_loss = 1.919642, dev_score = 0.6162\n",
            "2023-12-21 10:36:51 INFO: Finished STEP 21020/50000, loss = 1.384407 (0.064 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:36:53 INFO: Finished STEP 21040/50000, loss = 1.689258 (0.068 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:36:55 INFO: Finished STEP 21060/50000, loss = 2.445228 (0.077 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:36:56 INFO: Finished STEP 21080/50000, loss = 2.390526 (0.074 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:36:58 INFO: Finished STEP 21100/50000, loss = 2.172046 (0.075 sec/batch), lr: 0.003000\n",
            "2023-12-21 10:36:58 INFO: Evaluating on dev set...\n",
            "2023-12-21 10:37:10 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 10:37:10 INFO: 62.04\t56.35\t58.20\n",
            "2023-12-21 10:37:10 INFO: step 21100: train_loss = 1.929974, dev_score = 0.6204\n",
            "2023-12-21 10:37:10 INFO: Training ended with 21100 steps.\n",
            "2023-12-21 10:37:10 INFO: Best dev F1 = 62.45, at iteration = 18100\n",
            "2023-12-21 10:37:10 INFO: Using default pretrain for language, found in /content/drive/MyDrive/stanza_resources/vi/pretrain/conll17.pt  To use a different pretrain, specify --wordvec_pretrain_file\n",
            "2023-12-21 10:37:10 INFO: Running dev depparse for UD_Vietnamese-VTB with args ['--wordvec_dir', 'extern_data/wordvec', '--eval_file', '/content/drive/MyDrive/DEPPARSE/vi_vtb.dev.in.conllu', '--output_file', '/tmp/tmp84th40bl', '--gold_file', '/content/drive/MyDrive/DEPPARSE/vi_vtb.dev.gold.conllu', '--lang', 'vi', '--shorthand', 'vi_vtb', '--mode', 'predict', '--wordvec_pretrain_file', '/content/drive/MyDrive/stanza_resources/vi/pretrain/conll17.pt', '--charlm', '--charlm_shorthand', 'vi_conll17', '--charlm_forward_file', '/content/drive/MyDrive/stanza_resources/vi/forward_charlm/conll17.pt', '--charlm_backward_file', '/content/drive/MyDrive/stanza_resources/vi/backward_charlm/conll17.pt', '--batch_size', '200']\n",
            "2023-12-21 10:37:10 INFO: Running parser in predict mode\n",
            "2023-12-21 10:37:10 INFO: Loading model from: saved_models/depparse/vi_vtb_charlm_parser.pt\n",
            "2023-12-21 10:37:11 DEBUG: Loaded pretrain from /content/drive/MyDrive/stanza_resources/vi/pretrain/conll17.pt\n",
            "2023-12-21 10:37:11 DEBUG: Depparse model loading charmodels: /content/drive/MyDrive/stanza_resources/vi/forward_charlm/conll17.pt and /content/drive/MyDrive/stanza_resources/vi/backward_charlm/conll17.pt\n",
            "2023-12-21 10:37:11 DEBUG: Loading charlm from /content/drive/MyDrive/stanza_resources/vi/forward_charlm/conll17.pt\n",
            "2023-12-21 10:37:11 DEBUG: Loading charlm from /content/drive/MyDrive/stanza_resources/vi/backward_charlm/conll17.pt\n",
            "2023-12-21 10:37:11 INFO: Loading data with batch size 200...\n",
            "2023-12-21 10:37:13 DEBUG: 147 batches created.\n",
            "2023-12-21 10:37:13 INFO: Start evaluation...\n",
            "2023-12-21 10:37:24 INFO: F1 scores for each dependency:\n",
            "  Note that unlabeled attachment errors hurt the labeled attachment scores\n",
            "              acl: p 0.0000 r 0.0000 f1 0.0000 (67 actual)\n",
            "        acl:relcl: p 0.0000 r 0.0000 f1 0.0000 (20 actual)\n",
            "         acl:subj: p 0.5255 r 0.3740 f1 0.4370 (853 actual)\n",
            "         acl:tmod: p 0.5278 r 0.4672 f1 0.4957 (122 actual)\n",
            "         acl:tonp: p 0.0000 r 0.0000 f1 0.0000 (51 actual)\n",
            "            advcl: p 0.4743 r 0.2225 f1 0.3029 (373 actual)\n",
            "  advcl:objective: p 0.4254 r 0.5089 f1 0.4634 (112 actual)\n",
            "           advmod: p 0.8182 r 0.8286 f1 0.8234 (1342 actual)\n",
            "       advmod:adj: p 0.4512 r 0.1209 f1 0.1907 (306 actual)\n",
            "       advmod:dir: p 0.0000 r 0.0000 f1 0.0000 (1 actual)\n",
            "       advmod:neg: p 0.8143 r 0.7256 f1 0.7674 (266 actual)\n",
            "             amod: p 0.4521 r 0.7396 f1 0.5612 (434 actual)\n",
            "            appos: p 0.1412 r 0.1154 f1 0.1270 (104 actual)\n",
            "       appos:nmod: p 0.0959 r 0.0631 f1 0.0761 (111 actual)\n",
            "              aux: p 0.9625 r 0.8063 f1 0.8775 (191 actual)\n",
            "         aux:pass: p 0.7897 r 0.9286 f1 0.8535 (182 actual)\n",
            "             case: p 0.8625 r 0.9062 f1 0.8838 (1460 actual)\n",
            "               cc: p 0.6960 r 0.6806 f1 0.6882 (407 actual)\n",
            "            ccomp: p 0.2177 r 0.2160 f1 0.2169 (250 actual)\n",
            "              clf: p 0.7143 r 0.1271 f1 0.2158 (118 actual)\n",
            "          clf:det: p 0.6042 r 0.4315 f1 0.5035 (336 actual)\n",
            "         compound: p 0.5891 r 0.4363 f1 0.5013 (1288 actual)\n",
            "     compound:adj: p 0.0000 r 0.0000 f1 0.0000 (20 actual)\n",
            "    compound:amod: p 0.0000 r 0.0000 f1 0.0000 (74 actual)\n",
            "    compound:atov: p 0.0000 r 0.0000 f1 0.0000 (10 actual)\n",
            "     compound:dir: p 0.4423 r 0.6389 f1 0.5227 (144 actual)\n",
            "    compound:pron: p 0.0000 r 0.0000 f1 0.0000 (23 actual)\n",
            "     compound:prt: p 0.0000 r 0.0000 f1 0.0000 (22 actual)\n",
            "     compound:svc: p 0.6220 r 0.2705 f1 0.3771 (292 actual)\n",
            "compound:verbnoun: p 0.0000 r 0.0000 f1 0.0000 (31 actual)\n",
            "    compound:vmod: p 0.5957 r 0.7416 f1 0.6607 (298 actual)\n",
            "       compound:z: p 0.0000 r 0.0000 f1 0.0000 (5 actual)\n",
            "             conj: p 0.3606 r 0.3741 f1 0.3673 (1259 actual)\n",
            "              cop: p 0.8770 r 0.8865 f1 0.8817 (185 actual)\n",
            "            csubj: p 0.0000 r 0.0000 f1 0.0000 (48 actual)\n",
            "      csubj:asubj: p 0.0000 r 0.0000 f1 0.0000 (7 actual)\n",
            "       csubj:pass: p 0.0000 r 0.0000 f1 0.0000 (1 actual)\n",
            "      csubj:vsubj: p 0.7500 r 0.1200 f1 0.2069 (25 actual)\n",
            "              dep: p 0.0000 r 0.0000 f1 0.0000 (1 actual)\n",
            "              det: p 0.8966 r 0.9098 f1 0.9031 (543 actual)\n",
            "         det:pmod: p 0.6411 r 0.8228 f1 0.7207 (254 actual)\n",
            "        discourse: p 0.6111 r 0.2933 f1 0.3964 (150 actual)\n",
            "       dislocated: p 0.0000 r 0.0000 f1 0.0000 (18 actual)\n",
            "             expl: p 0.0000 r 0.0000 f1 0.0000 (4 actual)\n",
            "            fixed: p 0.0000 r 0.0000 f1 0.0000 (18 actual)\n",
            "             flat: p 0.0000 r 0.0000 f1 0.0000 (3 actual)\n",
            "        flat:date: p 0.2925 r 0.4769 f1 0.3626 (65 actual)\n",
            "     flat:foreign: p 0.0000 r 0.0000 f1 0.0000 (7 actual)\n",
            "      flat:number: p 0.3333 r 0.0200 f1 0.0377 (100 actual)\n",
            "        flat:time: p 0.1111 r 0.5000 f1 0.1818 (6 actual)\n",
            "             iobj: p 0.0000 r 0.0000 f1 0.0000 (6 actual)\n",
            "             list: p 0.0000 r 0.0000 f1 0.0000 (24 actual)\n",
            "             mark: p 0.6918 r 0.6621 f1 0.6766 (512 actual)\n",
            "       mark:pcomp: p 0.8482 r 0.8962 f1 0.8716 (106 actual)\n",
            "             nmod: p 0.3403 r 0.4218 f1 0.3767 (1304 actual)\n",
            "        nmod:poss: p 0.6475 r 0.6680 f1 0.6576 (253 actual)\n",
            "            nsubj: p 0.6271 r 0.7130 f1 0.6673 (1519 actual)\n",
            "         nsubj:nn: p 0.0000 r 0.0000 f1 0.0000 (104 actual)\n",
            "       nsubj:pass: p 0.7872 r 0.3592 f1 0.4933 (103 actual)\n",
            "           nummod: p 0.6706 r 0.8931 f1 0.7660 (636 actual)\n",
            "       nummod:det: p 0.0000 r 0.0000 f1 0.0000 (71 actual)\n",
            "              obj: p 0.6631 r 0.8730 f1 0.7537 (1835 actual)\n",
            "              obl: p 0.1668 r 0.3370 f1 0.2232 (460 actual)\n",
            "        obl:about: p 0.0000 r 0.0000 f1 0.0000 (27 actual)\n",
            "          obl:adj: p 0.0000 r 0.0000 f1 0.0000 (111 actual)\n",
            "          obl:adv: p 0.0000 r 0.0000 f1 0.0000 (3 actual)\n",
            "        obl:agent: p 0.7561 r 0.5962 f1 0.6667 (52 actual)\n",
            "         obl:comp: p 0.5455 r 0.0973 f1 0.1651 (555 actual)\n",
            "         obl:iobj: p 0.2667 r 0.0769 f1 0.1194 (52 actual)\n",
            "         obl:tmod: p 0.5520 r 0.5580 f1 0.5550 (552 actual)\n",
            "         obl:with: p 0.2000 r 0.0139 f1 0.0260 (72 actual)\n",
            "        parataxis: p 0.1691 r 0.3846 f1 0.2349 (182 actual)\n",
            "            punct: p 0.6216 r 0.6119 f1 0.6167 (3517 actual)\n",
            "             root: p 0.7560 r 0.7560 f1 0.7560 (1123 actual)\n",
            "         vocative: p 0.0000 r 0.0000 f1 0.0000 (6 actual)\n",
            "            xcomp: p 0.5357 r 0.7688 f1 0.6314 (917 actual)\n",
            "        xcomp:adj: p 0.2778 r 0.1389 f1 0.1852 (36 actual)\n",
            "        xcomp:dir: p 0.0000 r 0.0000 f1 0.0000 (17 actual)\n",
            "2023-12-21 10:37:25 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 10:37:25 INFO: 62.45\t56.59\t58.47\n",
            "2023-12-21 10:37:25 INFO: Parser score:\n",
            "2023-12-21 10:37:25 INFO: vi_vtb 62.45\n",
            "2023-12-21 10:37:27 INFO: Finished running dev set on\n",
            "UD_Vietnamese-VTB\n",
            "  UAS   LAS  CLAS  MLAS  BLEX\n",
            "73.26 62.45 58.47 56.59 58.47\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 -m stanza.utils.training.run_depparse UD_Vietnamese-VTB --score_dev\n",
        "!python3 -m stanza.utils.training.run_depparse UD_Vietnamese-VTB --score_test"
      ],
      "metadata": {
        "id": "Ls--LlGdB2w9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0ea28be-bbc5-4897-f97d-8bdd48be6e99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-12-21 10:38:10 INFO: Training program called with:\n",
            "/usr/local/lib/python3.10/dist-packages/stanza/utils/training/run_depparse.py UD_Vietnamese-VTB --score_dev\n",
            "2023-12-21 10:38:10 DEBUG: UD_Vietnamese-VTB: vi_vtb\n",
            "2023-12-21 10:38:10 INFO: Using model /content/drive/MyDrive/stanza_resources/vi/forward_charlm/conll17.pt for forward charlm\n",
            "2023-12-21 10:38:10 INFO: Using model /content/drive/MyDrive/stanza_resources/vi/backward_charlm/conll17.pt for backward charlm\n",
            "2023-12-21 10:38:10 INFO: Using default pretrain for language, found in /content/drive/MyDrive/stanza_resources/vi/pretrain/conll17.pt  To use a different pretrain, specify --wordvec_pretrain_file\n",
            "2023-12-21 10:38:10 INFO: Running dev depparse for UD_Vietnamese-VTB with args ['--wordvec_dir', 'extern_data/wordvec', '--eval_file', '/content/drive/MyDrive/DEPPARSE/vi_vtb.dev.in.conllu', '--output_file', '/tmp/tmps5bzc6vd', '--gold_file', '/content/drive/MyDrive/DEPPARSE/vi_vtb.dev.gold.conllu', '--lang', 'vi', '--shorthand', 'vi_vtb', '--mode', 'predict', '--wordvec_pretrain_file', '/content/drive/MyDrive/stanza_resources/vi/pretrain/conll17.pt', '--charlm', '--charlm_shorthand', 'vi_conll17', '--charlm_forward_file', '/content/drive/MyDrive/stanza_resources/vi/forward_charlm/conll17.pt', '--charlm_backward_file', '/content/drive/MyDrive/stanza_resources/vi/backward_charlm/conll17.pt']\n",
            "2023-12-21 10:38:10 INFO: Running parser in predict mode\n",
            "2023-12-21 10:38:10 INFO: Loading model from: saved_models/depparse/vi_vtb_charlm_parser.pt\n",
            "2023-12-21 10:38:10 DEBUG: Loaded pretrain from /content/drive/MyDrive/stanza_resources/vi/pretrain/conll17.pt\n",
            "2023-12-21 10:38:10 DEBUG: Depparse model loading charmodels: /content/drive/MyDrive/stanza_resources/vi/forward_charlm/conll17.pt and /content/drive/MyDrive/stanza_resources/vi/backward_charlm/conll17.pt\n",
            "2023-12-21 10:38:10 DEBUG: Loading charlm from /content/drive/MyDrive/stanza_resources/vi/forward_charlm/conll17.pt\n",
            "2023-12-21 10:38:10 DEBUG: Loading charlm from /content/drive/MyDrive/stanza_resources/vi/backward_charlm/conll17.pt\n",
            "2023-12-21 10:38:12 INFO: Loading data with batch size 5000...\n",
            "2023-12-21 10:38:14 DEBUG: 6 batches created.\n",
            "2023-12-21 10:38:14 INFO: Start evaluation...\n",
            "2023-12-21 10:38:20 INFO: F1 scores for each dependency:\n",
            "  Note that unlabeled attachment errors hurt the labeled attachment scores\n",
            "              acl: p 0.0000 r 0.0000 f1 0.0000 (67 actual)\n",
            "        acl:relcl: p 0.0000 r 0.0000 f1 0.0000 (20 actual)\n",
            "         acl:subj: p 0.5255 r 0.3740 f1 0.4370 (853 actual)\n",
            "         acl:tmod: p 0.5278 r 0.4672 f1 0.4957 (122 actual)\n",
            "         acl:tonp: p 0.0000 r 0.0000 f1 0.0000 (51 actual)\n",
            "            advcl: p 0.4743 r 0.2225 f1 0.3029 (373 actual)\n",
            "  advcl:objective: p 0.4254 r 0.5089 f1 0.4634 (112 actual)\n",
            "           advmod: p 0.8182 r 0.8286 f1 0.8234 (1342 actual)\n",
            "       advmod:adj: p 0.4512 r 0.1209 f1 0.1907 (306 actual)\n",
            "       advmod:dir: p 0.0000 r 0.0000 f1 0.0000 (1 actual)\n",
            "       advmod:neg: p 0.8143 r 0.7256 f1 0.7674 (266 actual)\n",
            "             amod: p 0.4521 r 0.7396 f1 0.5612 (434 actual)\n",
            "            appos: p 0.1412 r 0.1154 f1 0.1270 (104 actual)\n",
            "       appos:nmod: p 0.0959 r 0.0631 f1 0.0761 (111 actual)\n",
            "              aux: p 0.9625 r 0.8063 f1 0.8775 (191 actual)\n",
            "         aux:pass: p 0.7897 r 0.9286 f1 0.8535 (182 actual)\n",
            "             case: p 0.8625 r 0.9062 f1 0.8838 (1460 actual)\n",
            "               cc: p 0.6960 r 0.6806 f1 0.6882 (407 actual)\n",
            "            ccomp: p 0.2177 r 0.2160 f1 0.2169 (250 actual)\n",
            "              clf: p 0.7143 r 0.1271 f1 0.2158 (118 actual)\n",
            "          clf:det: p 0.6042 r 0.4315 f1 0.5035 (336 actual)\n",
            "         compound: p 0.5891 r 0.4363 f1 0.5013 (1288 actual)\n",
            "     compound:adj: p 0.0000 r 0.0000 f1 0.0000 (20 actual)\n",
            "    compound:amod: p 0.0000 r 0.0000 f1 0.0000 (74 actual)\n",
            "    compound:atov: p 0.0000 r 0.0000 f1 0.0000 (10 actual)\n",
            "     compound:dir: p 0.4423 r 0.6389 f1 0.5227 (144 actual)\n",
            "    compound:pron: p 0.0000 r 0.0000 f1 0.0000 (23 actual)\n",
            "     compound:prt: p 0.0000 r 0.0000 f1 0.0000 (22 actual)\n",
            "     compound:svc: p 0.6220 r 0.2705 f1 0.3771 (292 actual)\n",
            "compound:verbnoun: p 0.0000 r 0.0000 f1 0.0000 (31 actual)\n",
            "    compound:vmod: p 0.5957 r 0.7416 f1 0.6607 (298 actual)\n",
            "       compound:z: p 0.0000 r 0.0000 f1 0.0000 (5 actual)\n",
            "             conj: p 0.3606 r 0.3741 f1 0.3673 (1259 actual)\n",
            "              cop: p 0.8770 r 0.8865 f1 0.8817 (185 actual)\n",
            "            csubj: p 0.0000 r 0.0000 f1 0.0000 (48 actual)\n",
            "      csubj:asubj: p 0.0000 r 0.0000 f1 0.0000 (7 actual)\n",
            "       csubj:pass: p 0.0000 r 0.0000 f1 0.0000 (1 actual)\n",
            "      csubj:vsubj: p 0.7500 r 0.1200 f1 0.2069 (25 actual)\n",
            "              dep: p 0.0000 r 0.0000 f1 0.0000 (1 actual)\n",
            "              det: p 0.8966 r 0.9098 f1 0.9031 (543 actual)\n",
            "         det:pmod: p 0.6411 r 0.8228 f1 0.7207 (254 actual)\n",
            "        discourse: p 0.6111 r 0.2933 f1 0.3964 (150 actual)\n",
            "       dislocated: p 0.0000 r 0.0000 f1 0.0000 (18 actual)\n",
            "             expl: p 0.0000 r 0.0000 f1 0.0000 (4 actual)\n",
            "            fixed: p 0.0000 r 0.0000 f1 0.0000 (18 actual)\n",
            "             flat: p 0.0000 r 0.0000 f1 0.0000 (3 actual)\n",
            "        flat:date: p 0.2925 r 0.4769 f1 0.3626 (65 actual)\n",
            "     flat:foreign: p 0.0000 r 0.0000 f1 0.0000 (7 actual)\n",
            "      flat:number: p 0.3333 r 0.0200 f1 0.0377 (100 actual)\n",
            "        flat:time: p 0.1111 r 0.5000 f1 0.1818 (6 actual)\n",
            "             iobj: p 0.0000 r 0.0000 f1 0.0000 (6 actual)\n",
            "             list: p 0.0000 r 0.0000 f1 0.0000 (24 actual)\n",
            "             mark: p 0.6918 r 0.6621 f1 0.6766 (512 actual)\n",
            "       mark:pcomp: p 0.8482 r 0.8962 f1 0.8716 (106 actual)\n",
            "             nmod: p 0.3403 r 0.4218 f1 0.3767 (1304 actual)\n",
            "        nmod:poss: p 0.6475 r 0.6680 f1 0.6576 (253 actual)\n",
            "            nsubj: p 0.6271 r 0.7130 f1 0.6673 (1519 actual)\n",
            "         nsubj:nn: p 0.0000 r 0.0000 f1 0.0000 (104 actual)\n",
            "       nsubj:pass: p 0.7872 r 0.3592 f1 0.4933 (103 actual)\n",
            "           nummod: p 0.6706 r 0.8931 f1 0.7660 (636 actual)\n",
            "       nummod:det: p 0.0000 r 0.0000 f1 0.0000 (71 actual)\n",
            "              obj: p 0.6631 r 0.8730 f1 0.7537 (1835 actual)\n",
            "              obl: p 0.1668 r 0.3370 f1 0.2232 (460 actual)\n",
            "        obl:about: p 0.0000 r 0.0000 f1 0.0000 (27 actual)\n",
            "          obl:adj: p 0.0000 r 0.0000 f1 0.0000 (111 actual)\n",
            "          obl:adv: p 0.0000 r 0.0000 f1 0.0000 (3 actual)\n",
            "        obl:agent: p 0.7561 r 0.5962 f1 0.6667 (52 actual)\n",
            "         obl:comp: p 0.5455 r 0.0973 f1 0.1651 (555 actual)\n",
            "         obl:iobj: p 0.2667 r 0.0769 f1 0.1194 (52 actual)\n",
            "         obl:tmod: p 0.5520 r 0.5580 f1 0.5550 (552 actual)\n",
            "         obl:with: p 0.2000 r 0.0139 f1 0.0260 (72 actual)\n",
            "        parataxis: p 0.1691 r 0.3846 f1 0.2349 (182 actual)\n",
            "            punct: p 0.6216 r 0.6119 f1 0.6167 (3517 actual)\n",
            "             root: p 0.7560 r 0.7560 f1 0.7560 (1123 actual)\n",
            "         vocative: p 0.0000 r 0.0000 f1 0.0000 (6 actual)\n",
            "            xcomp: p 0.5357 r 0.7688 f1 0.6314 (917 actual)\n",
            "        xcomp:adj: p 0.2778 r 0.1389 f1 0.1852 (36 actual)\n",
            "        xcomp:dir: p 0.0000 r 0.0000 f1 0.0000 (17 actual)\n",
            "2023-12-21 10:38:21 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 10:38:21 INFO: 62.45\t56.59\t58.47\n",
            "2023-12-21 10:38:21 INFO: Parser score:\n",
            "2023-12-21 10:38:21 INFO: vi_vtb 62.45\n",
            "2023-12-21 10:38:23 INFO: Finished running dev set on\n",
            "UD_Vietnamese-VTB\n",
            "  UAS   LAS  CLAS  MLAS  BLEX\n",
            "73.26 62.45 58.47 56.59 58.47\n",
            "2023-12-21 10:38:26 INFO: Training program called with:\n",
            "/usr/local/lib/python3.10/dist-packages/stanza/utils/training/run_depparse.py UD_Vietnamese-VTB --score_test\n",
            "2023-12-21 10:38:26 DEBUG: UD_Vietnamese-VTB: vi_vtb\n",
            "2023-12-21 10:38:26 INFO: Using model /content/drive/MyDrive/stanza_resources/vi/forward_charlm/conll17.pt for forward charlm\n",
            "2023-12-21 10:38:26 INFO: Using model /content/drive/MyDrive/stanza_resources/vi/backward_charlm/conll17.pt for backward charlm\n",
            "2023-12-21 10:38:26 INFO: Using default pretrain for language, found in /content/drive/MyDrive/stanza_resources/vi/pretrain/conll17.pt  To use a different pretrain, specify --wordvec_pretrain_file\n",
            "2023-12-21 10:38:26 INFO: Running test depparse for UD_Vietnamese-VTB with args ['--wordvec_dir', 'extern_data/wordvec', '--eval_file', '/content/drive/MyDrive/DEPPARSE/vi_vtb.test.in.conllu', '--output_file', '/tmp/tmp4m68wjuz', '--gold_file', '/content/drive/MyDrive/DEPPARSE/vi_vtb.test.gold.conllu', '--lang', 'vi', '--shorthand', 'vi_vtb', '--mode', 'predict', '--wordvec_pretrain_file', '/content/drive/MyDrive/stanza_resources/vi/pretrain/conll17.pt', '--charlm', '--charlm_shorthand', 'vi_conll17', '--charlm_forward_file', '/content/drive/MyDrive/stanza_resources/vi/forward_charlm/conll17.pt', '--charlm_backward_file', '/content/drive/MyDrive/stanza_resources/vi/backward_charlm/conll17.pt']\n",
            "2023-12-21 10:38:26 INFO: Running parser in predict mode\n",
            "2023-12-21 10:38:26 INFO: Loading model from: saved_models/depparse/vi_vtb_charlm_parser.pt\n",
            "2023-12-21 10:38:26 DEBUG: Loaded pretrain from /content/drive/MyDrive/stanza_resources/vi/pretrain/conll17.pt\n",
            "2023-12-21 10:38:26 DEBUG: Depparse model loading charmodels: /content/drive/MyDrive/stanza_resources/vi/forward_charlm/conll17.pt and /content/drive/MyDrive/stanza_resources/vi/backward_charlm/conll17.pt\n",
            "2023-12-21 10:38:26 DEBUG: Loading charlm from /content/drive/MyDrive/stanza_resources/vi/forward_charlm/conll17.pt\n",
            "2023-12-21 10:38:26 DEBUG: Loading charlm from /content/drive/MyDrive/stanza_resources/vi/backward_charlm/conll17.pt\n",
            "2023-12-21 10:38:28 INFO: Loading data with batch size 5000...\n",
            "2023-12-21 10:38:29 DEBUG: 3 batches created.\n",
            "2023-12-21 10:38:29 INFO: Start evaluation...\n",
            "2023-12-21 10:38:32 INFO: F1 scores for each dependency:\n",
            "  Note that unlabeled attachment errors hurt the labeled attachment scores\n",
            "              acl: p 0.3333 r 0.0118 f1 0.0227 (85 actual)\n",
            "        acl:relcl: p 0.0000 r 0.0000 f1 0.0000 (2 actual)\n",
            "         acl:subj: p 0.2556 r 0.3239 f1 0.2857 (142 actual)\n",
            "         acl:tmod: p 0.6667 r 0.5098 f1 0.5778 (51 actual)\n",
            "         acl:tonp: p 0.0000 r 0.0000 f1 0.0000 (15 actual)\n",
            "            advcl: p 0.5360 r 0.3175 f1 0.3988 (211 actual)\n",
            "  advcl:objective: p 0.4524 r 0.2969 f1 0.3585 (64 actual)\n",
            "           advmod: p 0.8108 r 0.8378 f1 0.8241 (752 actual)\n",
            "       advmod:adj: p 0.4468 r 0.1373 f1 0.2100 (153 actual)\n",
            "       advmod:dir: p 0.0000 r 0.0000 f1 0.0000 (9 actual)\n",
            "       advmod:neg: p 0.8603 r 0.8462 f1 0.8532 (182 actual)\n",
            "             amod: p 0.5880 r 0.7532 f1 0.6604 (235 actual)\n",
            "            appos: p 0.1667 r 0.0741 f1 0.1026 (27 actual)\n",
            "       appos:nmod: p 0.0000 r 0.0000 f1 0.0000 (26 actual)\n",
            "              aux: p 0.9467 r 0.8256 f1 0.8820 (86 actual)\n",
            "         aux:pass: p 0.7679 r 0.9556 f1 0.8515 (45 actual)\n",
            "             case: p 0.8571 r 0.9558 f1 0.9038 (565 actual)\n",
            "               cc: p 0.7861 r 0.6071 f1 0.6851 (224 actual)\n",
            "            ccomp: p 0.3040 r 0.3551 f1 0.3276 (107 actual)\n",
            "              clf: p 0.5143 r 0.3830 f1 0.4390 (47 actual)\n",
            "          clf:det: p 0.8311 r 0.9212 f1 0.8738 (203 actual)\n",
            "         compound: p 0.3182 r 0.2727 f1 0.2937 (154 actual)\n",
            "     compound:adj: p 0.0000 r 0.0000 f1 0.0000 (1 actual)\n",
            "    compound:amod: p 0.0000 r 0.0000 f1 0.0000 (17 actual)\n",
            "     compound:apr: p 0.0000 r 0.0000 f1 0.0000 (1 actual)\n",
            "    compound:atov: p 0.0000 r 0.0000 f1 0.0000 (4 actual)\n",
            "     compound:dir: p 0.2656 r 0.4857 f1 0.3434 (35 actual)\n",
            "    compound:pron: p 0.0000 r 0.0000 f1 0.0000 (18 actual)\n",
            "     compound:prt: p 0.0000 r 0.0000 f1 0.0000 (35 actual)\n",
            "   compound:redup: p 0.0000 r 0.0000 f1 0.0000 (1 actual)\n",
            "     compound:svc: p 0.3182 r 0.0778 f1 0.1250 (90 actual)\n",
            "compound:verbnoun: p 0.0000 r 0.0000 f1 0.0000 (26 actual)\n",
            "    compound:vmod: p 0.7032 r 0.7315 f1 0.7171 (149 actual)\n",
            "       compound:z: p 0.0000 r 0.0000 f1 0.0000 (1 actual)\n",
            "             conj: p 0.3893 r 0.4808 f1 0.4302 (468 actual)\n",
            "              cop: p 0.8584 r 0.9510 f1 0.9023 (102 actual)\n",
            "            csubj: p 0.0000 r 0.0000 f1 0.0000 (20 actual)\n",
            "      csubj:asubj: p 0.5000 r 0.3333 f1 0.4000 (6 actual)\n",
            "      csubj:vsubj: p 0.6667 r 0.1538 f1 0.2500 (13 actual)\n",
            "              dep: p 0.0000 r 0.0000 f1 0.0000 (3 actual)\n",
            "              det: p 0.9531 r 0.9683 f1 0.9606 (189 actual)\n",
            "         det:pmod: p 0.7176 r 0.8201 f1 0.7654 (189 actual)\n",
            "        discourse: p 0.6408 r 0.4925 f1 0.5570 (134 actual)\n",
            "       dislocated: p 0.0000 r 0.0000 f1 0.0000 (9 actual)\n",
            "            fixed: p 0.0000 r 0.0000 f1 0.0000 (8 actual)\n",
            "             flat: p 0.0000 r 0.0000 f1 0.0000 (10 actual)\n",
            "        flat:date: p 0.3750 r 0.3333 f1 0.3529 (9 actual)\n",
            "        flat:name: p 0.0000 r 0.0000 f1 0.0000 (2 actual)\n",
            "      flat:number: p 0.0000 r 0.0000 f1 0.0000 (9 actual)\n",
            "        flat:time: p 0.0000 r 0.0000 f1 0.0000 (2 actual)\n",
            "             iobj: p 0.0000 r 0.0000 f1 0.0000 (11 actual)\n",
            "             list: p 0.0000 r 0.0000 f1 0.0000 (0 actual)\n",
            "             mark: p 0.6366 r 0.7211 f1 0.6762 (294 actual)\n",
            "       mark:pcomp: p 0.9000 r 0.9231 f1 0.9114 (39 actual)\n",
            "             nmod: p 0.5431 r 0.5879 f1 0.5646 (461 actual)\n",
            "        nmod:poss: p 0.7158 r 0.6733 f1 0.6939 (101 actual)\n",
            "            nsubj: p 0.7492 r 0.7516 f1 0.7504 (958 actual)\n",
            "         nsubj:nn: p 0.0000 r 0.0000 f1 0.0000 (14 actual)\n",
            "       nsubj:pass: p 0.5714 r 0.3750 f1 0.4528 (32 actual)\n",
            "      nsubj:xsubj: p 0.0000 r 0.0000 f1 0.0000 (5 actual)\n",
            "           nummod: p 0.8251 r 0.9118 f1 0.8663 (238 actual)\n",
            "              obj: p 0.7453 r 0.8777 f1 0.8061 (867 actual)\n",
            "              obl: p 0.2400 r 0.3012 f1 0.2671 (259 actual)\n",
            "        obl:about: p 0.0000 r 0.0000 f1 0.0000 (15 actual)\n",
            "          obl:adj: p 0.0000 r 0.0000 f1 0.0000 (17 actual)\n",
            "          obl:adv: p 0.0000 r 0.0000 f1 0.0000 (1 actual)\n",
            "        obl:agent: p 0.3333 r 0.3333 f1 0.3333 (3 actual)\n",
            "         obl:comp: p 0.4333 r 0.2393 f1 0.3083 (163 actual)\n",
            "         obl:iobj: p 0.5455 r 0.2222 f1 0.3158 (27 actual)\n",
            "         obl:tmod: p 0.5050 r 0.4928 f1 0.4988 (207 actual)\n",
            "         obl:with: p 0.5714 r 0.0816 f1 0.1429 (49 actual)\n",
            "        parataxis: p 0.3491 r 0.2891 f1 0.3162 (128 actual)\n",
            "            punct: p 0.7183 r 0.7187 f1 0.7185 (1703 actual)\n",
            "             root: p 0.7887 r 0.7887 f1 0.7887 (800 actual)\n",
            "         vocative: p 0.0000 r 0.0000 f1 0.0000 (2 actual)\n",
            "            xcomp: p 0.4514 r 0.7629 f1 0.5672 (329 actual)\n",
            "        xcomp:adj: p 0.5333 r 0.5161 f1 0.5246 (31 actual)\n",
            "      xcomp:vcomp: p 0.0000 r 0.0000 f1 0.0000 (2 actual)\n",
            "2023-12-21 10:38:33 INFO: LAS\tMLAS\tBLEX\n",
            "2023-12-21 10:38:33 INFO: 69.41\t62.49\t65.27\n",
            "2023-12-21 10:38:33 INFO: Parser score:\n",
            "2023-12-21 10:38:33 INFO: vi_vtb 69.41\n",
            "2023-12-21 10:38:33 INFO: Finished running test set on\n",
            "UD_Vietnamese-VTB\n",
            "  UAS   LAS  CLAS  MLAS  BLEX\n",
            "78.39 69.41 65.27 62.49 65.27\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import stanza"
      ],
      "metadata": {
        "id": "JZYzICszBjLY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline = stanza.Pipeline(lang=\"vi\", depparse_model_path=\"/content/drive/MyDrive/saved_models/depparse/vi_vtb_charlm_parser.pt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 756,
          "referenced_widgets": [
            "b2ab8fae53834fc1bb5d0f61bb011e92",
            "317a56cc788c4ecaac6b37c8a3f30769",
            "bf4a4caab1dc495c889731726a34ce6d",
            "5d17ce7fa3514f4d8df144033983a978",
            "3ffb78d8c5a54b32a8c033f7c6cc40ba",
            "05e872ea2a46447d9f2b2b9215b73ca7",
            "c1c65f53c934435d8c60f398e875931a",
            "791cbc0bf8854cf4ab6040b569c5eaf6",
            "bfb7421febf8418c8901bf05b244908e",
            "75bec608a3d24251a72f7bd904c3d488",
            "b6fac222e8574c87b2394d54037e5d38",
            "6aac134b60b942c2b7aebb44e7a5fd20",
            "36c23c8fcdaf4a1f91ce7541ba59f129",
            "65f4b1c251de47fcbac45c8002bc681c",
            "33d358f425174bafae6c574f02906110",
            "942610994e0b40dd996fc0fdf458ecbb",
            "94d2044760594ad6b763ad87ee34b90a",
            "91f0ad68c8824544a4539e92d4bb3cbe",
            "2dbd8e120c6945c78e68e6535c1ad15a",
            "292902829e2f49279ba805e4491b5991",
            "81705314278b42ceba5530d1f4878231",
            "433b548928bb41f9830aaf60d37b6445",
            "a515f1f7b2044d83a1c3aea2af6a9706",
            "525147f8eb0b41e8a657e9cf51ea1c29",
            "4f08a50425694d4eba498e73f3329ca8",
            "56c99f9c0d3441c6b90a550f9a31e61c",
            "41117cf619c649d28c5e81a839debf6d",
            "1f5d7bc235714a888cf259c5db3396d9",
            "8a73985e88f84e8e8f51c3738c56cb89",
            "f8853ab53bb74c8288d36211107fa980",
            "735c59f7caf5434d8ad8a2ddb1017336",
            "9241ac74c6c94094abe32460c848ffa9",
            "ba6cd5285de0407c9d2a789a2c8e5c86",
            "acefd5d6f72e490d8398dab8178bfa50",
            "e4083120606f48c69894d596a96717d5",
            "e42dfb9c36234149a66df587200d6cbc",
            "7d24d4ff172b45cca5c935c398fb876e",
            "e212a78f10634650a08bc78fa75582ff",
            "b94d88c0aeb046009db12454ba85a10e",
            "14a10165e97d41fa88d4949540856ab5",
            "b25439c16cc34f7fb359a7f235768b91",
            "d7fdb4f5436245dea13f47f576c2addf",
            "67f5698090224aa68ed707478eb9e348",
            "e1061dbcb80440d89294fcdb063fc49a",
            "d30be805e87146269ee04182756b043e",
            "64b20422df3e48c3ae9f0b00531b9c67",
            "6c94e813653248638d085641c270cb3a",
            "7740f72c792e433c8d4a017ba0e0ffe0",
            "4293e3590c9943ab917e0cd94d141e84",
            "bc5d57e96461468ea5cdb4bd9a08b2e9",
            "0ad85e3557cf4d56b556efefda73a77c",
            "d2c977a2c0054e9590f4bb20c2e8952e",
            "09bf8702c66b46f893c99977696f48ec",
            "7c688e2ac5eb4895990e8c0a4f886d15",
            "70b39ab459bc4fe6ae4de50565ca1770",
            "658e5e55a52c4ef099f38c3ad9972f56",
            "1194852bae0d42bf836104c296f37552",
            "72182c58b3874634834208d297eefe61",
            "f835684546134f1eadee7041bd9db892",
            "5df1145016b74e3fa160dc846392d4f4",
            "55b41830bab94484813723f31d77a6c1",
            "6dbdb52497ca4d19b5661c11d1634a19",
            "8cbf48680357418c9d1ee9f7a5a35508",
            "c313b22eb6584cc090638a712209e683",
            "2bffd8975f6e44a58761988eb206c4bc",
            "2245bad616c448a59daf5e6a855c1e66",
            "2d740012e319419f91a6ec99e45e36b0",
            "0637a34545224428b4d1b003a702606d",
            "09881afeedf74b89a52fd126e5a47c44",
            "66e4c8f8d6c042c9acce639fcabdebca",
            "a202e39b079043cd8903299e35db353d",
            "c48a8451eb294042a981e9ece01a88d2",
            "3229f3137762487cb93b4136be96c623",
            "6b95d647daf24802924b9e37bee23caf",
            "e430846b8b5f4f2bb27f1a17957c160c",
            "5a1d5eefc7384871837dbbf94e053856",
            "a6da5a1950c44f29806fe2b8412c17ca",
            "beb320a915ed4860af4323e755d0221e",
            "ccec99d6d4284c269d9342fbc5bf8d7e",
            "a8cc90ba9dbc4109827527e36aade708",
            "c5ee975818774b8f90d996ef3d887ae4",
            "654a49e954cf4504aa9ee555024b61d8",
            "0534ec6a084a441b8284af5b879c3324",
            "41899a89787b4631ac4b1f43d3c2b097",
            "1429402e5b6847c9af70ce02b03c9276",
            "cb0360c250964e61838ee3c18e0985f4",
            "d70f9be6a5974c26a25f23993d38deb8",
            "d957beb0d7aa411f89f048feaa388849",
            "72f6d1e4c137420ca6fc0b440c8a7eb5",
            "e19f58467e014d209ea34a08ea6a66d5",
            "47b23ad6513241f9a882f569ee4e3674",
            "8577ffddffed44c1a861fc15d3dc5a66",
            "2b37e6276a3845e4af04a9de2a63d389",
            "dfa9464766b44a15bde43e30eaa78dc1",
            "97f21f5c80d54c9499d83220b753a2af",
            "c1d45ef090e14534ac2cfe6397841ed1",
            "27aeaefe868447fea2bec468f11a04c6",
            "014e26ee7cd9456a9e23afa50ca7443f",
            "ebbc489da11842bdbd2cc69cafe24ce5",
            "56fe7e2f028e4902a4b9a4182490e0f2",
            "73779ee5f44142c09b1467b6bc3bf73d",
            "b2efe33f37ce402ebc276161a0ab28ec",
            "09e4fc7dca274bbb94ece0c2818e55a5",
            "83ec1126eb034e40b82baab1ed667634",
            "fe2f058a2fb24c488d5c86897b80ee08",
            "60b1855f8de240d8976dcb39a44b35d3",
            "675432f003654b478caa4ac7a8af2681",
            "5471c82fa1e34215a99abfe7642a2b66",
            "fc1b6ecd3d284224a756b7dcc5028eca",
            "5d31ac500abb4dc1a178140d558ca625"
          ]
        },
        "id": "I76-913_cFNH",
        "outputId": "06cf20cc-d981-4a6d-ec40-4234695702b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:stanza:Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.7.0.json:   0%|   …"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b2ab8fae53834fc1bb5d0f61bb011e92"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading https://huggingface.co/stanfordnlp/stanza-vi/resolve/v1.7.0/models/tokenize/vtb.pt:   0%|         …"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6aac134b60b942c2b7aebb44e7a5fd20"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading https://huggingface.co/stanfordnlp/stanza-vi/resolve/v1.7.0/models/pos/vtb_charlm.pt:   0%|       …"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a515f1f7b2044d83a1c3aea2af6a9706"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading https://huggingface.co/stanfordnlp/stanza-vi/resolve/v1.7.0/models/constituency/vlsp22_charlm.pt: …"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "acefd5d6f72e490d8398dab8178bfa50"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading https://huggingface.co/stanfordnlp/stanza-vi/resolve/v1.7.0/models/depparse/vtb_charlm.pt:   0%|  …"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d30be805e87146269ee04182756b043e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading https://huggingface.co/stanfordnlp/stanza-vi/resolve/v1.7.0/models/sentiment/vsfc.pt:   0%|       …"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "658e5e55a52c4ef099f38c3ad9972f56"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading https://huggingface.co/stanfordnlp/stanza-vi/resolve/v1.7.0/models/ner/vlsp.pt:   0%|          | 0…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2d740012e319419f91a6ec99e45e36b0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading https://huggingface.co/stanfordnlp/stanza-vi/resolve/v1.7.0/models/backward_charlm/conll17.pt:   0…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "beb320a915ed4860af4323e755d0221e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading https://huggingface.co/stanfordnlp/stanza-vi/resolve/v1.7.0/models/pretrain/conll17.pt:   0%|     …"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "72f6d1e4c137420ca6fc0b440c8a7eb5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading https://huggingface.co/stanfordnlp/stanza-vi/resolve/v1.7.0/models/forward_charlm/conll17.pt:   0%…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "56fe7e2f028e4902a4b9a4182490e0f2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:stanza:Loading these models for language: vi (Vietnamese):\n",
            "==========================================\n",
            "| Processor    | Package                 |\n",
            "------------------------------------------\n",
            "| tokenize     | vtb                     |\n",
            "| pos          | vtb_charlm              |\n",
            "| lemma        | identity                |\n",
            "| constituency | vlsp22_charlm           |\n",
            "| depparse     | /content/d..._parser.pt |\n",
            "| sentiment    | vsfc                    |\n",
            "| ner          | vlsp                    |\n",
            "==========================================\n",
            "\n",
            "INFO:stanza:Using device: cuda\n",
            "INFO:stanza:Loading: tokenize\n",
            "INFO:stanza:Loading: pos\n",
            "INFO:stanza:Loading: lemma\n",
            "INFO:stanza:Loading: constituency\n",
            "INFO:stanza:Loading: depparse\n",
            "INFO:stanza:Loading: sentiment\n",
            "INFO:stanza:Loading: ner\n",
            "INFO:stanza:Done loading processors!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc = pipeline(\"Hôm nay tôi đi qua nhà Lan .\")\n",
        "doc.sentences[0].print_dependencies()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nWDjV0BahIEg",
        "outputId": "ad2d4c45-69fc-4df9-9e7b-d096c3763b59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('Hôm', 4, 'obl:tmod')\n",
            "('nay', 1, 'det:pmod')\n",
            "('tôi', 4, 'nsubj')\n",
            "('đi', 0, 'root')\n",
            "('qua', 4, 'xcomp')\n",
            "('nhà', 4, 'obj')\n",
            "('Lan', 6, 'nmod')\n",
            "('.', 4, 'punct')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/stanza/visualization"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6hsrOjqLCIOV",
        "outputId": "8ce8f810-9022-4e21-a94e-c7be44b5778c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/stanza/visualization\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install -y graphviz\n",
        "!pip install graphviz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KccyoOu2CTNw",
        "outputId": "32e1ced1-15b2-4763-d2fe-945dccfd3dbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "graphviz is already the newest version (2.42.2-6).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 24 not upgraded.\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (0.20.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import stanza\n",
        "import graphviz"
      ],
      "metadata": {
        "id": "xiUSzs6ECVuo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_dependency_tree(doc):\n",
        "    dot = graphviz.Digraph(comment='Dependency Tree')\n",
        "\n",
        "    dot.attr(fontpath='/content/drive/MyDrive', fontname='Roboto-Medium.ttf', fontcharset='utf-8')\n",
        "\n",
        "    dot.attr(rankdir='TB', ranksep='0.1', nodesep='0.1', fontname='Roboto-Medium.ttf', fontcharset='utf-8')\n",
        "\n",
        "    for i, word in enumerate(doc.sentences[0].words):\n",
        "        dot.node(str(i + 1), f\"{word.text} ({word.deprel})\", fontname='Roboto-Medium.ttf', fontcharset='utf-8')\n",
        "\n",
        "    for i, word in enumerate(doc.sentences[0].words):\n",
        "        if word.head != 0:\n",
        "            dot.edge(str(word.head), str(i + 1))\n",
        "\n",
        "    return dot"
      ],
      "metadata": {
        "id": "UHNLoYu6CbWD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "import os\n",
        "\n",
        "# Specify the directory to save the PNG image\n",
        "save_dir = '/content/drive/MyDrive/stanza/visualization'\n",
        "\n",
        "# Visualize the dependency parsing tree for Vietnamese\n",
        "dependency_tree = visualize_dependency_tree(doc)\n",
        "\n",
        "# Save the dependency tree as a PNG file\n",
        "png_data = dependency_tree.pipe(format='png')\n",
        "image = Image.open(BytesIO(png_data))\n",
        "\n",
        "# Save the PNG image to the specified directory\n",
        "image_path = os.path.join(save_dir, 'dependency_tree_vi.png')\n",
        "image.save(image_path)\n",
        "\n",
        "# Display the PNG image in Colab (optional)\n",
        "display(image)\n",
        "\n",
        "# Print the path where the image is saved\n",
        "print(f\"Image saved to: {image_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "id": "V6wkI_mxDNux",
        "outputId": "e7a1350b-62f3-4b87-d41c-0b26f1349ab3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=963x176>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image saved to: /content/drive/MyDrive/stanza/visualization/dependency_tree_vi.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RIp9Z9LiIhm4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}